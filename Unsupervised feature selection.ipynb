{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vcf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage ,fcluster\n",
    "from collections import Counter\n",
    "#from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "import itertools\n",
    "import random\n",
    "from scipy.spatial import distance as ssd\n",
    "from tqdm import tqdm\n",
    "import scipy\n",
    "import scipy.sparse \n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import kneighbors_graph \n",
    "from scipy.sparse.linalg import expm\n",
    "from scipy.linalg import solve_banded\n",
    "from scipy.spatial.distance import pdist\n",
    "import scipy.spatial.distance\n",
    "import math\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import sklearn\n",
    "import os.path\n",
    "import re\n",
    "import math\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.linear_model import LassoLars, Lars\n",
    "from scipy.linalg import eigh\n",
    "from fsfc.base import KBestFeatureSelector\n",
    "plt.ion()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/Aral/Desktop/毕业论文/数据/SARS-CoV-2 lineage meta data.csv')\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = list(df[(df['lineage']=='AY.12 (Delta-like)')|(df['lineage']=='AY.9 (Delta-like)')|(df['lineage']=='AY.4 (Delta-like)')]['INAB sample ID'])\n",
    "file_dir = 'C:/Users/Aral/Desktop/毕业论文/数据/clinical_variant_files'\n",
    "def getFlist(path):\n",
    "    f = []\n",
    "    for root, dirs, files in os.walk(file_dir):\n",
    "        f.append(files)\n",
    "    return f\n",
    "file_name = getFlist(file_dir)[0]\n",
    "\n",
    "pos_record = {}\n",
    "\n",
    "for i in range(len(file_name)):\n",
    "    if i != 306:\n",
    "        t = re.findall(r'V[0-9]*',file_name[i])\n",
    "        if t[0] in target:\n",
    "            test = vcf.Reader(filename = 'C:/Users/Aral/Desktop/毕业论文/数据/clinical_variant_files/'+file_name[i])\n",
    "            for record in test:\n",
    "                if record.POS not in pos_record:\n",
    "                    pos_record[record.POS] = 1\n",
    "                else:\n",
    "                    pos_record[record.POS] += 1\n",
    "\n",
    "res = sorted(pos_record.items(),key = lambda item:item[1],reverse=True)\n",
    "sor_res = {str(k):v for k,v in res}\n",
    "x = list(sor_res.keys())\n",
    "\n",
    "sor_res_filter = dict(filter(lambda x: x[1] > 1 ,sor_res.items()))\n",
    "pos2 = list(sor_res_filter.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('C:/Users/Aral/Desktop/毕业论文/数据/SARS-CoV-2 lineage meta data.csv')\n",
    "df2 = df2.dropna()\n",
    "target2 = list(df2[(df2['lineage']=='AY.4 (Delta-like)')]['INAB sample ID'])\n",
    "x2 = []\n",
    "for i in range(len(file_name)):\n",
    "    tar = [0]*len(pos2)\n",
    "    if i != 306:\n",
    "        t = re.findall(r'V[0-9]*',file_name[i])\n",
    "        if t[0] in target2:\n",
    "            test = vcf.Reader(filename = 'C:/Users/Aral/Desktop/毕业论文/数据/clinical_variant_files/'+file_name[i])\n",
    "            for p in test:\n",
    "                if str(p.POS) in pos2:\n",
    "                    if p.ALT[0] == 'A':\n",
    "                        tar[pos2.index(str(p.POS))] = 1\n",
    "                    if p.ALT[0] == 'C':\n",
    "                        tar[pos2.index(str(p.POS))] = 2\n",
    "                    if p.ALT[0] == 'G':\n",
    "                        tar[pos2.index(str(p.POS))] = 3\n",
    "                    if p.ALT[0] == 'T':\n",
    "                        tar[pos2.index(str(p.POS))] = 4\n",
    "            x2.append(tar)\n",
    "\n",
    "AY4_POS2 = pd.DataFrame(x2)\n",
    "AY4_POS2.columns = pos2\n",
    "AY4_POS2['Label'] =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv('C:/Users/Aral/Desktop/毕业论文/数据/SARS-CoV-2 lineage meta data.csv')\n",
    "df3 = df3.dropna()\n",
    "target3 = list(df3[(df3['lineage']=='AY.9 (Delta-like)')]['INAB sample ID'])\n",
    "\n",
    "x3 = []\n",
    "for i in range(len(file_name)):\n",
    "    tar = [0]*len(pos2)\n",
    "    if i != 306:\n",
    "        t = re.findall(r'V[0-9]*',file_name[i])\n",
    "        if t[0] in target3:\n",
    "            test = vcf.Reader(filename = 'C:/Users/Aral/Desktop/毕业论文/数据/clinical_variant_files/'+file_name[i])\n",
    "            for p in test:\n",
    "                if str(p.POS) in pos2:\n",
    "                    if p.ALT[0] == 'A':\n",
    "                        tar[pos2.index(str(p.POS))] = 1\n",
    "                    if p.ALT[0] == 'C':\n",
    "                        tar[pos2.index(str(p.POS))] = 2\n",
    "                    if p.ALT[0] == 'G':\n",
    "                        tar[pos2.index(str(p.POS))] = 3\n",
    "                    if p.ALT[0] == 'T':\n",
    "                        tar[pos2.index(str(p.POS))] = 4\n",
    "            x3.append(tar)\n",
    "\n",
    "AY9_POS2 = pd.DataFrame(x3)\n",
    "AY9_POS2.columns = pos2\n",
    "AY9_POS2['Label'] =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/Aral/Desktop/毕业论文/数据/SARS-CoV-2 lineage meta data.csv')\n",
    "df = df.dropna()\n",
    "target1 = list(df[(df['lineage']=='AY.12 (Delta-like)')]['INAB sample ID'])\n",
    "\n",
    "x = []\n",
    "name1 = []\n",
    "for i in range(len(file_name)):\n",
    "    tar = [0]*len(pos2)\n",
    "    if i != 306:\n",
    "        t = re.findall(r'V[0-9]*',file_name[i])\n",
    "        if t[0] in target1:\n",
    "            name1.append(t[0])\n",
    "            test = vcf.Reader(filename = 'C:/Users/Aral/Desktop/毕业论文/数据/clinical_variant_files/'+file_name[i])\n",
    "            for p in test:\n",
    "                if str(p.POS) in pos2:\n",
    "                    if p.ALT[0] == 'A':\n",
    "                        tar[pos2.index(str(p.POS))] = 1\n",
    "                    if p.ALT[0] == 'C':\n",
    "                        tar[pos2.index(str(p.POS))] = 2\n",
    "                    if p.ALT[0] == 'G':\n",
    "                        tar[pos2.index(str(p.POS))] = 3\n",
    "                    if p.ALT[0] == 'T':\n",
    "                        tar[pos2.index(str(p.POS))] = 4\n",
    "            x.append(tar)\n",
    "            \n",
    "AY12_POS2 = pd.DataFrame(x)\n",
    "AY12_POS2.columns = pos2\n",
    "AY12_POS2['Label'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>23403</th>\n",
       "      <th>28270</th>\n",
       "      <th>28881</th>\n",
       "      <th>14408</th>\n",
       "      <th>3037</th>\n",
       "      <th>22917</th>\n",
       "      <th>16466</th>\n",
       "      <th>22995</th>\n",
       "      <th>26767</th>\n",
       "      <th>28247</th>\n",
       "      <th>...</th>\n",
       "      <th>20055</th>\n",
       "      <th>2258</th>\n",
       "      <th>3569</th>\n",
       "      <th>12056</th>\n",
       "      <th>13701</th>\n",
       "      <th>26625</th>\n",
       "      <th>491</th>\n",
       "      <th>22790</th>\n",
       "      <th>9584</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>459 rows × 370 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     23403  28270  28881  14408  3037  22917  16466  22995  26767  28247  ...  \\\n",
       "0        3      4      4      4     4      3      4      1      2      1  ...   \n",
       "1        3      4      4      4     4      3      4      1      2      1  ...   \n",
       "2        3      4      4      4     4      3      4      1      2      1  ...   \n",
       "3        3      4      4      4     4      3      4      1      2      1  ...   \n",
       "4        3      4      4      4     4      3      4      1      0      1  ...   \n",
       "..     ...    ...    ...    ...   ...    ...    ...    ...    ...    ...  ...   \n",
       "279      3      4      4      4     4      3      4      1      2      1  ...   \n",
       "280      3      4      4      4     4      3      4      1      2      1  ...   \n",
       "281      3      4      4      4     4      3      4      1      2      1  ...   \n",
       "282      3      4      4      4     4      3      4      1      2      1  ...   \n",
       "283      3      4      4      4     4      3      4      1      2      1  ...   \n",
       "\n",
       "     20055  2258  3569  12056  13701  26625  491  22790  9584  Label  \n",
       "0        0     0     0      0      0      0    0      0     0      0  \n",
       "1        0     0     0      0      0      0    0      0     0      0  \n",
       "2        0     0     0      0      0      0    0      0     0      0  \n",
       "3        0     0     0      0      0      0    0      0     0      0  \n",
       "4        0     0     0      0      0      0    0      0     0      0  \n",
       "..     ...   ...   ...    ...    ...    ...  ...    ...   ...    ...  \n",
       "279      0     0     0      0      0      0    0      0     0      2  \n",
       "280      0     0     0      0      0      0    0      0     0      2  \n",
       "281      0     0     0      0      0      0    0      0     0      2  \n",
       "282      0     0     0      0      0      0    0      0     0      2  \n",
       "283      0     0     0      0      0      0    0      0     0      2  \n",
       "\n",
       "[459 rows x 370 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = AY4_POS2.append(AY9_POS2)\n",
    "fin_data = b.append(AY12_POS2)\n",
    "\n",
    "fin_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(fin_data.iloc[:,:-1])\n",
    "\n",
    "# Project data onto first two principal components\n",
    "projX = pca.transform(fin_data.iloc[:,:-1])\n",
    "plt.figure(figsize=(30,15))\n",
    "\n",
    "scatter = plt.scatter(projX[:,0],projX[:,1],c=fin_data.iloc[:,-1],cmap='rainbow')\n",
    "plt.legend(handles=scatter.legend_elements()[0],labels = scatter.legend_elements()[1],\n",
    "           title=\"lineage\")\n",
    "plt.title('Projected data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3703263588438124\n"
     ]
    }
   ],
   "source": [
    "pred = KMeans(n_clusters= 3).fit(np.array(fin_data.iloc[:,:-1])).labels_\n",
    "print(adjusted_rand_score(np.array(fin_data.iloc[:,-1]), pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laplacian Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_W(X, neighbour_size = 10, t = 1):\n",
    "    n_samples, n_features = np.shape(X)\n",
    "    S=kneighbors_graph(X, neighbour_size+1, mode='distance',metric='euclidean') #sqecludian distance works only with mode=connectivity  results were absurd\n",
    "    S = (-1*(S*S))/(2*t*t)\n",
    "    S=S.tocsc()\n",
    "    S=expm(S) # exponential\n",
    "    S=S.tocsr()\n",
    "    #[1]  M. Belkin and P. Niyogi, “Laplacian Eigenmaps and Spectral Techniques for Embedding and Clustering,” Advances in Neural Information Processing Systems,\n",
    "    #Vol. 14, 2001. Following the paper to make the weights matrix symmetrix we use this method\n",
    "    bigger = np.transpose(S) > S\n",
    "    S = S - S.multiply(bigger) + np.transpose(S).multiply(bigger)\n",
    "    return S\n",
    "\n",
    "def LaplacianScore(X, neighbour_size = 10,  t = 1):\n",
    "    W = construct_W(X,t=t,neighbour_size=neighbour_size)\n",
    "    n_samples, n_features = np.shape(X)\n",
    "    \n",
    "    #construct the diagonal matrix\n",
    "    D=np.array(W.sum(axis=1))\n",
    "    D = scipy.sparse.diags(np.transpose(D), [0])\n",
    "    #construct graph Laplacian L\n",
    "    L=D-W.toarray()\n",
    "\n",
    "    #construct 1= [1,···,1]' \n",
    "    I=np.ones((n_samples,n_features))\n",
    "\n",
    "    #construct fr' => fr= [fr1,...,frn]'\n",
    "    Xt = np.transpose(X)\n",
    "\n",
    "    #construct fr^=fr-(frt D I/It D I)I\n",
    "    t=np.matmul(np.matmul(Xt,D.toarray()),I)/np.matmul(np.matmul(np.transpose(I),D.toarray()),I)\n",
    "    t=t[:,0]\n",
    "    t=np.tile(t,(n_samples,1))\n",
    "    fr=X-t\n",
    "\n",
    "    #Compute Laplacian Score\n",
    "    fr_t=np.transpose(fr)\n",
    "    Lr=np.matmul(np.matmul(fr_t,L),fr)/np.matmul(np.dot(fr_t,D.toarray()),fr)\n",
    "\n",
    "    return np.diag(Lr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:38: RuntimeWarning: divide by zero encountered in true_divide\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:38: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ls =LaplacianScore(np.array(fin_data.iloc[:,:-1]))\n",
    "plt.figure(figsize=(30,15))\n",
    "plt.title('Laplacian feature importance scores')\n",
    "plt.bar(np.arange(np.array(fin_data.iloc[:,:-1]).shape[1]),ls);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "indices = np.argsort(ls)[:50]  # top 30 features\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)),ls[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [fin_data.columns[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fea_name = []\n",
    "sel_fea = list(np.where(ls< 0.3)[0])\n",
    "for i in range(len(list(fin_data.columns))):\n",
    "    if i in sel_fea:\n",
    "        fea_name.append(list(fin_data.columns)[i])\n",
    "sel_data = fin_data[fea_name]\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(sel_data)\n",
    "\n",
    "# Project data onto first two principal components\n",
    "projX = pca.transform(sel_data)\n",
    "plt.figure(figsize=(30,15))\n",
    "\n",
    "scatter = plt.scatter(projX[:,0],projX[:,1],c=fin_data.iloc[:,-1],cmap='rainbow')\n",
    "plt.legend(handles=scatter.legend_elements()[0],labels = ['AY.4 (Delta-like)','AY.9 (Delta-like)','AY.12 (Delta-like)'],\n",
    "           title=\"lineage\")\n",
    "plt.title('Projected data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['23403',\n",
       " '5184',\n",
       " '9891',\n",
       " '11418',\n",
       " '11514',\n",
       " '2509',\n",
       " '3553',\n",
       " '15760',\n",
       " '29212',\n",
       " '26152',\n",
       " '22310',\n",
       " '29716',\n",
       " '2571',\n",
       " '6500',\n",
       " '15337',\n",
       " '25047',\n",
       " '5131',\n",
       " '20134',\n",
       " '27987',\n",
       " '26464',\n",
       " '26873',\n",
       " '6990',\n",
       " '11758',\n",
       " '11767',\n",
       " '8730',\n",
       " '25019',\n",
       " '27047',\n",
       " '27596',\n",
       " '3717',\n",
       " '11521',\n",
       " '18441',\n",
       " '3369',\n",
       " '12557',\n",
       " '20055']"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fea_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl = ['10029',\n",
    " '11332',\n",
    " '8986',\n",
    " '6402',\n",
    " '9053',\n",
    " '11201',\n",
    " '27874',\n",
    " '4181',\n",
    " '28916',\n",
    " '7124',\n",
    " '19220',\n",
    " '1048',\n",
    " '613',\n",
    " '9891',\n",
    " '5184',\n",
    " '11514',\n",
    " '11418',\n",
    " '22227',\n",
    " '22792',\n",
    " '19009']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5184\n",
      "9891\n",
      "11418\n",
      "11514\n"
     ]
    }
   ],
   "source": [
    "for i in fea_name:\n",
    "    if i in sl:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47762090585730516\n"
     ]
    }
   ],
   "source": [
    "pred = KMeans(n_clusters= 3).fit(np.array(fin_data.iloc[:,:-1])[:,list(np.where( ls < 0.3)[0])]).labels_\n",
    "print(adjusted_rand_score(np.array(fin_data.iloc[:,-1]), pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MCFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=6.750e-05, with an active set of 27 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=6.579e-05, with an active set of 37 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=4.368e-05, with an active set of 51 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=3.880e-05, with an active set of 64 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=3.880e-05, with an active set of 64 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=3.874e-05, with an active set of 64 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=3.874e-05, with an active set of 64 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 93 iterations, i.e. alpha=3.660e-05, with an active set of 73 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 93 iterations, i.e. alpha=3.660e-05, with an active set of 73 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=3.569e-05, with an active set of 75 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=3.569e-05, with an active set of 75 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=3.574e-05, with an active set of 80 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=3.560e-05, with an active set of 81 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 105 iterations, i.e. alpha=3.559e-05, with an active set of 82 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 106 iterations, i.e. alpha=3.409e-05, with an active set of 83 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=3.335e-05, with an active set of 86 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=3.303e-05, with an active set of 88 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=3.303e-05, with an active set of 88 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=3.231e-05, with an active set of 92 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=3.201e-05, with an active set of 94 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 119 iterations, i.e. alpha=3.186e-05, with an active set of 95 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 119 iterations, i.e. alpha=3.137e-05, with an active set of 95 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 119 iterations, i.e. alpha=3.137e-05, with an active set of 95 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 127 iterations, i.e. alpha=3.091e-05, with an active set of 101 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 127 iterations, i.e. alpha=3.011e-05, with an active set of 101 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=2.875e-05, with an active set of 106 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=2.861e-05, with an active set of 106 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=2.566e-05, with an active set of 116 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=2.564e-05, with an active set of 116 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 164 iterations, i.e. alpha=1.498e-04, with an active set of 128 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=6.060e-04, with an active set of 133 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 181 iterations, i.e. alpha=6.458e-04, with an active set of 137 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 181 iterations, i.e. alpha=6.443e-04, with an active set of 137 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 220 iterations, i.e. alpha=6.246e-04, with an active set of 170 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 220 iterations, i.e. alpha=6.219e-04, with an active set of 170 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 228 iterations, i.e. alpha=6.064e-04, with an active set of 176 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 232 iterations, i.e. alpha=5.961e-04, with an active set of 180 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 237 iterations, i.e. alpha=5.924e-04, with an active set of 184 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 237 iterations, i.e. alpha=5.838e-04, with an active set of 184 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 237 iterations, i.e. alpha=5.815e-04, with an active set of 184 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 244 iterations, i.e. alpha=5.578e-04, with an active set of 190 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 244 iterations, i.e. alpha=5.575e-04, with an active set of 190 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 253 iterations, i.e. alpha=5.368e-04, with an active set of 197 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 253 iterations, i.e. alpha=5.366e-04, with an active set of 197 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=5.339e-04, with an active set of 200 regressors, and the smallest cholesky pivot element being 8.560e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 259 iterations, i.e. alpha=5.267e-04, with an active set of 203 regressors, and the smallest cholesky pivot element being 8.560e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 259 iterations, i.e. alpha=5.244e-04, with an active set of 203 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 259 iterations, i.e. alpha=5.201e-04, with an active set of 203 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 259 iterations, i.e. alpha=5.114e-04, with an active set of 203 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 261 iterations, i.e. alpha=5.020e-04, with an active set of 205 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 261 iterations, i.e. alpha=4.951e-04, with an active set of 205 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 261 iterations, i.e. alpha=4.882e-04, with an active set of 205 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 261 iterations, i.e. alpha=4.880e-04, with an active set of 205 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 261 iterations, i.e. alpha=4.853e-04, with an active set of 205 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 261 iterations, i.e. alpha=4.851e-04, with an active set of 205 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 261 iterations, i.e. alpha=4.850e-04, with an active set of 205 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 261 iterations, i.e. alpha=4.839e-04, with an active set of 205 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=4.658e-04, with an active set of 206 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=4.542e-04, with an active set of 206 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 264 iterations, i.e. alpha=4.347e-04, with an active set of 208 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 268 iterations, i.e. alpha=4.066e-04, with an active set of 211 regressors, and the smallest cholesky pivot element being 9.940e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 268 iterations, i.e. alpha=3.926e-04, with an active set of 211 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 268 iterations, i.e. alpha=3.881e-04, with an active set of 211 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 268 iterations, i.e. alpha=3.727e-04, with an active set of 211 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=4.227e-04, with an active set of 218 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 281 iterations, i.e. alpha=3.944e-04, with an active set of 219 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 339 iterations, i.e. alpha=2.299e-02, with an active set of 240 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 339 iterations, i.e. alpha=2.174e-02, with an active set of 240 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 339 iterations, i.e. alpha=2.045e-02, with an active set of 240 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=2.425e-02, with an active set of 245 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=2.067e-02, with an active set of 245 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=1.691e-02, with an active set of 248 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=1.607e-02, with an active set of 248 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=1.606e-02, with an active set of 248 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=1.565e-02, with an active set of 248 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=1.551e-02, with an active set of 248 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=1.432e-02, with an active set of 248 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=1.206e-02, with an active set of 248 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=9.622e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 9.940e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=9.621e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 9.940e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=9.226e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=9.225e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=9.150e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=9.014e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=8.826e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=8.712e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=8.473e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=8.463e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=8.452e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=8.451e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=8.450e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=8.436e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=8.433e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=8.432e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=8.431e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=8.431e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=8.383e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=8.382e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=8.361e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=8.360e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=8.357e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=8.351e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=8.290e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=8.239e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=8.230e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=8.227e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=8.223e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=8.221e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=8.220e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=8.175e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=8.159e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=8.054e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=8.051e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=8.049e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=8.041e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=8.040e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=8.023e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=7.999e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=7.955e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=7.936e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=7.930e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=7.926e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=7.911e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=7.905e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=7.897e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=7.896e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=7.888e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=7.857e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=7.852e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=7.807e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=7.752e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=7.728e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=7.687e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=7.673e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=7.670e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=7.613e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=7.547e-03, with an active set of 248 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=7.290e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=7.169e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=6.970e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=6.833e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=6.605e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=6.493e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=6.276e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=5.925e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=5.924e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=5.867e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=5.840e-03, with an active set of 250 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=5.784e-03, with an active set of 250 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=5.587e-03, with an active set of 250 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=5.574e-03, with an active set of 250 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=5.471e-03, with an active set of 250 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=4.780e-03, with an active set of 250 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=4.493e-03, with an active set of 251 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=3.925e-03, with an active set of 251 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=3.615e-03, with an active set of 251 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=3.473e-03, with an active set of 251 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 358 iterations, i.e. alpha=2.963e-03, with an active set of 252 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 358 iterations, i.e. alpha=2.817e-03, with an active set of 252 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 358 iterations, i.e. alpha=2.782e-03, with an active set of 252 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=2.519e-03, with an active set of 253 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=1.962e-03, with an active set of 253 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=1.802e-03, with an active set of 253 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=1.756e-03, with an active set of 253 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=1.680e-03, with an active set of 253 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=1.670e-03, with an active set of 253 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=1.451e-03, with an active set of 253 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=1.449e-03, with an active set of 253 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=1.448e-03, with an active set of 253 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=1.251e-03, with an active set of 253 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=1.113e-03, with an active set of 253 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=1.033e-03, with an active set of 253 regressors, and the smallest cholesky pivot element being 9.940e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.920e-04, with an active set of 253 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.897e-04, with an active set of 253 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.881e-04, with an active set of 253 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.806e-04, with an active set of 253 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=9.650e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=9.586e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=9.324e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=9.311e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=9.252e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=9.187e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=9.110e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=9.055e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=8.900e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=8.851e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=8.803e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=8.771e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=8.711e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=8.703e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=8.679e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=8.677e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=8.676e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=8.658e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=8.651e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=8.557e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=8.549e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=8.545e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=8.542e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=8.425e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=8.377e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=8.363e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=8.303e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=8.220e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=8.081e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=8.077e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=8.039e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=8.038e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=8.014e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=7.996e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=7.985e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=7.975e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=7.970e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=7.969e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=7.941e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=7.906e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=7.896e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=7.834e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=7.678e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=7.611e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=7.580e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=7.574e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=7.564e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=7.458e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=7.438e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=7.424e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=7.420e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=7.382e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=7.375e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=7.224e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=7.168e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=6.891e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=6.840e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=6.839e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=6.502e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=6.445e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=6.421e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=5.963e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=5.957e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=5.953e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=5.809e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=5.583e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=5.421e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=4.850e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=2.402e-04, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=9.583e-05, with an active set of 254 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=3.052e-05, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=2.143e-05, with an active set of 254 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=1.926e-05, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=9.069e-06, with an active set of 254 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=8.711e-06, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=8.405e-06, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=4.039e-06, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=3.937e-06, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=3.322e-06, with an active set of 254 regressors, and the smallest cholesky pivot element being 9.940e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=3.314e-06, with an active set of 254 regressors, and the smallest cholesky pivot element being 9.940e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=2.932e-06, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=2.890e-06, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=2.844e-06, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=2.594e-06, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=1.307e-06, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=7.506e-07, with an active set of 254 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=5.599e-07, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.202e+07, with an active set of 9 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.202e+07, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.299e+07, with an active set of 11 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.282e+07, with an active set of 12 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.271e+07, with an active set of 13 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.066e+07, with an active set of 16 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.066e+07, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.061e+07, with an active set of 16 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.024e+07, with an active set of 16 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=9.167e+06, with an active set of 18 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=6.830e+06, with an active set of 19 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=6.830e+06, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=5.739e+06, with an active set of 24 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=5.346e+06, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=4.722e+06, with an active set of 28 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=4.722e+06, with an active set of 28 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=4.722e+06, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=4.008e+06, with an active set of 30 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=3.854e+06, with an active set of 30 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=3.081e+06, with an active set of 37 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=2.875e+06, with an active set of 38 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=2.663e+06, with an active set of 42 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=2.633e+06, with an active set of 46 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=2.343e+06, with an active set of 52 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=2.297e+06, with an active set of 56 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=2.228e+06, with an active set of 57 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=2.228e+06, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=2.228e+06, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=2.158e+06, with an active set of 58 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=2.142e+06, with an active set of 59 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=1.968e+06, with an active set of 62 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=1.891e+06, with an active set of 67 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=1.891e+06, with an active set of 67 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=1.803e+06, with an active set of 68 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 77 iterations, i.e. alpha=1.801e+06, with an active set of 69 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 83 iterations, i.e. alpha=1.649e+06, with an active set of 74 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=1.619e+06, with an active set of 77 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 95 iterations, i.e. alpha=1.531e+06, with an active set of 85 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=1.380e+06, with an active set of 98 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=1.360e+06, with an active set of 98 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=1.360e+06, with an active set of 98 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=1.349e+06, with an active set of 99 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=1.349e+06, with an active set of 99 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=1.312e+06, with an active set of 100 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 119 iterations, i.e. alpha=1.265e+06, with an active set of 107 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 119 iterations, i.e. alpha=1.265e+06, with an active set of 107 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 144 iterations, i.e. alpha=1.094e+06, with an active set of 131 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 144 iterations, i.e. alpha=1.094e+06, with an active set of 131 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 144 iterations, i.e. alpha=1.091e+06, with an active set of 131 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 149 iterations, i.e. alpha=1.043e+06, with an active set of 136 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 155 iterations, i.e. alpha=1.024e+06, with an active set of 141 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 158 iterations, i.e. alpha=1.002e+06, with an active set of 144 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 158 iterations, i.e. alpha=1.002e+06, with an active set of 144 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=1.001e+06, with an active set of 145 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=9.903e+05, with an active set of 145 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=9.881e+05, with an active set of 145 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 159 iterations, i.e. alpha=9.881e+05, with an active set of 145 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=9.353e+05, with an active set of 154 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 190 iterations, i.e. alpha=9.042e+05, with an active set of 171 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 190 iterations, i.e. alpha=9.042e+05, with an active set of 171 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 190 iterations, i.e. alpha=9.042e+05, with an active set of 171 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 190 iterations, i.e. alpha=8.736e+05, with an active set of 171 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 190 iterations, i.e. alpha=8.585e+05, with an active set of 171 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 203 iterations, i.e. alpha=8.787e+05, with an active set of 180 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 204 iterations, i.e. alpha=8.630e+05, with an active set of 181 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 207 iterations, i.e. alpha=8.388e+05, with an active set of 183 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 211 iterations, i.e. alpha=8.135e+05, with an active set of 187 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 211 iterations, i.e. alpha=8.118e+05, with an active set of 187 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 226 iterations, i.e. alpha=8.066e+05, with an active set of 199 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 264 iterations, i.e. alpha=2.538e+09, with an active set of 212 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 297 iterations, i.e. alpha=1.252e+10, with an active set of 230 regressors, and the smallest cholesky pivot element being 9.884e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 297 iterations, i.e. alpha=1.251e+10, with an active set of 230 regressors, and the smallest cholesky pivot element being 9.884e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 297 iterations, i.e. alpha=1.241e+10, with an active set of 230 regressors, and the smallest cholesky pivot element being 9.541e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 297 iterations, i.e. alpha=8.692e+09, with an active set of 230 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=5.221e+13, with an active set of 253 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 343 iterations, i.e. alpha=5.130e+13, with an active set of 255 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 343 iterations, i.e. alpha=4.926e+13, with an active set of 255 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 343 iterations, i.e. alpha=4.818e+13, with an active set of 255 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 343 iterations, i.e. alpha=3.991e+13, with an active set of 255 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 343 iterations, i.e. alpha=3.488e+13, with an active set of 255 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 344 iterations, i.e. alpha=3.223e+13, with an active set of 256 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 344 iterations, i.e. alpha=3.021e+13, with an active set of 256 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 344 iterations, i.e. alpha=2.507e+13, with an active set of 256 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 344 iterations, i.e. alpha=2.261e+13, with an active set of 256 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 344 iterations, i.e. alpha=1.862e+13, with an active set of 256 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 344 iterations, i.e. alpha=1.854e+13, with an active set of 256 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 344 iterations, i.e. alpha=1.826e+13, with an active set of 256 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 344 iterations, i.e. alpha=1.346e+13, with an active set of 256 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 346 iterations, i.e. alpha=1.452e+13, with an active set of 257 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 346 iterations, i.e. alpha=1.335e+13, with an active set of 257 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 346 iterations, i.e. alpha=1.226e+13, with an active set of 257 regressors, and the smallest cholesky pivot element being 9.771e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 347 iterations, i.e. alpha=1.091e+13, with an active set of 258 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 347 iterations, i.e. alpha=1.088e+13, with an active set of 258 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 347 iterations, i.e. alpha=1.018e+13, with an active set of 258 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 347 iterations, i.e. alpha=9.925e+12, with an active set of 258 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 347 iterations, i.e. alpha=8.083e+12, with an active set of 258 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 347 iterations, i.e. alpha=7.810e+12, with an active set of 258 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 347 iterations, i.e. alpha=7.134e+12, with an active set of 258 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 347 iterations, i.e. alpha=6.177e+12, with an active set of 258 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 347 iterations, i.e. alpha=6.155e+12, with an active set of 258 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 347 iterations, i.e. alpha=5.986e+12, with an active set of 258 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 347 iterations, i.e. alpha=5.934e+12, with an active set of 258 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 347 iterations, i.e. alpha=5.779e+12, with an active set of 258 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 347 iterations, i.e. alpha=5.446e+12, with an active set of 258 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 347 iterations, i.e. alpha=5.402e+12, with an active set of 258 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 347 iterations, i.e. alpha=5.332e+12, with an active set of 258 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 347 iterations, i.e. alpha=5.080e+12, with an active set of 258 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 347 iterations, i.e. alpha=4.604e+12, with an active set of 258 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 347 iterations, i.e. alpha=4.566e+12, with an active set of 258 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 347 iterations, i.e. alpha=4.556e+12, with an active set of 258 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=3.903e+12, with an active set of 259 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=3.903e+12, with an active set of 259 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 349 iterations, i.e. alpha=3.842e+12, with an active set of 260 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 349 iterations, i.e. alpha=3.842e+12, with an active set of 260 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 349 iterations, i.e. alpha=3.419e+12, with an active set of 260 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 349 iterations, i.e. alpha=3.343e+12, with an active set of 260 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 349 iterations, i.e. alpha=3.335e+12, with an active set of 260 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 349 iterations, i.e. alpha=2.756e+12, with an active set of 260 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 349 iterations, i.e. alpha=2.741e+12, with an active set of 260 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 349 iterations, i.e. alpha=2.722e+12, with an active set of 260 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=2.641e+12, with an active set of 261 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=2.560e+12, with an active set of 261 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=2.463e+12, with an active set of 261 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=2.285e+12, with an active set of 261 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=2.229e+12, with an active set of 261 regressors, and the smallest cholesky pivot element being 9.771e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=2.194e+12, with an active set of 261 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=2.194e+12, with an active set of 261 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=2.190e+12, with an active set of 261 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=2.149e+12, with an active set of 261 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=2.120e+12, with an active set of 261 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=2.085e+12, with an active set of 261 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=2.005e+12, with an active set of 261 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=1.830e+12, with an active set of 261 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=1.813e+12, with an active set of 261 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=1.788e+12, with an active set of 261 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=1.769e+12, with an active set of 261 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=1.757e+12, with an active set of 261 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=1.695e+12, with an active set of 261 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=1.653e+12, with an active set of 261 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=1.609e+12, with an active set of 261 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=1.596e+12, with an active set of 261 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=1.587e+12, with an active set of 261 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=1.558e+12, with an active set of 261 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=1.556e+12, with an active set of 261 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=1.549e+12, with an active set of 261 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=1.530e+12, with an active set of 261 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=1.496e+12, with an active set of 261 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=1.463e+12, with an active set of 261 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=1.413e+12, with an active set of 261 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=1.335e+12, with an active set of 261 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=1.318e+12, with an active set of 261 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=1.230e+12, with an active set of 261 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=1.185e+12, with an active set of 261 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=1.175e+12, with an active set of 261 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=1.167e+12, with an active set of 261 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=1.154e+12, with an active set of 261 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=1.147e+12, with an active set of 261 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=1.142e+12, with an active set of 261 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=1.116e+12, with an active set of 261 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=1.109e+12, with an active set of 261 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=1.093e+12, with an active set of 261 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=1.078e+12, with an active set of 261 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=1.078e+12, with an active set of 261 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=1.074e+12, with an active set of 261 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=1.009e+12, with an active set of 261 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=9.463e+11, with an active set of 262 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=7.791e+11, with an active set of 262 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=7.791e+11, with an active set of 262 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=7.290e+11, with an active set of 262 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=7.105e+11, with an active set of 262 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=7.101e+11, with an active set of 262 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=6.671e+11, with an active set of 262 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=6.575e+11, with an active set of 262 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=6.521e+11, with an active set of 262 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=6.423e+11, with an active set of 262 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=6.139e+11, with an active set of 262 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=6.016e+11, with an active set of 262 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=5.840e+11, with an active set of 262 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=5.681e+11, with an active set of 262 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=5.265e+11, with an active set of 262 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=5.138e+11, with an active set of 262 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=4.999e+11, with an active set of 262 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=4.970e+11, with an active set of 262 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=4.689e+11, with an active set of 262 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=3.825e+11, with an active set of 262 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=3.748e+11, with an active set of 262 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=3.729e+11, with an active set of 262 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=3.084e+11, with an active set of 262 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=2.893e+11, with an active set of 262 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=2.668e+11, with an active set of 262 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=2.291e+11, with an active set of 262 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=2.281e+11, with an active set of 262 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=2.134e+11, with an active set of 262 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=1.922e+11, with an active set of 262 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=1.853e+11, with an active set of 262 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=1.764e+11, with an active set of 262 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=1.690e+11, with an active set of 262 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=1.536e+11, with an active set of 262 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=1.471e+11, with an active set of 262 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=1.436e+11, with an active set of 262 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=1.363e+11, with an active set of 262 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=1.253e+11, with an active set of 262 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=1.247e+11, with an active set of 262 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=9.060e+10, with an active set of 262 regressors, and the smallest cholesky pivot element being 9.771e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=9.059e+10, with an active set of 262 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=7.485e+10, with an active set of 262 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=6.094e+10, with an active set of 262 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=6.045e+10, with an active set of 262 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=4.794e+10, with an active set of 262 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=4.275e+10, with an active set of 262 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=4.140e+10, with an active set of 262 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=3.954e+10, with an active set of 262 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=3.838e+10, with an active set of 262 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=3.728e+10, with an active set of 262 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=3.684e+10, with an active set of 262 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=3.359e+10, with an active set of 262 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=2.761e+10, with an active set of 262 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=2.302e+10, with an active set of 262 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=2.283e+10, with an active set of 262 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=1.886e+10, with an active set of 262 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=1.871e+10, with an active set of 262 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=1.841e+10, with an active set of 262 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=1.838e+10, with an active set of 262 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=1.607e+10, with an active set of 262 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=1.607e+10, with an active set of 262 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=1.494e+10, with an active set of 262 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=1.409e+10, with an active set of 262 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=1.407e+10, with an active set of 262 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=1.262e+10, with an active set of 262 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=1.182e+10, with an active set of 262 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=7.982e+09, with an active set of 262 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=7.086e+09, with an active set of 262 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=6.794e+09, with an active set of 262 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=5.798e+09, with an active set of 262 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=4.450e+09, with an active set of 262 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=4.428e+09, with an active set of 262 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=2.479e+09, with an active set of 262 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=2.479e+09, with an active set of 262 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=2.449e+09, with an active set of 262 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=1.772e+00, with an active set of 44 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=1.575e+00, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=1.463e+00, with an active set of 66 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 77 iterations, i.e. alpha=1.406e+00, with an active set of 71 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 82 iterations, i.e. alpha=1.317e+00, with an active set of 76 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 92 iterations, i.e. alpha=1.236e+00, with an active set of 84 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 92 iterations, i.e. alpha=1.236e+00, with an active set of 84 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=8.359e+00, with an active set of 102 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 129 iterations, i.e. alpha=7.946e+00, with an active set of 108 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=7.705e+00, with an active set of 113 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=7.145e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=7.145e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=7.145e+00, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 152 iterations, i.e. alpha=7.006e+00, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 153 iterations, i.e. alpha=6.966e+00, with an active set of 131 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.066e+01, with an active set of 138 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 220 iterations, i.e. alpha=1.509e+01, with an active set of 172 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 220 iterations, i.e. alpha=1.509e+01, with an active set of 172 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 223 iterations, i.e. alpha=1.487e+01, with an active set of 175 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 231 iterations, i.e. alpha=1.448e+01, with an active set of 181 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 313 iterations, i.e. alpha=4.795e+03, with an active set of 216 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 313 iterations, i.e. alpha=4.795e+03, with an active set of 216 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 313 iterations, i.e. alpha=4.795e+03, with an active set of 216 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 313 iterations, i.e. alpha=4.620e+03, with an active set of 216 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 313 iterations, i.e. alpha=4.572e+03, with an active set of 216 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 313 iterations, i.e. alpha=4.066e+03, with an active set of 216 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 316 iterations, i.e. alpha=3.890e+03, with an active set of 219 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 317 iterations, i.e. alpha=3.795e+03, with an active set of 220 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 323 iterations, i.e. alpha=3.518e+03, with an active set of 223 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 323 iterations, i.e. alpha=3.418e+03, with an active set of 223 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 323 iterations, i.e. alpha=3.418e+03, with an active set of 223 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 330 iterations, i.e. alpha=3.170e+03, with an active set of 229 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 332 iterations, i.e. alpha=2.761e+03, with an active set of 231 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 332 iterations, i.e. alpha=2.760e+03, with an active set of 231 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 332 iterations, i.e. alpha=2.760e+03, with an active set of 231 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 332 iterations, i.e. alpha=2.760e+03, with an active set of 231 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 332 iterations, i.e. alpha=2.759e+03, with an active set of 231 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 332 iterations, i.e. alpha=2.759e+03, with an active set of 231 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 332 iterations, i.e. alpha=2.759e+03, with an active set of 231 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 332 iterations, i.e. alpha=2.758e+03, with an active set of 231 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 332 iterations, i.e. alpha=2.758e+03, with an active set of 231 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 332 iterations, i.e. alpha=2.758e+03, with an active set of 231 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 332 iterations, i.e. alpha=2.757e+03, with an active set of 231 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 332 iterations, i.e. alpha=2.756e+03, with an active set of 231 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 332 iterations, i.e. alpha=2.755e+03, with an active set of 231 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 332 iterations, i.e. alpha=2.753e+03, with an active set of 231 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 332 iterations, i.e. alpha=2.753e+03, with an active set of 231 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 332 iterations, i.e. alpha=2.752e+03, with an active set of 231 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 332 iterations, i.e. alpha=2.751e+03, with an active set of 231 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 332 iterations, i.e. alpha=2.751e+03, with an active set of 231 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 332 iterations, i.e. alpha=2.749e+03, with an active set of 231 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 332 iterations, i.e. alpha=2.747e+03, with an active set of 231 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 332 iterations, i.e. alpha=2.747e+03, with an active set of 231 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 332 iterations, i.e. alpha=2.746e+03, with an active set of 231 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 332 iterations, i.e. alpha=2.746e+03, with an active set of 231 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 332 iterations, i.e. alpha=2.739e+03, with an active set of 231 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 332 iterations, i.e. alpha=2.737e+03, with an active set of 231 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 332 iterations, i.e. alpha=2.718e+03, with an active set of 231 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 332 iterations, i.e. alpha=2.718e+03, with an active set of 231 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 332 iterations, i.e. alpha=2.715e+03, with an active set of 231 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 332 iterations, i.e. alpha=2.713e+03, with an active set of 231 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 332 iterations, i.e. alpha=2.695e+03, with an active set of 231 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 334 iterations, i.e. alpha=2.489e+03, with an active set of 233 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 334 iterations, i.e. alpha=2.489e+03, with an active set of 233 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 338 iterations, i.e. alpha=2.444e+03, with an active set of 236 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=2.430e+03, with an active set of 239 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=2.430e+03, with an active set of 239 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=2.361e+03, with an active set of 239 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=2.358e+03, with an active set of 239 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=2.311e+03, with an active set of 239 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=2.303e+03, with an active set of 239 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=2.289e+03, with an active set of 239 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 342 iterations, i.e. alpha=2.249e+03, with an active set of 240 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 343 iterations, i.e. alpha=2.212e+03, with an active set of 241 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 343 iterations, i.e. alpha=2.212e+03, with an active set of 241 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 344 iterations, i.e. alpha=2.154e+03, with an active set of 242 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 344 iterations, i.e. alpha=2.141e+03, with an active set of 242 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 344 iterations, i.e. alpha=2.068e+03, with an active set of 242 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 345 iterations, i.e. alpha=2.006e+03, with an active set of 243 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 345 iterations, i.e. alpha=1.973e+03, with an active set of 243 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 345 iterations, i.e. alpha=1.754e+03, with an active set of 243 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 346 iterations, i.e. alpha=1.439e+03, with an active set of 244 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 346 iterations, i.e. alpha=1.382e+03, with an active set of 244 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 352 iterations, i.e. alpha=1.015e+03, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 352 iterations, i.e. alpha=1.014e+03, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 352 iterations, i.e. alpha=1.013e+03, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 352 iterations, i.e. alpha=9.398e+02, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 352 iterations, i.e. alpha=8.633e+02, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=8.347e+02, with an active set of 250 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=7.526e+02, with an active set of 251 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=7.498e+02, with an active set of 251 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=7.229e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=6.991e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=6.177e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=5.801e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=5.739e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=5.565e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=5.452e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=5.378e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=5.116e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=4.245e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=4.051e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.911e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.607e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.606e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.541e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.465e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.412e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.407e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.352e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.351e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.351e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.351e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.350e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.346e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.345e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.344e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.344e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.343e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.341e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.340e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.339e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.338e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.337e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.337e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.337e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.335e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.333e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.332e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.329e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.329e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.326e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.324e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.317e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.310e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.297e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.296e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.243e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.158e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.157e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.153e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=2.928e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=2.913e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=2.741e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=2.711e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=2.608e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=2.587e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=2.585e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=2.575e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=2.573e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=2.569e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=2.555e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=2.311e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=2.301e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=2.297e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=2.291e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=2.262e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=2.186e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=2.039e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=1.973e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=1.801e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=1.750e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=1.746e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=1.739e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=1.723e+02, with an active set of 252 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.618e+01, with an active set of 252 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=7.992e+01, with an active set of 252 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=7.060e+01, with an active set of 252 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=6.845e+01, with an active set of 252 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=6.775e+01, with an active set of 252 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=6.727e+01, with an active set of 252 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=6.204e+01, with an active set of 252 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=5.312e+01, with an active set of 252 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 358 iterations, i.e. alpha=3.506e+01, with an active set of 253 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 358 iterations, i.e. alpha=3.466e+01, with an active set of 253 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=2.142e+01, with an active set of 254 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=1.983e+01, with an active set of 254 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=1.959e+01, with an active set of 254 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=1.958e+01, with an active set of 254 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=1.605e+01, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=1.475e+01, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=1.296e+01, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=1.242e+01, with an active set of 254 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=1.139e+01, with an active set of 254 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=1.102e+01, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=1.031e+01, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=1.018e+01, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.957e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.730e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.635e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.628e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.619e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.614e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.596e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.593e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.560e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.540e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.496e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.481e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.478e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.410e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.408e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.386e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.383e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.376e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.373e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.350e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.334e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.334e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.268e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.263e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.262e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.256e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.244e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.240e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.239e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.217e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.207e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.201e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.197e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.197e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.195e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.189e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.187e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.186e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.185e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.183e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.170e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.170e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.163e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.150e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.123e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.105e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.096e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.076e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=8.971e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=8.743e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=8.691e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=8.537e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=8.510e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=8.487e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=8.152e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=8.055e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=7.339e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=7.301e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=7.272e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=7.198e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=6.597e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=6.498e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=3.845e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=2.875e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=1.319e+00, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 5, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 5, 0, 0, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 3, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 7, 0, 4, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 3, 5, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 6, 7, 0, 0, 6, 6, 0, 0, 0, 7, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       6, 0, 2, 0, 0, 0, 0, 0, 0, 7, 7, 0, 0, 7, 6, 1, 0, 0, 3, 6, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 1, 2, 0, 2, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 2,\n",
       "       0, 1, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 4, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fsfc.generic import MCFS\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('select', MCFS(30,3)),\n",
    "    ('cluster', KMeans())\n",
    "])\n",
    "pipeline.fit_predict(np.array(fin_data.iloc[:,:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>23403</th>\n",
       "      <th>28270</th>\n",
       "      <th>28881</th>\n",
       "      <th>14408</th>\n",
       "      <th>3037</th>\n",
       "      <th>22917</th>\n",
       "      <th>16466</th>\n",
       "      <th>22995</th>\n",
       "      <th>26767</th>\n",
       "      <th>28247</th>\n",
       "      <th>...</th>\n",
       "      <th>12557</th>\n",
       "      <th>20055</th>\n",
       "      <th>2258</th>\n",
       "      <th>3569</th>\n",
       "      <th>12056</th>\n",
       "      <th>13701</th>\n",
       "      <th>26625</th>\n",
       "      <th>491</th>\n",
       "      <th>22790</th>\n",
       "      <th>9584</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>459 rows × 369 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     23403  28270  28881  14408  3037  22917  16466  22995  26767  28247  ...  \\\n",
       "0        3      4      4      4     4      3      4      1      2      1  ...   \n",
       "1        3      4      4      4     4      3      4      1      2      1  ...   \n",
       "2        3      4      4      4     4      3      4      1      2      1  ...   \n",
       "3        3      4      4      4     4      3      4      1      2      1  ...   \n",
       "4        3      4      4      4     4      3      4      1      0      1  ...   \n",
       "..     ...    ...    ...    ...   ...    ...    ...    ...    ...    ...  ...   \n",
       "279      3      4      4      4     4      3      4      1      2      1  ...   \n",
       "280      3      4      4      4     4      3      4      1      2      1  ...   \n",
       "281      3      4      4      4     4      3      4      1      2      1  ...   \n",
       "282      3      4      4      4     4      3      4      1      2      1  ...   \n",
       "283      3      4      4      4     4      3      4      1      2      1  ...   \n",
       "\n",
       "     12557  20055  2258  3569  12056  13701  26625  491  22790  9584  \n",
       "0        0      0     0     0      0      0      0    0      0     0  \n",
       "1        0      0     0     0      0      0      0    0      0     0  \n",
       "2        0      0     0     0      0      0      0    0      0     0  \n",
       "3        0      0     0     0      0      0      0    0      0     0  \n",
       "4        0      0     0     0      0      0      0    0      0     0  \n",
       "..     ...    ...   ...   ...    ...    ...    ...  ...    ...   ...  \n",
       "279      0      0     0     0      0      0      0    0      0     0  \n",
       "280      0      0     0     0      0      0      0    0      0     0  \n",
       "281      0      0     0     0      0      0      0    0      0     0  \n",
       "282      0      0     0     0      0      0      0    0      0     0  \n",
       "283      0      0     0     0      0      0      0    0      0     0  \n",
       "\n",
       "[459 rows x 369 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_data.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.384e-05, with an active set of 11 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.384e-05, with an active set of 11 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=4.886e-05, with an active set of 13 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=4.885e-05, with an active set of 14 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=4.314e-05, with an active set of 23 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=3.952e-05, with an active set of 24 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=3.952e-05, with an active set of 24 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=3.952e-05, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=3.588e-05, with an active set of 25 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=2.990e-05, with an active set of 27 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=2.820e-05, with an active set of 30 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=2.389e-05, with an active set of 35 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=2.208e-05, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=2.135e-05, with an active set of 37 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=2.055e-05, with an active set of 37 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.892e-05, with an active set of 39 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.802e-05, with an active set of 41 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.494e-05, with an active set of 46 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.494e-05, with an active set of 46 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=1.310e-05, with an active set of 48 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=1.310e-05, with an active set of 48 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=1.252e-05, with an active set of 51 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=9.143e-06, with an active set of 66 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=9.143e-06, with an active set of 66 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=9.011e-06, with an active set of 66 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=8.826e-06, with an active set of 67 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=8.125e-06, with an active set of 73 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=7.742e-06, with an active set of 76 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=7.742e-06, with an active set of 76 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=7.742e-06, with an active set of 76 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=7.559e-06, with an active set of 81 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 83 iterations, i.e. alpha=7.463e-06, with an active set of 83 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 87 iterations, i.e. alpha=7.324e-06, with an active set of 86 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=7.012e-06, with an active set of 88 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=7.012e-06, with an active set of 88 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 92 iterations, i.e. alpha=6.706e-06, with an active set of 91 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=6.372e-06, with an active set of 95 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=6.372e-06, with an active set of 95 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 97 iterations, i.e. alpha=6.246e-06, with an active set of 96 regressors, and the smallest cholesky pivot element being 9.125e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=6.129e-06, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=5.504e-06, with an active set of 121 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 141 iterations, i.e. alpha=5.270e-06, with an active set of 133 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 141 iterations, i.e. alpha=5.222e-06, with an active set of 133 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 141 iterations, i.e. alpha=5.153e-06, with an active set of 133 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 141 iterations, i.e. alpha=5.134e-06, with an active set of 133 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 141 iterations, i.e. alpha=5.134e-06, with an active set of 133 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 144 iterations, i.e. alpha=5.022e-06, with an active set of 135 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=4.708e-06, with an active set of 154 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=4.654e-06, with an active set of 158 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 178 iterations, i.e. alpha=4.506e-06, with an active set of 165 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 178 iterations, i.e. alpha=4.506e-06, with an active set of 165 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 178 iterations, i.e. alpha=4.473e-06, with an active set of 165 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 182 iterations, i.e. alpha=4.447e-06, with an active set of 169 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 182 iterations, i.e. alpha=4.415e-06, with an active set of 169 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 182 iterations, i.e. alpha=4.396e-06, with an active set of 169 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 184 iterations, i.e. alpha=4.362e-06, with an active set of 170 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 267 iterations, i.e. alpha=2.321e-03, with an active set of 211 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 268 iterations, i.e. alpha=2.317e-03, with an active set of 212 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 329 iterations, i.e. alpha=6.506e+00, with an active set of 238 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 335 iterations, i.e. alpha=5.858e+00, with an active set of 242 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 336 iterations, i.e. alpha=5.853e+00, with an active set of 243 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 336 iterations, i.e. alpha=5.851e+00, with an active set of 243 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 336 iterations, i.e. alpha=5.832e+00, with an active set of 243 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 336 iterations, i.e. alpha=5.780e+00, with an active set of 243 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 338 iterations, i.e. alpha=5.519e+00, with an active set of 244 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 338 iterations, i.e. alpha=5.322e+00, with an active set of 244 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 338 iterations, i.e. alpha=5.251e+00, with an active set of 244 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 344 iterations, i.e. alpha=1.086e+01, with an active set of 246 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 344 iterations, i.e. alpha=7.435e+00, with an active set of 246 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 344 iterations, i.e. alpha=6.834e+00, with an active set of 246 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 345 iterations, i.e. alpha=5.076e+00, with an active set of 247 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 345 iterations, i.e. alpha=5.074e+00, with an active set of 247 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 345 iterations, i.e. alpha=4.810e+00, with an active set of 247 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 345 iterations, i.e. alpha=4.675e+00, with an active set of 247 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 345 iterations, i.e. alpha=4.617e+00, with an active set of 247 regressors, and the smallest cholesky pivot element being 9.657e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 347 iterations, i.e. alpha=4.325e+00, with an active set of 248 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 347 iterations, i.e. alpha=4.324e+00, with an active set of 248 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 347 iterations, i.e. alpha=4.227e+00, with an active set of 248 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 347 iterations, i.e. alpha=4.219e+00, with an active set of 248 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=4.085e+00, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=3.962e+00, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=3.918e+00, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=3.906e+00, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=3.885e+00, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=3.878e+00, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=3.864e+00, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=3.863e+00, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=3.860e+00, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=3.837e+00, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=3.836e+00, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=3.833e+00, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=3.804e+00, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=3.802e+00, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=3.798e+00, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=3.793e+00, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=3.789e+00, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=3.788e+00, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=3.786e+00, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=3.784e+00, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=3.783e+00, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=3.781e+00, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=3.779e+00, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=3.774e+00, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=3.770e+00, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=3.768e+00, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=3.761e+00, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=3.757e+00, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=3.755e+00, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=3.754e+00, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=3.744e+00, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=3.726e+00, with an active set of 249 regressors, and the smallest cholesky pivot element being 9.657e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=3.720e+00, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=3.714e+00, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=3.713e+00, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=3.670e+00, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=3.654e+00, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=3.646e+00, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=3.572e+00, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=3.546e+00, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=3.531e+00, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=3.517e+00, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=3.509e+00, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=3.493e+00, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 349 iterations, i.e. alpha=3.467e+00, with an active set of 250 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 349 iterations, i.e. alpha=3.449e+00, with an active set of 250 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 349 iterations, i.e. alpha=3.438e+00, with an active set of 250 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 349 iterations, i.e. alpha=3.400e+00, with an active set of 250 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 349 iterations, i.e. alpha=3.259e+00, with an active set of 250 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 349 iterations, i.e. alpha=3.233e+00, with an active set of 250 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 349 iterations, i.e. alpha=3.232e+00, with an active set of 250 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 349 iterations, i.e. alpha=2.634e+00, with an active set of 250 regressors, and the smallest cholesky pivot element being 9.541e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 349 iterations, i.e. alpha=2.130e+00, with an active set of 250 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 349 iterations, i.e. alpha=2.112e+00, with an active set of 250 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 349 iterations, i.e. alpha=2.061e+00, with an active set of 250 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 349 iterations, i.e. alpha=1.957e+00, with an active set of 250 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=1.868e+00, with an active set of 251 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=1.867e+00, with an active set of 251 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=1.621e+00, with an active set of 251 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=1.609e+00, with an active set of 251 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=1.604e+00, with an active set of 251 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=1.513e+00, with an active set of 251 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=1.361e+00, with an active set of 251 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 352 iterations, i.e. alpha=1.217e+00, with an active set of 252 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 352 iterations, i.e. alpha=1.211e+00, with an active set of 252 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 352 iterations, i.e. alpha=1.066e+00, with an active set of 252 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 352 iterations, i.e. alpha=9.078e-01, with an active set of 252 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 352 iterations, i.e. alpha=8.724e-01, with an active set of 252 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 352 iterations, i.e. alpha=8.721e-01, with an active set of 252 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=7.260e-01, with an active set of 253 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=6.015e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 9.541e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=4.212e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=4.120e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=3.891e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=3.719e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=3.125e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=2.968e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=2.766e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=2.475e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 9.657e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=2.370e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=2.291e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=2.289e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=2.271e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=2.165e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=2.105e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=2.099e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=2.033e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=2.032e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=2.031e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=2.027e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=2.004e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=2.000e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.941e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.937e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.935e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.934e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.913e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.912e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.909e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.905e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.898e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.894e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.892e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.887e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.884e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.882e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.881e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.880e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.877e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.870e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.863e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.852e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.850e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.846e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.844e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.839e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.839e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.829e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.825e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.802e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.790e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.789e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.787e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.762e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.756e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.754e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.750e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.729e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.711e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.706e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.665e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.647e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.639e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.638e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.631e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.626e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.626e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.528e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.527e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.504e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.472e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.465e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.116e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.113e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.066e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.062e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.029e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.027e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=1.026e-01, with an active set of 254 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=9.185e-02, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=5.426e-02, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=4.676e-02, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=3.720e-02, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=3.464e-02, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=2.516e-02, with an active set of 254 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.179e-04, with an active set of 7 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.748e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.246e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.246e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.127e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.102e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.053e-04, with an active set of 18 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.053e-04, with an active set of 18 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=8.830e-05, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=7.551e-05, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=7.312e-05, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=6.962e-05, with an active set of 34 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=6.962e-05, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=6.885e-05, with an active set of 35 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=6.335e-05, with an active set of 38 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=5.976e-05, with an active set of 43 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=5.425e-05, with an active set of 49 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=5.305e-05, with an active set of 51 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=4.933e-05, with an active set of 55 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=1.066e-04, with an active set of 90 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=9.528e-05, with an active set of 112 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=9.528e-05, with an active set of 112 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 136 iterations, i.e. alpha=9.492e-05, with an active set of 113 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 138 iterations, i.e. alpha=9.448e-05, with an active set of 115 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 149 iterations, i.e. alpha=1.083e-04, with an active set of 122 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=1.002e-04, with an active set of 127 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 158 iterations, i.e. alpha=1.002e-04, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=9.782e-05, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=9.699e-05, with an active set of 132 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=9.682e-05, with an active set of 132 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 162 iterations, i.e. alpha=9.558e-05, with an active set of 133 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 178 iterations, i.e. alpha=3.476e-04, with an active set of 138 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 187 iterations, i.e. alpha=3.070e-04, with an active set of 146 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 197 iterations, i.e. alpha=2.869e-04, with an active set of 155 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 215 iterations, i.e. alpha=2.791e-04, with an active set of 171 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 215 iterations, i.e. alpha=2.791e-04, with an active set of 171 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 215 iterations, i.e. alpha=2.791e-04, with an active set of 171 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 246 iterations, i.e. alpha=5.720e-04, with an active set of 193 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 270 iterations, i.e. alpha=1.876e-03, with an active set of 201 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 310 iterations, i.e. alpha=5.382e-02, with an active set of 219 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 342 iterations, i.e. alpha=9.607e-01, with an active set of 231 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 342 iterations, i.e. alpha=9.607e-01, with an active set of 231 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 343 iterations, i.e. alpha=8.752e-01, with an active set of 232 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 343 iterations, i.e. alpha=8.053e-01, with an active set of 232 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 343 iterations, i.e. alpha=7.891e-01, with an active set of 232 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 343 iterations, i.e. alpha=7.889e-01, with an active set of 232 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 346 iterations, i.e. alpha=7.502e-01, with an active set of 235 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=7.469e-01, with an active set of 239 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=7.445e-01, with an active set of 240 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=7.445e-01, with an active set of 240 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=6.843e-01, with an active set of 240 regressors, and the smallest cholesky pivot element being 8.941e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 352 iterations, i.e. alpha=6.162e-01, with an active set of 241 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=5.194e-01, with an active set of 243 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=5.148e-01, with an active set of 244 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=4.942e-01, with an active set of 244 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=4.718e-01, with an active set of 244 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=4.717e-01, with an active set of 244 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=4.295e-01, with an active set of 244 regressors, and the smallest cholesky pivot element being 9.884e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=4.231e-01, with an active set of 244 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=4.143e-01, with an active set of 244 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.862e-01, with an active set of 244 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.852e-01, with an active set of 244 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.851e-01, with an active set of 244 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.848e-01, with an active set of 244 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.839e-01, with an active set of 244 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.838e-01, with an active set of 244 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.838e-01, with an active set of 244 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.838e-01, with an active set of 244 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.837e-01, with an active set of 244 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.837e-01, with an active set of 244 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.837e-01, with an active set of 244 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.836e-01, with an active set of 244 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.836e-01, with an active set of 244 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.835e-01, with an active set of 244 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.835e-01, with an active set of 244 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.834e-01, with an active set of 244 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.833e-01, with an active set of 244 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.833e-01, with an active set of 244 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.833e-01, with an active set of 244 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.833e-01, with an active set of 244 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.830e-01, with an active set of 244 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.824e-01, with an active set of 244 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.822e-01, with an active set of 244 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.778e-01, with an active set of 244 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.772e-01, with an active set of 244 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.771e-01, with an active set of 244 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.762e-01, with an active set of 244 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.737e-01, with an active set of 244 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.696e-01, with an active set of 244 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.695e-01, with an active set of 244 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=3.491e-01, with an active set of 244 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=3.413e-01, with an active set of 245 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=3.347e-01, with an active set of 245 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=3.286e-01, with an active set of 245 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=3.156e-01, with an active set of 245 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=2.989e-01, with an active set of 245 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=2.953e-01, with an active set of 245 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=2.938e-01, with an active set of 245 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=2.919e-01, with an active set of 245 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=2.917e-01, with an active set of 245 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=2.915e-01, with an active set of 245 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=2.863e-01, with an active set of 245 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 358 iterations, i.e. alpha=2.565e-01, with an active set of 246 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 358 iterations, i.e. alpha=2.565e-01, with an active set of 246 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=2.281e-01, with an active set of 247 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=2.193e-01, with an active set of 247 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=2.076e-01, with an active set of 247 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=1.419e-01, with an active set of 247 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=1.045e-01, with an active set of 247 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=1.041e-01, with an active set of 247 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=1.040e-01, with an active set of 247 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.910e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.570e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.375e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 8.941e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.352e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.346e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.341e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=9.328e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=8.764e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=6.148e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=5.976e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=5.461e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=5.439e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=5.323e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=3.787e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=3.462e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=3.376e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=3.073e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=2.995e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=2.881e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=2.766e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=2.761e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=2.745e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=2.740e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=2.739e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=2.738e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=2.738e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=2.737e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=2.737e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=2.736e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=2.735e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=2.734e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=2.734e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=2.733e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=2.733e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=2.733e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=2.732e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=2.732e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=2.731e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=2.731e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=2.731e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=2.730e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=2.730e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=2.727e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=2.726e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=2.726e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=2.654e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=2.600e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=1.976e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=1.976e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=1.973e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=1.965e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=1.944e-02, with an active set of 247 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=1.613e-02, with an active set of 249 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=1.608e-02, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=1.605e-02, with an active set of 249 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=1.442e-02, with an active set of 249 regressors, and the smallest cholesky pivot element being 9.884e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=1.389e-02, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=1.115e-02, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=8.799e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=8.794e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=8.789e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=7.965e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=7.210e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=6.401e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=6.243e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=5.971e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=5.560e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 8.941e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=4.600e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=3.200e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=2.934e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=2.857e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=2.746e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=2.550e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=2.527e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=2.508e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=2.374e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=2.370e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=2.321e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=2.319e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=2.317e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=2.317e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=2.316e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=2.316e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=2.315e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=2.315e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=2.314e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=2.314e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=2.314e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=2.313e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=2.313e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=2.313e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=2.313e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=2.312e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=2.312e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=2.311e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=2.311e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=2.311e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=2.310e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=2.310e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=2.310e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=2.309e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=2.309e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=2.309e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=2.308e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=2.308e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=2.307e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=2.304e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=2.303e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=2.267e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=2.102e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=1.270e-03, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=3.852e-04, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=1.277e-04, with an active set of 249 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=3.404e-05, with an active set of 8 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.914e-05, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.874e-05, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.874e-05, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.703e-05, with an active set of 24 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.593e-05, with an active set of 25 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=1.486e-05, with an active set of 27 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.249e-05, with an active set of 37 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=1.146e-05, with an active set of 43 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=9.809e-06, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=9.656e-06, with an active set of 58 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=9.655e-06, with an active set of 59 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=9.655e-06, with an active set of 59 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=9.554e-06, with an active set of 59 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=9.954e-06, with an active set of 67 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=9.775e-06, with an active set of 67 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=9.475e-06, with an active set of 71 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 114 iterations, i.e. alpha=7.034e-06, with an active set of 89 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 122 iterations, i.e. alpha=6.628e-06, with an active set of 96 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 122 iterations, i.e. alpha=6.628e-06, with an active set of 96 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 122 iterations, i.e. alpha=6.628e-06, with an active set of 96 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=6.425e-06, with an active set of 102 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 168 iterations, i.e. alpha=6.316e-06, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 168 iterations, i.e. alpha=6.315e-06, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 168 iterations, i.e. alpha=6.315e-06, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 168 iterations, i.e. alpha=6.315e-06, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 198 iterations, i.e. alpha=4.056e-05, with an active set of 115 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 230 iterations, i.e. alpha=4.451e-05, with an active set of 140 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 236 iterations, i.e. alpha=4.305e-05, with an active set of 145 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 238 iterations, i.e. alpha=4.249e-05, with an active set of 147 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 252 iterations, i.e. alpha=4.039e-05, with an active set of 158 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 282 iterations, i.e. alpha=4.679e-05, with an active set of 180 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 282 iterations, i.e. alpha=4.679e-05, with an active set of 180 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 282 iterations, i.e. alpha=4.679e-05, with an active set of 180 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=4.664e-05, with an active set of 181 regressors, and the smallest cholesky pivot element being 8.363e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=4.560e-05, with an active set of 182 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 284 iterations, i.e. alpha=4.498e-05, with an active set of 182 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 295 iterations, i.e. alpha=4.155e-05, with an active set of 190 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 305 iterations, i.e. alpha=1.177e-04, with an active set of 194 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 389 iterations, i.e. alpha=7.691e-02, with an active set of 225 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.888e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.837e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.726e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.720e-02, with an active set of 230 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 397 iterations, i.e. alpha=6.158e-02, with an active set of 233 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 411 iterations, i.e. alpha=2.085e-01, with an active set of 241 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 411 iterations, i.e. alpha=1.809e-01, with an active set of 241 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 412 iterations, i.e. alpha=1.178e-01, with an active set of 242 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 417 iterations, i.e. alpha=1.153e-01, with an active set of 247 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 417 iterations, i.e. alpha=1.152e-01, with an active set of 247 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 417 iterations, i.e. alpha=1.059e-01, with an active set of 247 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 421 iterations, i.e. alpha=1.025e-01, with an active set of 249 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 421 iterations, i.e. alpha=1.024e-01, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 421 iterations, i.e. alpha=1.023e-01, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 421 iterations, i.e. alpha=9.106e-02, with an active set of 249 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 421 iterations, i.e. alpha=8.482e-02, with an active set of 249 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 421 iterations, i.e. alpha=8.481e-02, with an active set of 249 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 421 iterations, i.e. alpha=8.477e-02, with an active set of 249 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 421 iterations, i.e. alpha=8.340e-02, with an active set of 249 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 421 iterations, i.e. alpha=8.339e-02, with an active set of 249 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 421 iterations, i.e. alpha=8.336e-02, with an active set of 249 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 421 iterations, i.e. alpha=7.700e-02, with an active set of 249 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 422 iterations, i.e. alpha=5.691e-02, with an active set of 250 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 422 iterations, i.e. alpha=5.687e-02, with an active set of 250 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 422 iterations, i.e. alpha=5.448e-02, with an active set of 250 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 422 iterations, i.e. alpha=4.770e-02, with an active set of 250 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 422 iterations, i.e. alpha=4.712e-02, with an active set of 250 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 422 iterations, i.e. alpha=4.697e-02, with an active set of 250 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 422 iterations, i.e. alpha=4.694e-02, with an active set of 250 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 422 iterations, i.e. alpha=4.638e-02, with an active set of 250 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 422 iterations, i.e. alpha=4.589e-02, with an active set of 250 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=4.577e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=4.470e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=4.166e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=4.145e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=3.989e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=3.940e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=3.791e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=3.782e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=3.712e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=3.710e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=3.709e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=3.708e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=3.708e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=3.708e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=3.706e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=3.683e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=3.683e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=3.658e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=3.644e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=3.580e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=3.545e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=3.535e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=3.466e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=3.447e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=3.446e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=3.411e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=3.401e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=3.400e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=3.399e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=3.376e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=3.366e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=3.344e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=3.331e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=3.272e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=3.264e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=3.249e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=3.245e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=3.243e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=3.201e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=3.108e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=3.104e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=3.076e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=3.007e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=2.948e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=2.917e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=2.858e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=2.786e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=2.570e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=2.525e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=2.524e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 423 iterations, i.e. alpha=2.519e-02, with an active set of 251 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 425 iterations, i.e. alpha=2.422e-02, with an active set of 253 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 425 iterations, i.e. alpha=2.350e-02, with an active set of 253 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 425 iterations, i.e. alpha=2.219e-02, with an active set of 253 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 425 iterations, i.e. alpha=1.872e-02, with an active set of 253 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 425 iterations, i.e. alpha=1.772e-02, with an active set of 253 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 425 iterations, i.e. alpha=1.623e-02, with an active set of 253 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 425 iterations, i.e. alpha=1.490e-02, with an active set of 253 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 425 iterations, i.e. alpha=1.420e-02, with an active set of 253 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 425 iterations, i.e. alpha=1.395e-02, with an active set of 253 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 425 iterations, i.e. alpha=1.237e-02, with an active set of 253 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 425 iterations, i.e. alpha=1.156e-02, with an active set of 253 regressors, and the smallest cholesky pivot element being 8.560e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 425 iterations, i.e. alpha=9.987e-03, with an active set of 253 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 426 iterations, i.e. alpha=9.492e-03, with an active set of 254 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 426 iterations, i.e. alpha=9.414e-03, with an active set of 254 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 426 iterations, i.e. alpha=8.350e-03, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 426 iterations, i.e. alpha=8.073e-03, with an active set of 254 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 426 iterations, i.e. alpha=7.108e-03, with an active set of 254 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 426 iterations, i.e. alpha=6.385e-03, with an active set of 254 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 427 iterations, i.e. alpha=5.882e-03, with an active set of 255 regressors, and the smallest cholesky pivot element being 8.560e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 427 iterations, i.e. alpha=5.651e-03, with an active set of 255 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 427 iterations, i.e. alpha=5.550e-03, with an active set of 255 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 427 iterations, i.e. alpha=5.522e-03, with an active set of 255 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 427 iterations, i.e. alpha=5.323e-03, with an active set of 255 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 427 iterations, i.e. alpha=5.281e-03, with an active set of 255 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 427 iterations, i.e. alpha=5.246e-03, with an active set of 255 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 427 iterations, i.e. alpha=5.237e-03, with an active set of 255 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 427 iterations, i.e. alpha=4.782e-03, with an active set of 255 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 427 iterations, i.e. alpha=4.091e-03, with an active set of 255 regressors, and the smallest cholesky pivot element being 8.560e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 427 iterations, i.e. alpha=3.426e-03, with an active set of 255 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 427 iterations, i.e. alpha=3.128e-03, with an active set of 255 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 427 iterations, i.e. alpha=3.064e-03, with an active set of 255 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 427 iterations, i.e. alpha=3.061e-03, with an active set of 255 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 427 iterations, i.e. alpha=2.980e-03, with an active set of 255 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 427 iterations, i.e. alpha=2.933e-03, with an active set of 255 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 427 iterations, i.e. alpha=2.896e-03, with an active set of 255 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 427 iterations, i.e. alpha=2.322e-03, with an active set of 255 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 427 iterations, i.e. alpha=2.313e-03, with an active set of 255 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=1.957e-03, with an active set of 256 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=1.699e-03, with an active set of 256 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=1.671e-03, with an active set of 256 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=1.650e-03, with an active set of 256 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=1.635e-03, with an active set of 256 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=1.614e-03, with an active set of 256 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=1.609e-03, with an active set of 256 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=1.455e-03, with an active set of 256 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=1.436e-03, with an active set of 256 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=1.340e-03, with an active set of 256 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=1.331e-03, with an active set of 256 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=1.327e-03, with an active set of 256 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=1.259e-03, with an active set of 256 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=1.250e-03, with an active set of 256 regressors, and the smallest cholesky pivot element being 8.560e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=1.246e-03, with an active set of 256 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=1.194e-03, with an active set of 256 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=1.193e-03, with an active set of 256 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=1.191e-03, with an active set of 256 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=1.155e-03, with an active set of 256 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=1.097e-03, with an active set of 256 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=1.088e-03, with an active set of 256 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=1.081e-03, with an active set of 256 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=1.076e-03, with an active set of 256 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=1.059e-03, with an active set of 256 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=1.029e-03, with an active set of 256 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=1.025e-03, with an active set of 256 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=9.848e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=9.677e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=9.597e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=9.558e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=9.558e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=9.553e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=9.485e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=9.395e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=9.325e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=8.988e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=8.842e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=8.652e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=8.606e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=8.557e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=8.521e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=8.489e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=8.414e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=8.407e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=8.334e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=8.316e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=8.246e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=8.026e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=7.954e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=7.829e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 8.560e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=7.756e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=7.705e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=7.479e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=7.154e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=7.135e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=7.120e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 8.229e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=6.945e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=6.801e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=6.757e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=6.606e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=6.542e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=6.239e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=6.113e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=4.837e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=4.139e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=3.386e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=3.180e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=3.058e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=3.019e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=2.674e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=2.447e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=2.263e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=2.240e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=1.957e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 8.297e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=1.713e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=1.590e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=1.590e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=1.529e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=1.089e-04, with an active set of 256 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=4.893e-05, with an active set of 256 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n"
     ]
    }
   ],
   "source": [
    "x = np.array(fin_data.iloc[:,:-1])\n",
    "clusters = 3\n",
    "p=10\n",
    "sigma=2\n",
    "mode='default'\n",
    "alpha=0.001\n",
    "\n",
    "def create_regressor(mode,alpha):\n",
    "    if mode == 'default':\n",
    "        return Lars()\n",
    "    if mode == 'lasso':\n",
    "        return LassoLars(alpha=alpha)\n",
    "    raise ValueError('Unexpected mode ' + mode + '. Expected \"default\" or \"lasso\"')\n",
    "\n",
    "graph = kneighbors_graph(\n",
    "            x,\n",
    "            n_neighbors=p,\n",
    "        )\n",
    "        # Construct the heat matrix\n",
    "w = np.zeros([x.shape[0], x.shape[0]])\n",
    "rows, cols = graph.nonzero()\n",
    "for i, j in zip(rows, cols):\n",
    "    w[i, j] = math.exp(-np.linalg.norm(x[i] - x[j])**2/sigma)\n",
    "\n",
    "# Compute degree and Laplacian matrices\n",
    "degree_vector = np.sum(w, 1)\n",
    "degree = np.diag(degree_vector)\n",
    "laplacian = degree - w\n",
    "\n",
    "# Solve the eigen-problem\n",
    "values, vectors = eigh(laplacian, degree)\n",
    "smallest = vectors[:, 0:clusters].T\n",
    "\n",
    "# Find coefficients for each cluster\n",
    "coefs = []\n",
    "for i in range(clusters):\n",
    "    this_coefs = create_regressor(mode,alpha).fit(x, smallest[i]).coef_\n",
    "    coefs.append(this_coefs)\n",
    "coefs = np.array(coefs)\n",
    "\n",
    "# Compute MCFS-scores\n",
    "scores = np.max(coefs, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8     -1.552329e+05\n",
       "142   -9.637497e+04\n",
       "6     -7.058406e+04\n",
       "26    -5.759574e+04\n",
       "11    -5.072211e+04\n",
       "           ...     \n",
       "333    9.113302e+16\n",
       "84     1.837361e+17\n",
       "163    3.063291e+17\n",
       "109    1.162396e+18\n",
       "273    2.324793e+18\n",
       "Length: 369, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(scores).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[31,\n",
       " 47,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 58,\n",
       " 65,\n",
       " 86,\n",
       " 121,\n",
       " 133,\n",
       " 151,\n",
       " 295,\n",
       " 328,\n",
       " 343,\n",
       " 346,\n",
       " 347,\n",
       " 353,\n",
       " 356,\n",
       " 363,\n",
       " 364,\n",
       " 365,\n",
       " 368]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_mutations = [22028,22029.22030,23402,23403,23404,28143,28144,28145,25468,25469,25470,23603,23604,23605,14381,14382,14383,26766,26767,26768,16439,16440,\n",
    "16441,28880,28881,28882,21617,21618,21619,29402,29403,29404,15425,15426,15427,22994,22995,22996,28460,28461,28462,22916,22917,22918,24410,\n",
    "24411,24412,27751,27752,27753,27637,27638,27639,10028,10029,10030,11201,11202,11203,19193,19194,19195,4181,4182,4183,9053,9054,9055,28916,\n",
    "28917,28918,27873,27874,27875,6401,6402,6403,7124,7125,7126]\n",
    "\n",
    "\n",
    "fea_name = []\n",
    "sel_fea = list(pd.Series(scores).sort_values( ascending=False).index[:])\n",
    "for i in sel_fea:\n",
    "    fea_name.append(list(fin_data.iloc[:,:-1].columns)[i])\n",
    "rank_def = []\n",
    "sel_def = []\n",
    "for i in range(len(fea_name)):\n",
    "    if int(fea_name[i]) in def_mutations:\n",
    "        rank_def.append(i)\n",
    "        sel_def.append(fea_name[i])\n",
    "rank_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'28145'in list(fin_data.iloc[:,:-1].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['22995',\n",
       " '28881',\n",
       " '22917',\n",
       " '9053',\n",
       " '27874',\n",
       " '23604',\n",
       " '27638',\n",
       " '25469',\n",
       " '29402',\n",
       " '7124',\n",
       " '22028',\n",
       " '23403',\n",
       " '28461',\n",
       " '24410',\n",
       " '6402',\n",
       " '28916',\n",
       " '4181',\n",
       " '21618',\n",
       " '10029',\n",
       " '27752',\n",
       " '11201',\n",
       " '26767']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_name = []\n",
    "sel_fea = list(pd.Series(scores).sort_values().index[:10])\n",
    "for i in range(len(list(fin_data.columns))):\n",
    "    if i in sel_fea:\n",
    "        fea_name.append(list(fin_data.columns)[i])\n",
    "sel_data = fin_data[fea_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10029\n",
      "11201\n",
      "22792\n"
     ]
    }
   ],
   "source": [
    "fea_name\n",
    "for i in fea_name:\n",
    "    if i in sl:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJEAAAJcCAYAAABJ6DXiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABjQklEQVR4nOzde5SdZXn///dHAionsTJ4IMGggjYqBN1FLKIIiogWPBe+ilIPKQoVFE+oxVP9fRUUD7XVpoDabyNqOVhEEahS0SronhAISRARURKiGQHlpEDg+v2xn7HbYcKezN6TyeH9WmuvPM91H57roWuWXde67/tJVSFJkiRJkiTdnwdMdwKSJEmSJEla/1lEkiRJkiRJUk8WkSRJkiRJktSTRSRJkiRJkiT1ZBFJkiRJkiRJPVlEkiRJkiRJUk8WkSRJkiRJktSTRSRJkrROJbkuye+T3Nb1e9QA5nzOoHKcwPPen+Tf19Xz7k+SI5J8f7rzkCRJGz+LSJIkaTr8VVVt3fW7YTqTSTJjOp8/WRtq3pIkacNkEUmSJK0XkjwkyalJViZZkeQfkmzWtD02yXeS3JjkN0kWJNmuaft/wE7A15tVTe9Ism+S5WPm/+NqpWYl0RlJ/j3JLcAR9/f8CeReSd6U5KdJbk3yoSbnHyS5JclXk2zR9N03yfIk727e5bokrxzz3+Hfkowk+UWS9yZ5QNN2RJL/SfKJJDcCXwE+Bzy9efffNv1ekOSy5tnXJ3l/1/yzm3xfk+SXTQ7v6WrfrMntZ827DCeZ1bQ9IcmFSW5K8pMkr+gad1CSpc2YFUneNsH/00uSpA2ERSRJkrS++AKwGngcsAdwAPD6pi3A/wUeBfw5MAt4P0BVHQ78kv9d3XTiBJ93CHAGsB2woMfzJ+J5wFOBvYB3APOBVzW5Pgk4rKvvI4DtgR2B1wDzkzy+aftH4CHAY4BnAa8G/qZr7NOAa4GHN/MfCfywefftmj63N+O2A14AvDHJi8bk+wzg8cD+wAlJ/ryJv7XJ9SBgW+C1wB1JtgIuBL4E7AAcCvxzkjnNuFOBv62qbZr3/U7v/2SSJGlDYhFJkiRNh68l+W3z+1qSh9MpWhxbVbdX1SrgE3QKFVTVNVV1YVXdWVUjwMl0Ciz9+GFVfa2q7qVTLFnj8yfoxKq6paqWAFcCF1TVtVX1O+A8OoWpbn/fvM93gW8Ar2hWPh0KHF9Vt1bVdcDHgcO7xt1QVf9YVaur6vfjJVJV/11Vi6vq3qq6Ajid+/73+kBV/b6qLgcuB3Zv4q8H3ltVP6mOy6vqRuCFwHVV9fnm2ZcBZwIvb8bdDcxJsm1V3VxVC9fiv50kSdoAuI9ekiRNhxdV1X+N3iTZE9gcWJlkNPwA4Pqm/eHAp4B9gG2atpv7zOH6rutH39/zJ+jXXde/H+f+EV33N1fV7V33v6Czymr7Jo9fjGnbcQ15jyvJ04CP0FkRtAXwQOA/xnT7Vdf1HcDWzfUs4GfjTPto4GmjW+YaM4D/11y/FHgv8JEkVwDvqqof9spVkiRtOFyJJEmS1gfXA3cC21fVds1v26p6YtP+/wEFPLmqtqWzjStd42vMfLcDW47eNCt8hsb06R7T6/mD9tBme9ionYAbgN/QWdHz6DFtK9aQ93j30Nlydg4wq6oeQufcpIzTbzzXA49dQ/y7Xf99tmu20L0RoKp+XFWH0Nnq9jXgqxN8niRJ2kBYRJIkSdOuqlYCFwAfT7Jtkgc0B1OPbsHaBrgN+F2SHYG3j5ni13TOEBp1NfCg5oDpzemskHlgH8+fCh9IskWSfehsFfuPqrqHTvHlw0m2SfJoOmcU/fv9zPNrYObowd2NbYCbquoPzSqv/7MWeZ0CfCjJLunYLcnDgHOBXZMcnmTz5vcXSf68eY9XJnlIVd0N3ALcuxbPlCRJGwCLSJIkaX3xajpbr5bS2ap2BvDIpu0DwFOA39E5P+isMWP/L/De5oyltzXnEL2JTkFkBZ2VScu5f/f3/EH7VfOMG+gc6n1kVV3VtP0dnXyvBb5PZ1XRafcz13eAJcCvkvymib0J+GCSW4ETWLtVQSc3/S+gUww6FXhwVd1K57DxQ5u8fwV8lP8tzh0OXNd87e5I4JVIkqSNSqrGWwEtSZKkqZBkX+Dfq2rmNKciSZK0VlyJJEmSJEmSpJ4sIkmSJEmSJKknt7NJkiRJkiSpJ1ciSZIkSZIkqacZ053AZG2//fY1e/bs6U5DkiRJkiRpozE8PPybqhoar22DLSLNnj2bdrs93WlIkiRJkiRtNJL8Yk1tbmeTJEmSJElSTxaRJEmSJEmS1JNFJEmSJEmSJPVkEUmSJEmSJEk9WUSSJEmSJElSTxaRJEmSJEmS1JNFJEmSJEmSJPVkEUmSJEmSJEk9WUSSJEmSJElSTxaRJEmSJEmS1JNFJEmSJEmSJPVkEUmSJEmSJEk9WUSSJEmSJElSTxaRJEmSJEmS1JNFJEmSJEmSJPVkEUmSJEmSJEk9WUSSJEmSJElSTxaRJEmSJEmS1JNFJEmSJEmSJPVkEUmSJEmSJEk9WUSSJEmSJElSTxaRJEmSJEmS1JNFJEmSJEmSJPU0Y7oTmKzhYUimOwtJkiRJkrSpqpruDNYtVyJJkiRJkiSpp76KSElmJbkoydIkS5Ic08R3T/LDJIuTfD3JtmPG7ZTktiRvGxPfLMllSc7tJy9JkiRJkiQNVr8rkVYDx1XVHGAv4Kgkc4BTgHdV1ZOBs4G3jxl3MnDeOPMdAyzrMydJkiRJkiQNWF9FpKpaWVULm+tb6RSAdgR2BS5uul0IvHR0TJIXAT8HlnTPlWQm8AI6BShJkiRJkiStRwZ2JlKS2cAewKV0CkSHNE0vB2Y1fbYG3gl8YJwpPgm8A7j3fp4xL0k7SRtGBpW6JEmSJEmSehhIEakpDp0JHFtVtwCvBd6UZBjYBrir6fp+4BNVdduY8S8EVlXV8P09p6rmV1WrqlowNIjUJUmSJEmSNAEz+p0gyeZ0CkgLquosgKq6Cjigad+VzjY1gKcBL0tyIrAdcG+SP9DZAndwkoOABwHbJvn3qnpVv/lJkiRJkiSpf30VkZIEOBVYVlUnd8V3qKpVSR4AvBf4HEBV7dPV5/3AbVX1mSZ0fBPfF3ibBSRJkiRJkqT1R7/b2fYGDgf2S7Ko+R0EHJbkauAq4Abg830+R5IkSZIkSdMoVTXdOUxKq9Wqdrs93WlIkiRJkiRtNJIMd86ivq+BfZ1NkiRJkiRJG6++D9aeLsPDkEx3FpIkaUO2gS7IliRJmhauRJIkSZIkSVJPEyoiJTktyaokV47TdlySSrJ9c/+QJF9PcnmSJUn+pqvva5L8tPm9pit+WJLFSa5I8q3RuSRJkiRJkrR+mOhKpC8AB44NJpkFHAD8sit8FLC0qnYH9gU+nmSLJH8GvA94GrAn8L4kD00yA/gU8Oyq2g24Ajh6cq8jSZIkSZKkqTChIlJVXQzcNE7TJ4B3AN0nChSwTZIAWzfjVgPPAy6sqpuq6mbgQjqFqTS/rZox2wI3TO51JEmSJEmSNBUmfbB2kkOAFVV1ef70hOvPAOfQKQRtA/x1Vd2bZEfg+q5+y4Edq+ruJG8EFgO3Az+ls5ppvGfOA+Z17naabOqSJEmSJElaS5M6WDvJlsC7gRPGaX4esAh4FDAX+EySbe9nrs2BNwJ7NGOuAI4fr29Vza+qVlW1YGgyqUuSJEmSJGkSJvt1tscCOwOXJ7kOmAksTPII4G+As6rjGuDnwBOAFcCsrjlmNrG5AFX1s6oq4KvAX04yL0mSJEmSJE2BSRWRqmpxVe1QVbOrajadrWlPqapf0Tlke3+AJA8HHg9cC5wPHNAcpv1QOgdyn0+nkDQnyejSoucCy/p4J0mSJEmSJA3YhM5ESnI6nS+tbZ9kOfC+qjp1Dd0/BHwhyWI6B2a/s6p+08zzIeDHTb8PVtVNTfwDwMVJ7gZ+ARwxudeRJEmSJEnSVEhnB9mGp9VqVbvdnu40JEmSJEmSNhpJhjtnUd/XZM9EkiRJkiRJ0ibEIpIkSZIkSZJ6mtCZSOuj4WFIpjsLbSg20F2bkiRJkiStN1yJJEmSJEmSpJ76KiIleXySRV2/W5Icm+TlSZYkuTdJq6v/Fkk+n2RxksuT7DvOnOckubKfvCRJkiRJkjRYfW1nq6qfAHMBkmwGrADOBrYEXgL8y5ghb2jGPTnJDsB5Sf6iqu5t5ngJcFs/OUmSJEmSJGnwBrmdbX/gZ1X1i6pa1hSYxpoDfAegqlYBvwVaAEm2Bt4K/MMAc5IkSZIkSdIADLKIdChweo8+lwMHJ5mRZGfgqcCspu1DwMeBO9Y0OMm8JO0kbRgZRM6SJEmSJEmagIEUkZJsARwM/EePrqcBy4E28EngB8A9SeYCj62qs+9vcFXNr6pWVbVgqO+8JUmSJEmSNDF9nYnU5fnAwqr69f11qqrVwFtG75P8ALgaeBbQSnJdk9MOSf67qvYdUH6SJEmSJEnqw6CKSIfReysbSbYEUlW3J3kusLqqlgJLgc82fWYD51pAkiRJkiRJWn/0vZ0tyVbAc4GzumIvTrIceDrwjSTnN007AAuTLAPeCRze7/MlSZIkSZI09VJV053DpLRarWq329OdhiRJkiRJ0kYjyXDnLOr7GuTX2SRJkiRJkrSRGtSZSOvc8DAk053FxmMDXZAmSZIkSZLWEVciSZIkSZIkqaeeRaQks5JclGRpkiVJjmniX0myqPldl2RRE5+d5PddbZ9r4lsm+UaSq5p5PjLmOa/oesaXpuBdJUmSJEmSNEkT2c62GjiuqhYm2QYYTnJhVf31aIckHwd+1zXmZ1U1d5y5PlZVFyXZAvh2kudX1XlJdgGOB/auqpuT7DD5V5IkSZIkSdKg9SwiVdVKYGVzfWuSZcCOwFKAJAFeAezXY547gIua67uSLARmNs1vAP6pqm5u2ldN6m0kSZIkSZI0JdbqTKQks4E9gEu7wvsAv66qn3bFdk5yWZLvJtlnnHm2A/4K+HYT2hXYNcn/JLkkyYFreP68JO0kbRhZm9QlSZIkSZLUhwl/nS3J1sCZwLFVdUtX02HA6V33K4GdqurGJE8FvpbkiaNjksxo+n+6qq7tymMXYF86q5MuTvLkqvptdw5VNR+Y35mn5ffEJEmSJEmS1pEJrURKsjmdAtKCqjqrKz4DeAnwldFYVd1ZVTc218PAz+isNBo1H/hpVX2yK7YcOKeq7q6qnwNX0ykqSZIkSZIkaT0wka+zBTgVWFZVJ49pfg5wVVUt7+o/lGSz5voxdIpB1zb3/wA8BDh2zDxfo7MKiSTb0yk6XYskSZIkSZLWCxNZibQ3cDiwX5JFze+gpu1Q/nQrG8AzgSuSLALOAI6sqpuSzATeA8wBFjbzvL4Zcz5wY5KldA7ffvvoaiZJkiRJkiRNv1RtmEcLtVqtarfb052GJEmSJEnSRiPJcFW1xmtbq6+zSZIkSZIkadNkEUmSJEmSJEk9zZjuBCZreBiS6c6itw10t6AkSZIkSdKfcCWSJEmSJEmSeuq7iJRksySXJTl3TPzTSW7ruj8iyUjXF95e39W2U5ILkixLsjTJ7H7zkiRJkiRJ0uAMYjvbMcAyYNvRQJIW8NBx+n6lqo4eJ/5vwIer6sIkWwP3DiAvSZIkSZIkDUhfK5GSzAReAJzSFdsMOAl4xwTnmAPMqKoLAarqtqq6o5+8JEmSJEmSNFj9bmf7JJ1iUffKoaOBc6pq5Tj9X5rkiiRnJJnVxHYFfpvkrGZb3ElNIeo+ksxL0k7ShpE+U5ckSZIkSdJETbqIlOSFwKqqGu6KPQp4OfCP4wz5OjC7qnYDLgS+2MRnAPsAbwP+AngMcMR4z6yq+VXVqqoWDE02dUmSJEmSJK2lflYi7Q0cnOQ64MvAfsAS4HHANU18yyTXAFTVjVV1ZzP2FOCpzfVyYFFVXVtVq4GvAU/pIy9JkiRJkiQN2KSLSFV1fFXNrKrZwKHAd6rqoVX1iKqa3cTvqKrHASR5ZNfwg+kcxg3wY2C7JKNLi/YDlk42L0mSJEmSJA3eIL7ONlFvTnIwsBq4iWbLWlXdk+RtwLeTBBgG/nUd5iVJkiRJkqQeUlXTncOktFqtarfb052GJEmSJEnSRiPJcOcs6vvq9+tskiRJkiRJ2gSsy+1sAzU8DMnUPmMDXaQlSZIkSZI0cK5EkiRJkiRJUk89i0hJZiW5KMnSJEuSHNPEv5JkUfO7LsmiJv7KrviiJPcmmTtmznOSXNl1//4kK7rGHDTY15QkSZIkSVI/JrKdbTVwXFUtTLINMJzkwqr669EOST4O/A6gqhYAC5r4k4GvVdWirr4vAW4b5zmfqKqPTfpNJEmSJEmSNGV6rkSqqpVVtbC5vhVYBuw42p4kwCuA08cZfhjw5a6+WwNvBf6hv7QlSZIkSZK0Lq3VmUhJZgN7AJd2hfcBfl1VPx1nyF/zp8WlDwEfB+4Yp+/RSa5IclqSh67h+fOStJO0YWRtUpckSZIkSVIfJlxEalYRnQkcW1W3dDUdxjirkJI8Dbijqq5s7ucCj62qs8eZ/rPAY4G5wEo6hab7qKr5VdWqqhYMTTR1SZIkSZIk9WkiZyKRZHM6BaQFVXVWV3wG8BLgqeMMO5Q/LS49HWglua557g5J/ruq9q2qX3fN+a/AuWv7IpIkSZIkSZo6E/k6W4BTgWVVdfKY5ucAV1XV8jFjHkDnnKQ/nodUVZ+tqkdV1WzgGcDVVbVv0/+RXcNfDFyJJEmSJEmS1hsTWYm0N3A4sDjJoib27qr6JvddbTTqmcD1VXXtBPM4sdnuVsB1wN9OcJwkSZIkSZLWgVTVdOcwKa1Wq9rt9nSnIUmSJEmStNFIMtw5i/q+1urrbJIkSZIkSdo0Tehg7fXR8DAk/c+zgS7EkiRJkiRJWqdciSRJkiRJkqSe+i4iJdkuyRlJrkqyLMnTk3woyRVJFiW5IMmjmr5PSPLDJHcmeduYed6SZEmSK5OcnuRB/eYmSZIkSZKkwRjESqRPAd+qqicAuwPLgJOqareqmgucC5zQ9L0JeDPwse4JkuzYxFtV9SRgMzpffpMkSZIkSdJ6oK8iUpKHAM8ETgWoqruq6rdVdUtXt62AatpXVdWPgbvHmW4G8OAkM4AtgRv6yU2SJEmSJEmD0+9KpJ2BEeDzSS5LckqSrQCSfDjJ9cAr+d+VSOOqqhV0Vif9ElgJ/K6qLhjbL8m8JO0k7c5jJUmSJEmStC70W0SaATwF+GxV7QHcDrwLoKreU1WzgAXA0fc3SZKHAofQKUo9CtgqyavG9quq+VXVqqoWDPWZuiRJkiRJkiaq3yLScmB5VV3a3J9Bp6jUbQHw0h7zPAf4eVWNVNXdwFnAX/aZmyRJkiRJkgakryJSVf0KuD7J45vQ/sDSJLt0dTsEuKrHVL8E9kqyZZI08yzrJzdJkiRJkiQNzowBzPF3wIIkWwDXAn8DnNIUlu4FfgEcCZDkEUAb2Ba4N8mxwJyqujTJGcBCYDVwGTB/ALlJkiRJkiRpAFJV053DpLRarWq329OdhiRJkiRJ0kYjyXDnLOr76vdMJEmSJEmSJG0CLCJJkiRJkiSpp0GciTQthochWftxG+juPUmSJEmSpGnlSiRJkiRJkiT11HcRKcl2Sc5IclWSZUme3tV2XJJKsn1znySfTnJNkiuSPKWr74lJljRzfDqZzDojSZIkSZIkTYVBrET6FPCtqnoCsDuwDCDJLOAA4JddfZ8P7NL85gGfbfr+JbA3sBvwJOAvgGcNIDdJkiRJkiQNQF9FpCQPAZ4JnApQVXdV1W+b5k8A7wC6TyE6BPi36rgE2C7JI5s+DwK2AB4IbA78up/cJEmSJEmSNDj9rkTaGRgBPp/ksiSnJNkqySHAiqq6fEz/HYHru+6XAztW1Q+Bi4CVze/8qlo29mFJ5iVpJ2l3HitJkiRJkqR1od8i0gzgKcBnq2oP4Hbg/cC7gRMmOkmSxwF/DsykU2jaL8k+Y/tV1fyqalVVC4b6TF2SJEmSJEkT1W8RaTmwvKoube7PoFNU2hm4PMl1dApDC5M8AlgBzOoaP7OJvRi4pKpuq6rbgPOApyNJkiRJkqT1Ql9FpKr6FXB9ksc3of2BhVW1Q1XNrqrZdApNT2n6ngO8uvlK217A76pqJZ3Dt5+VZEaSzekcqn2f7WySJEmSJEmaHjMGMMffAQuSbAFcC/zN/fT9JnAQcA1wR1ffM4D9gMV0Dtn+VlV9fQC5SZIkSZIkaQBSVb17rYdarVa12+3pTkOSJEmSJGmjkWS4cxb1ffV7JpIkSZIkSZI2AYPYzjYthochuW98A11YJUmSJEmStF5zJZIkSZIkSZJ6mnQRKcmsJBclWZpkSZJjmvhXkixqftclWTRm3E5Jbkvytq7YdknOSHJVkmVJnj7pN5IkSZIkSdLA9bOdbTVwXFUtTLINMJzkwqr669EOST4O/G7MuJOB88bEPkXni2wva77ytmUfeUmSJEmSJGnAJl1EqqqVwMrm+tYky4AdgaUASQK8AthvdEySFwE/B27vij0EeCZwRDPXXcBdk81LkiRJkiRJgzeQM5GSzAb2AC7tCu8D/Lqqftr02Rp4J/CBMcN3BkaAzye5LMkpSbZaw3PmJWknaXeGSJIkSZIkaV3ou4jUFIfOBI6tqlu6mg4DTu+6fz/wiaq6bcwUM4CnAJ+tqj3orFJ613jPqqr5VdWqqhYM9Zu6JEmSJEmSJqifM5FIsjmdAtKCqjqrKz4DeAnw1K7uTwNeluREYDvg3iR/AM4AllfV6CqmM1hDEUmSJEmSJEnTY9JFpObMo1OBZVV18pjm5wBXVdXy0UBV7dM19v3AbVX1meb++iSPr6qfAPvTnKskSZIkSZKk9UM/K5H2Bg4HFidZ1MTeXVXfBA7lT7ey9fJ3wILmy2zXAn/TR16SJEmSJEkasFTVdOcwKa1Wq9rt9nSnIUmSJEmStNFIMtw5i/q+BvJ1NkmSJEmSJG3cLCJJkiRJkiSppw22iDQ8DMl0ZyFJkiRJkrRp2GCLSJIkSZIkSVp3+ioiJdkuyRlJrkqyLMnTk3woyRVJFiW5IMmjmr5PSPLDJHcmeVvXHLOSXJRkaZIlSY7p96UkSZIkSZI0WP2uRPoU8K2qegKwO7AMOKmqdququcC5wAlN35uANwMfGzPHauC4qpoD7AUclWROn3lJkiRJkiRpgCZdREryEOCZwKkAVXVXVf22qm7p6rYVUE37qqr6MXB39zxVtbKqFjbXt9IpRO042bwkSZIkSZI0eDP6GLszMAJ8PsnuwDBwTFXdnuTDwKuB3wHPnuiESWYDewCXrqF9HjCvc7dTH6lLkiRJkiRpbfSznW0G8BTgs1W1B3A78C6AqnpPVc0CFgBHT2SyJFsDZwLHjlnN9EdVNb+qWlXVgqE+UpckSZIkSdLa6KeItBxYXlWjq4bOoFNU6rYAeGmviZJsTqeAtKCqzuojJ0mSJEmSJE2BSReRqupXwPVJHt+E9geWJtmlq9shwFX3N0+S0DlXaVlVnTzZfCRJkiRJkjR1+jkTCeDvgAVJtgCuBf4GOKUpLN0L/AI4EiDJI4A2sC1wb5JjgTnAbsDhwOIki5p5311V3+wzN0mSJEmSJA1Iqmq6c5iUVqtV7XZ7utOQJEmSJEnaaCQZ7pxFfV/9nIkkSZIkSZKkTcQGW0QaHoZkurOQJEmSJEnaNGywRSRJkiRJkiStO30VkZIck+TKJEuag7JJ8vLm/t4kra6+eyZZ1PwuT/LirrYDk/wkyTVJ3tVPTpIkSZIkSRq8SX+dLcmTgDcAewJ3Ad9Kci5wJfAS4F/GDLkSaFXV6iSPBC5P8nWggH8CngssB36c5JyqWjrZ3CRJkiRJkjRY/axE+nPg0qq6o6pWA98FXlJVy6rqJ2M7d/UDeBCd4hF0ilDXVNW1VXUX8GXgkD7ykiRJkiRJ0oD1U0S6EtgnycOSbAkcBMy6vwFJnpZkCbAYOLIpKu0IXN/VbXkTG2/8vCTtJG0Y6SN1SZIkSZIkrY1Jb2erqmVJPgpcANwOLALu6THmUuCJSf4c+GKS89bymfOB+QBJq3p0lyRJkiRJ0oD0dbB2VZ1aVU+tqmcCNwNXT3DcMuA24EnACv50BdPMJiZJkiRJkqT1RL9fZ9uh+XcnOodpf+l++u6cZEZz/WjgCcB1wI+BXZr2LYBDgXP6yUuSJEmSJEmDNentbI0zkzwMuBs4qqp+m+TFwD8CQ8A3kiyqqucBzwDeleRu4F7gTVX1G4AkRwPnA5sBp1XVkj7zkiRJkiRJ0gClasM8WqjValW73Z7uNCRJkiRJkjYaSYarqjVeW1/b2SRJkiRJkrRp2GCLSMPDkEx3FpIkSZIkSZuGDbaIJEmSJEmSpHWn36+znZZkVZIrx2k7Lkkl2b65f0KSHya5M8nbxvS9LsniJIuSeNCRJEmSJEnSeqbflUhfAA4cG0wyCzgA+GVX+CbgzcDH1jDXs6tq7poOb5IkSZIkSdL06auIVFUX0ykOjfUJ4B1AdfVdVVU/Bu7u55mSJEmSJEla9wZ+JlKSQ4AVVXX5Wgwr4IIkw0nm3c/c85K0O1veRvrOVZIkSZIkSRMzY5CTJdkSeDedrWxr4xlVtSLJDsCFSa5qVjn9iaqaD8zvPKtVY9slSZIkSZI0NQa9EumxwM7A5UmuA2YCC5M84v4GVdWK5t9VwNnAngPOS5IkSZIkSX0YaBGpqhZX1Q5VNbuqZgPLgadU1a/WNCbJVkm2Gb2ms4rpPl97kyRJkiRJ0vTpaztbktOBfYHtkywH3ldVp66h7yOANrAtcG+SY4E5wPbA2UlG8/lSVX2rn7wkSZIkSZI0WKnaMI8WarVa1W63pzsNSZIkSZKkjUaS4apqjdc28K+zSZIkSZIkaeNjEUmSJEmSJEk9bbBFpOHh6c5AkiRJkiRp07HBFpEkSZIkSZK07ky6iJRkVpKLkixNsiTJMU38pCRXJbkiydlJtmvis5P8Psmi5ve5rrkOS7K4GfOtJNv3/WaSJEmSJEkamH5WIq0GjquqOcBewFFJ5gAXAk+qqt2Aq4Hju8b8rKrmNr8jAZLMAD4FPLsZcwVwdB95SZIkSZIkacAmXUSqqpVVtbC5vhVYBuxYVRdU1eqm2yXAzB5TpfltlSTAtsANk81LkiRJkiRJgzeQM5GSzAb2AC4d0/Ra4Lyu+52TXJbku0n2Aaiqu4E3AovpFI/mAKeu4TnzkrSTtGFkEKlLkiRJkiRpAvouIiXZGjgTOLaqbumKv4fOlrcFTWglsFNV7QG8FfhSkm2TbE6niLQH8Cg629m6t8D9UVXNr6pWVbVgqN/UJUmSJEmSNEEz+hncFIDOBBZU1Vld8SOAFwL7V1UBVNWdwJ3N9XCSnwG70tnKRlX9rBn7VeBd/eQlSZIkSZKkwern62yhs+1sWVWd3BU/EHgHcHBV3dEVH0qyWXP9GGAX4FpgBTAnyejSoufSOV9JkiRJkiRJ64l+ViLtDRwOLE6yqIm9G/g08EDgwk6diUuaL7E9E/hgkruBe4Ejq+omgCQfAC5u2n4BHNFHXpIkSZIkSRqwNLvNNjitVqva7fZ0pyFJkiRJkrTRSDLcOYv6vgbydTZJkiRJkiRt3DbYItLw8HRnIEmSJEmStOnYYItIkiRJkiRJWnd6FpGSzEpyUZKlSZYkOWZM+3FJKsn2zf0rk1yRZHGSHyTZvdc8ST7UjFmU5IIkjxr0i0qSJEmSJGnyJrISaTVwXFXNAfYCjkoyBzqFIeAA4Jdd/X8OPKuqngx8CJjfax7gpKrararmAucCJ/T3WpIkSZIkSRqknkWkqlpZVQub61uBZcCOTfMngHcA1dX/B1V1c3N7CTCz1zxVdUvXI7fqnk+SJEmSJEnTb8badE4yG9gDuDTJIcCKqro8yZqGvA447/7m6Yp9GHg18Dvg2Wt4/jxgXudup7VJXZIkSZIkSX1I1cQW/STZGvgu8GHgW8BFwAFV9bsk1wGtqvpNV/9nA/8MPKOqbhxvnqo6a5znHA88qKred//5tKqqPaHcJUmSJEmS1FuS4apqjdc2oa+zJdkcOBNY0BR+HgvsDFzeFJBmAguTPKLpvxtwCnDImALS2HnGswB46UTykiRJkiRJ0rrRcztbOnvVTgWWVdXJAFW1GNihq891NCuRkuwEnAUcXlVX3988XW27VNVPm9tDgKv6eitJkiRJkiQN1ETORNobOBxYnGRRE3t3VX1zDf1PAB4G/HNzVtLqZhnU/c3zkSSPB+4FfgEcOYl3kSRJkiRJ0hSZ8JlI65tWq1XttmciSZIkSZIkDUrfZyJJkiRJkiRp02YRSZIkSZIkST1tsEWk4eHpzkCSJEmSJGnTscEWkSRJkiRJkrTu9FVESvL4JIu6frckObar/bgklWT75v6VSa5IsjjJD5Ls3tX3wCQ/SXJNknf1k5ckSZIkSZIGa0Y/g6vqJ8BcgCSbASuAs5v7WcABwC+7hvwceFZV3Zzk+cB84GnN2H8CngssB36c5JyqWtpPfpIkSZIkSRqMQW5n2x/4WVX9orn/BPAOoEY7VNUPqurm5vYSYGZzvSdwTVVdW1V3AV8GDhlgbpIkSZIkSerDIItIhwKnAyQ5BFhRVZffT//XAec11zsC13e1LW9ifyLJvCTtJG0YGUzWkiRJkiRJ6qmv7WyjkmwBHAwcn2RL4N10trKtqf+z6RSRnrE2z6mq+XS2wJG0qkd3SZIkSZIkDcigViI9H1hYVb8GHgvsDFye5Do6W9YWJnkEQJLdgFOAQ6rqxmb8CmBW13wzm5gkSZIkSZLWAwNZiQQcRrOVraoWAzuMNjSFpFZV/SbJTsBZwOFVdXXX+B8DuyTZmU7x6FDg/wwoN0mSJEmSJPWp7yJSkq3ofFXtbyfQ/QTgYcA/JwFYXVWtqlqd5GjgfGAz4LSqWtJvbpIkSZIkSRqMVG2YRwu1Wq1qt9vTnYYkSZIkSdJGI8lwVbXGaxvk19kkSZIkSZK0kdpgi0jDw9OdgSRJkiRJ0qZjgy0iSZIkSZIkad3pWURKclqSVUmu7Iq9P8mKJIua30Fdbbsl+WGSJUkWJ3lQkm26+i5K8pskn2z6vzXJ0iRXJPl2kkdPyZtKkiRJkiRp0iayEukLwIHjxD9RVXOb3zcBkswA/h04sqqeCOwL3F1Vt3b1nQv8AjirmecyoFVVuwFnACf280KSJEmSJEkavJ5FpKq6GLhpgvMdAFxRVZc3Y2+sqnu6OyTZFdgB+F7T56KquqNpvgSYOcFnSZIkSZIkaR3p50yko5staKcleWgT2xWoJOcnWZjkHeOMOxT4SlXVOG2vA85b0wOTzEvSTtKGkT5SlyRJkiRJ0tqYbBHps8BjgbnASuDjTXwG8Azglc2/L06y/5ixhwKnj50wyauAFnDSmh5aVfOrqlVVLRiaZOqSJEmSJElaW5MqIlXVr6vqnqq6F/hXYM+maTlwcVX9ptmi9k3gKaPjkuwOzKiq4e75kjwHeA9wcFXdOZmcJEmSJEmSNHUmVURK8siu2xcDo19uOx94cpItm0O2nwUs7ep7GGNWISXZA/gXOgWkVZPJR5IkSZIkSVNrRq8OSU6n85W17ZMsB94H7JtkLlDAdcDfAlTVzUlOBn7ctH2zqr7RNd0rgIPGPOIkYGvgP5IA/LKqDp78K0mSJEmSJGnQMv751uu/VqtV7XZ7utOQJEmSJEnaaCQZ7pxFfV/9fJ1NkiRJkiRJmwiLSJIkSZIkSeppgy0iDQ/37iNJkiRJkqTB2GCLSJIkSZIkSVp3+ioiJTkmyZVJliQ5tontnuSHSRYn+XqSbceM2SnJbUne1tw/KMmPklzezPOBfnKSJEmSJEnS4E26iJTkScAbgD2B3YEXJnkccArwrqp6MnA28PYxQ08Gzuu6vxPYr6p2B+YCBybZa7J5SZIkSZIkafD6WYn058ClVXVHVa0Gvgu8BNgVuLjpcyHw0tEBSV4E/BxYMhqrjtua282bX/WRlyRJkiRJkgasnyLSlcA+SR6WZEvgIGAWnQLRIU2flzcxkmwNvBO4z3a1JJslWQSsAi6sqkvHe2CSeUnaSdow0kfqkiRJkiRJWhuTLiJV1TLgo8AFwLeARcA9wGuBNyUZBrYB7mqGvB/4RNeqo+657qmqucBMYM9mq9x4z5xfVa2qasHQZFOXJEmSJEnSWprRz+CqOhU4FSDJ/wcsr6qrgAOa2K7AC5ruTwNeluREYDvg3iR/qKrPdM332yQXAQfSWekkSZIkSZKk9UBfRaQkO1TVqiQ70TkPaa+u2AOA9wKfA6iqfbrGvR+4rao+k2QIuLspID0YeC6dFU6SJEmSJElaT/RVRALOTPIw4G7gqKYQdEySo5r2s4DP95jjkcAXk2xGZ3vdV6vq3D7zkiRJkiRJ0gClasP8EFqr1ap2uz3daUiSJEmSJG00kgx3zqK+r36+ziZJkiRJkqRNhEUkSZIkSZIk9WQRSZIkSZIkST31LCIlmZXkoiRLkyxJckwTPynJVUmuSHJ2ku2a+BZJPp9kcZLLk+zbNddfN/2XJPloV/zIpv+iJN9PMmfgbypJkiRJkqRJm8hKpNXAcVU1B9gLOKop8lwIPKmqdgOuBo5v+r8BoKqeDDwX+HiSBzRfcTsJ2L+qngg8Isn+zZgvVdWTq2oucCJw8mBeT5IkSZIkSYPQs4hUVSuramFzfSuwDNixqi6oqtVNt0uAmc31HOA7Tf9VwG+BFvAY4KdVNdL0+y/gpU2/W7oeuRWwYX4yTpIkSZIkaSO1VmciJZkN7AFcOqbptcB5zfXlwMFJZiTZGXgqMAu4Bnh8ktlJZgAvauKjcx+V5Gd0ViK9eQ3Pn5eknaQ9MjIyXhdJkiRJkiRNgQkXkZJsDZwJHNu9cijJe+hseVvQhE4DlgNt4JPAD4B7qupm4I3AV4DvAdcB94zOU1X/VFWPBd4JvHe8HKpqflW1qqo1NDQ00dQlSZIkSZLUpxkT6ZRkczoFpAVVdVZX/AjghXTOOSqAZovbW7r6/IDOmUlU1deBrzfxeXQVkbp8GfjsJN5FkiRJkiRJU2QiX2cLcCqwrKpO7oofCLwDOLiq7uiKb5lkq+b6ucDqqlra3O/Q/PtQ4E3AKc39Ll2PfAHw0z7fS5IkSZIkSQM0kZVIewOHA4uTLGpi7wY+DTwQuLBTZ+KSqjoS2AE4P8m9wIpm7KhPJdm9uf5gVV3dXB+d5DnA3cDNwGsm/0qSJEmSJEkatJ5FpKr6PpBxmr65hv7XAY9fQ9tha4gf0ysPSZIkSZIkTZ+1+jqbJEmSJEmSNk0WkSRJkiRJktSTRSRJkiRJkiT1NJGvs81KclGSpUmWJDmmq+3vklzVxE9sYrOT/D7Joub3ua7+30pyedP/c0k2a+IfSnJF0/+CJI+aipeVJEmSJEnS5Ezk62yrgeOqamGSbYDhJBcCDwcOAXavqjuT7NA15mdVNXecuV5RVbek8zm3M4CXA18GTqqqvwdI8mbgBODISb+VJEmSJEmSBmoiX2dbCaxsrm9NsgzYEXgD8JGqurNpWzWBuW7peu4WQI2JA2w1GpckSZIkSdL6Ya3OREoyG9gDuBTYFdgnyaVJvpvkL7q67pzksia+z5g5zgdWAbfSWY00Gv9wkuuBV9JZiTTe8+claSdpj4yMrE3qkiRJkiRJ6sOEi0hJtgbOBI5tVg7NAP4M2At4O/DVZpvaSmCnqtoDeCvwpSTbjs5TVc8DHgk8ENivK/6eqpoFLACOHi+HqppfVa2qag0NDa3dm0qSJEmSJGnSJlRESrI5nQLSgqo6qwkvB86qjh8B9wLbV9WdVXUjQFUNAz+js2rpj6rqD8B/0jlTaawFwEsn8zKSJEmSJEmaGhP5OluAU4FlVXVyV9PXgGc3fXalc8bRb5IMdX117THALsC1SbZO8sgmPgN4AXBVc79L17yHjMYlSZIkSZK0fpjI19n2Bg4HFidZ1MTeDZwGnJbkSuAu4DVVVUmeCXwwyd10VicdWVU3JXk4cE6SB9IpXl0EfK6Z7yNJHt/0/wV+mU2SJEmSJGm9kqoN80NorVar2u32dKchSZIkSZK00UgyXFWt8drW6utskiRJkiRJ2jRZRJIkSZIkSVJPFpEkSZIkSZLUk0UkSZIkSZIk9dSziJRkVpKLkixNsiTJMU38pCRXJbkiydlJtmviz00ynGRx8+9+TXzLJN9oxixJ8pGuZxyRZCTJoub3+il6X0mSJEmSJE3CRFYirQaOq6o5wF7AUUnmABcCT6qq3YCrgeOb/r8B/qqqngy8Bvh/XXN9rKqeAOwB7J3k+V1tX6mquc3vlP5eS5IkSZIkSYM0o1eHqloJrGyub02yDNixqi7o6nYJ8LKmz2Vd8SXAg5M8sKruAC5q+tyVZCEwczCvIUmSJEmSpKm0VmciJZlNZxXRpWOaXgucN86QlwILq+rOMfNsB/wV8O3uvs3WuDOSzFrD8+claSdpj4yMrE3qkiRJkiRJ6sOEi0hJtgbOBI6tqlu64u+hs+VtwZj+TwQ+CvztmPgM4HTg01V1bRP+OjC72Rp3IfDF8XKoqvlV1aqq1tDQ0ERTlyRJkiRJUp8mVERKsjmdAtKCqjqrK34E8ELglVVVXfGZwNnAq6vqZ2Ommw/8tKo+ORqoqhu7ViudAjx17V9FkiRJkiRJU2UiX2cLcCqwrKpO7oofCLwDOLg572g0vh3wDeBdVfU/Y+b6B+AhwLFj4o/suj0YWLa2LyJJkiRJkqSp0/NgbWBv4HBgcZJFTezdwKeBBwIXdupMXFJVRwJHA48DTkhyQtP/AGAL4D3AVcDCZsxnmi+xvTnJwXS2xd0EHNH3m0mSJEmSJGlg0rULbYPSarWq3W5PdxqSJEmSJEkbjSTDVdUar22tvs4mSZIkSZKkTZNFJEmSJEmSJPVkEUmSJEmSJEk9TeTrbLOSXJRkaZIlSY5p4rsn+WGSxUm+nmTbJv6wpv9tST4zZq4PJ7k+yW1j4o9O8u0kVyT57yQzB/mSkiRJkiRJ6s9EViKtBo6rqjnAXsBRSeYApwDvqqonA2cDb2/6/wH4e+Bt48z1dWDPceIfA/6tqnYDPgj837V6C0mSJEmSJE2pnkWkqlpZVQub61uBZcCOwK7AxU23C4GXNn1ur6rv0ykmjZ3rkqpaOc5j5gDfaa4vAg5Zy/eQJEmSJEnSFFqrM5GSzAb2AC4FlvC/xZ6XA7P6yONy4CXN9YuBbZI8bJznz0vSTtIeGRnp43GSJEmSJElaGxMuIiXZGjgTOLaqbgFeC7wpyTCwDXBXH3m8DXhWksuAZwErgHvGdqqq+VXVqqrW0NBQH4+TJEmSJEnS2pgxkU5JNqdTQFpQVWcBVNVVwAFN+67ACyabRFXdQLMSqSlWvbSqfjvZ+SRJkiRJkjRYE/k6W4BTgWVVdXJXfIfm3wcA7wU+N9kkkmzfzANwPHDaZOeSJEmSJEnS4E1kO9vewOHAfkkWNb+DgMOSXA1cBdwAfH50QJLrgJOBI5Isb77mRpITkywHtmzi72+G7Av8pJnv4cCHB/J2kiRJkiRJGohU1XTnMCmtVqva7fZ0pyFJkiRJkrTRSDJcVa3x2tbq62ySJEmSJEnaNFlEkiRJkiRJUk8WkSRJkiRJktSTRSRJkiRJkiT1NGVFpCRvSbIkyZVJTk/yoCRHJ7kmSSXZvqvvvkl+1/X1txOmKi9JkiRJkiStvRlTMWmSHYE3A3Oq6vdJvgocCvwPcC7w3+MM+15VvXAq8pEkSZIkSVJ/pqSI1DX3g5PcDWwJ3FBVlwEkmcLHSpIkSZIkadCmZDtbVa0APgb8ElgJ/K6qLugx7OlJLk9yXpInjtchybwk7STtkZGRAWctSZIkSZKkNZmSIlKShwKHADsDjwK2SvKq+xmyEHh0Ve0O/CPwtfE6VdX8qmpVVWtoaGjAWUuSJEmSJGlNpupg7ecAP6+qkaq6GzgL+Ms1da6qW6rqtub6m8Dm3QdvS5IkSZIkaXpNVRHpl8BeSbZM5wCk/YFla+qc5BFNP5Ls2eR14xTlJkmSJEmSpLU0VWciXQqcQWeb2uLmOfOTvDnJcmAmcEWSU5ohLwOuTHI58Gng0KqqqchNkiRJkiRJay8baq2m1WpVu92e7jQkSZIkSZI2GkmGq6o1XttUbWeTJEmSJEnSRsQikiRJkiRJknqyiCRJkiRJkqSeehaRkpyWZFWSK7tiuyf5YZLFSb6eZNsm/twkw018OMl+48x3zpi53p9kRZJFze+gQb2cJEmSJEmSBmMiK5G+ABw4JnYK8K6qejJwNvD2Jv4b4K+a+GuA/9c9KMlLgNvGecYnqmpu8/vmWuQvSZIkSZKkdaBnEamqLgZuGhPeFbi4ub4QeGnT97KquqGJLwEenOSBAEm2Bt4K/MMA8pYkSZIkSdI6NNkzkZYAhzTXLwdmjdPnpcDCqrqzuf8Q8HHgjnH6Hp3kimbr3EPX9NAk85K0k7RHRkYmmbokSZIkSZLW1mSLSK8F3pRkGNgGuKu7MckTgY8Cf9vczwUeW1VnjzPXZ4HHAnOBlXQKTeOqqvlV1aqq1tDQ0CRTlyRJkiRJ0tqaMZlBVXUVcABAkl2BF4y2JZlJ55ykV1fVz5rw04FWkuuaZ+6Q5L+rat+q+nXX2H8Fzp1MTpIkSZIkSZo6k1qJlGSH5t8HAO8FPtfcbwd8g86h2/8z2r+qPltVj6qq2cAzgKurat9mzCO7pn4xcCWSJEmSJElar/QsIiU5Hfgh8Pgky5O8DjgsydXAVcANwOeb7kcDjwNOSLKo+e3Q4xEnJlmc5Arg2cBbJvsykiRJkiRJmhqpqunOYVJarVa12+3pTkOSJEmSJGmjkWS4qlrjtU32YG1JkiRJkiRtQiwiSZIkSZIkqSeLSJIkSZIkSeqpryJSkgcl+VGSy5MsSfKBJv69roO1b0jytSaeJJ9Ock2SK5I8pWuu1yT5afN7TV9vJUmSJEmSpIGa0ef4O4H9quq2JJsD309yXlXtM9ohyZnAfza3zwd2aX5PAz4LPC3JnwHvA1pAAcNJzqmqm/vMT5IkSZIkSQPQ10qk6ritud28+f3xc29JtgX2A77WhA4B/q0ZdwmwXZJHAs8DLqyqm5rC0YXAgf3kJkmSJEmSpMHp+0ykJJslWQSsolMIurSr+UXAt6vqluZ+R+D6rvblTWxN8bHPmpeknaQ9MjLSb+qSJEmSJEmaoL6LSFV1T1XNBWYCeyZ5UlfzYcDp/T6j61nzq6pVVa2hoaFBTStJkiRJkqQeBvZ1tqr6LXARzTa0JNsDewLf6Oq2ApjVdT+zia0pLkmSJEmSpPVAv19nG0qyXXP9YOC5wFVN88uAc6vqD11DzgFe3XylbS/gd1W1EjgfOCDJQ5M8FDigiUmSJEmSJGk90O/X2R4JfDHJZnQKUl+tqnObtkOBj4zp/03gIOAa4A7gbwCq6qYkHwJ+3PT7YFXd1GdukiRJkiRJGpBUVe9e66FWq1Xtdnu605AkSZIkSdpoJBmuqtZ4bQM7E0mSJEmSJEkbL4tIkiRJkiRJ6skikiRJkiRJknqyiCRJkiRJkqSeehaRkpyWZFWSK7ti70+yIsmi5ndQE5+d5Pdd8c91jflWksuTLEnyueaLbmucS5IkSZIkSeuPGRPo8wXgM8C/jYl/oqo+Nk7/n1XV3HHir6iqW5IEOAN4OfDlHnNJkiRJkiRpPdBzJVJVXQzc1O+DquqW5nIGsAVQ/c4pSZIkSZKkdaOfM5GOTnJFs93toV3xnZNcluS7SfbpHpDkfGAVcCud1Ui95voTSeYlaSdpj4yM9JG6JEmSJEmS1sZki0ifBR4LzAVWAh9v4iuBnapqD+CtwJeSbDs6qKqeBzwSeCCwX4+57qOq5ldVq6paQ0NDk0xdkiRJkiRJa2tSRaSq+nVV3VNV9wL/CuzZxO+sqhub62HgZ8CuY8b+AfhP4JD7m0uSJEmSJEnrj0kVkZI8suv2xcCVTXyo66trjwF2Aa5NsvXomCQzgBcAV93fXJIkSZIkSVp/9Pw6W5LTgX2B7ZMsB94H7JtkLp3Dsa8D/rbp/kzgg0nuBu4Fjqyqm5I8HDgnyQPpFK4uAj7XjDlxDXNJkiRJkiRpPZGqDfMjaa1Wq9rt9nSnIUmSJEmStNFIMlxVrfHa+vk6myRJkiRJkjYRFpEkSZIkSZLUk0UkSZIkSZIk9dSziJTktCSrklzZFftKkkXN77oki5r4w5JclOS2JJ/p6r9lkm8kuSrJkiQfGfOMVyRZ2rR9aYDvJ0mSJEmSpAHo+XU24AvAZ4B/Gw1U1V+PXif5OPC75vYPwN8DT2p+3T5WVRcl2QL4dpLnV9V5SXYBjgf2rqqbk+ww6beRJEmSJEnSlOi5EqmqLgZuGq8tSYBXAKc3fW+vqu/TKSZ1z3FHVV3UXN8FLARmNs1vAP6pqm5u2ldN7lUkSZIkSZI0Vfo9E2kf4NdV9dOJDkiyHfBXwLeb0K7Arkn+J8klSQ68n7HzkrSTtEdGRvrJW5IkSZIkSWuh3yLSYTSrkCYiyYym/6er6tomPAPYBdi3me9fm0LTfVTV/KpqVVVraGion7wlSZIkSZK0FiZyJtK4moLQS4CnrsWw+cBPq+qTXbHlwKVVdTfw8yRX0ykq/XiyuUmSJEmSJGmw+lmJ9BzgqqpaPpHOSf4BeAhw7Jimr9FZhUSS7elsb7sWSZIkSZIkrTd6FpGSnA78EHh8kuVJXtc0Hco4W9mSXAecDBzR9J+TZCbwHmAOsDDJoiSvb4acD9yYZClwEfD2qrqx3xeTJEmSJEnS4KSqpjuHSWm1WtVut6c7DUmSJEmSpI1GkuGqao3X1u/B2pIkSZIkSdoEWESSJEmSJElSTxaRJEmSJEmS1JNFJEmSJEmSJPXUdxEpyVuSLElyZZLTkzwoyYIkP2lipyXZvOmbJJ9Ock2SK5I8pYk/OsnoV9uWJDmy37wkSZIkSZI0OH0VkZLsCLwZaFXVk4DNgEOBBcATgCcDDwZe3wx5PrBL85sHfLaJrwSeXlVzgacB70ryqH5ykyRJkiRJ0uAMYjvbDODBSWYAWwI3VNU3qwH8CJjZ9D0E+Lem6RJguySPrKq7qurOps8DB5SXJEmSJEmSBqSvYk1VrQA+BvySzmqi31XVBaPtzTa2w4FvNaEdgeu7pljexEgyK8kVTftHq+qGsc9LMi9JO0l7ZGSkn9QlSZIkSZK0FvrdzvZQOquLdgYeBWyV5FVdXf4ZuLiqvtdrrqq6vqp2Ax4HvCbJw8fpM7+qWlXVGhoa6id1SZIkSZIkrYV+t409B/h5VY1U1d3AWcBfAiR5HzAEvLWr/wpgVtf9zCb2R80KpCuBffrMTZIkSZIkSQPSbxHpl8BeSbZMEmB/YFmS1wPPAw6rqnu7+p8DvLr5SttedLa/rUwyM8mD4Y+rm54B/KTP3CRJkiRJkjQgM/oZXFWXJjkDWAisBi4D5gO3A78AftipLXFWVX0Q+CZwEHANcAfwN81Ufw58PEkBAT5WVYv7yU2SJEmSJEmDk84H1DY8rVar2u32dKchSZIkSZK00UgyXFWt8dr63c4mSZIkSZKkTYBFJEmSJEmSJPVkEUmSJEmSJEk99VVESvKgJD9KcnmSJUk+0MT3T7IwyaIk30/yuCb+iSa2KMnVSX47Zr5tkyxP8pl+8pIkSZIkSdJg9fV1NuBOYL+qui3J5sD3k5wHfBY4pKqWJXkT8F7giKp6y+jAJH8H7DFmvg8BF/eZkyRJkiRJkgasr5VI1XFbc7t586vmt20TfwhwwzjDDwNOH71J8lTg4cAF/eQkSZIkSZKkwet3JRJJNgOGgccB/1RVlyZ5PfDNJL8HbgH2GjPm0cDOwHea+wcAHwdeBTznfp41D5gHsNNOO/WbuiRJkiRJkiao74O1q+qeqpoLzAT2TPIk4C3AQVU1E/g8cPKYYYcCZ1TVPc39m4BvVtXyHs+aX1WtqmoNDQ31m7okSZIkSZImqO+VSKOq6rdJLgKeD+xeVZc2TV8BvjWm+6HAUV33Twf2ac5P2hrYIsltVfWuQeUnSZIkSZKkyeuriJRkCLi7KSA9GHgu8FHgIUl2raqrm9iyrjFPAB4K/HA0VlWv7Go/AmhZQJIkSZIkSVp/9LsS6ZHAF5tzkR4AfLWqzk3yBuDMJPcCNwOv7RpzKPDlqqo+ny1JkiRJkqR1JBtqLafValW73Z7uNCRJkiRJkjYaSYarqjVeW98Ha0uSJEmSJGnjZxFJkiRJkiRJPVlEkiRJkiRJUk8WkSRJkiRJktRTv19nW6Mk1wG3AvcAq6uqleTPgK8As4HrgFdU1c1J3g68siunPweGquqmqcpPkiRJkiRJEzfVK5GeXVVzu071fhfw7araBfh2c09VndT0mwscD3zXApIkSZIkSdL6Y11vZzsE+GJz/UXgReP0OQw4fV0lJEmSJEmSpN6msohUwAVJhpPMa2IPr6qVzfWvgId3D0iyJXAgcOZ4EyaZl6SdpD0yMjJVeUuSJEmSJGmMKTsTCXhGVa1IsgNwYZKruhurqpLUmDF/BfzPmrayVdV8YD5Aq9UaO1aSJEmSJElTZMpWIlXViubfVcDZwJ7Ar5M8EqD5d9WYYYfiVjZJkiRJkqT1zpQUkZJslWSb0WvgAOBK4BzgNU231wD/2TXmIcCzumOSJEmSJElaP0zVdraHA2cnGX3Gl6rqW0l+DHw1yeuAXwCv6BrzYuCCqrp9inKSJEmSJEnSJE1JEamqrgV2Hyd+I7D/GsZ8AfjCVOQjSZIkSZKk/kzl19kkSZIkSZK0kbCIJEmSJEmSpJ4sIkmSJEmSJKmnnkWkJKclWZXkyjHxv0tyVZIlSU7sih+f5JokP0nyvK74dUkWJ1mUpD2RuSRJkiRJkrR+mMjB2l8APgP822ggybOBQ4Ddq+rOJDs08TnAocATgUcB/5Vk16q6pxn67Kr6Tffka5pLkiRJkiRJ64+eK5Gq6mLgpjHhNwIfqao7mz6rmvghwJer6s6q+jlwDbBnj0esaS5JkiRJkiStJyZ7JtKuwD5JLk3y3SR/0cR3BK7v6re8iQEUcEGS4STzJjDXfSSZl6SdpD0yMjLJ1CVJkiRJkrS2JrKdbU3j/gzYC/gL4KtJHtNjzDOqakWzXe3CJFc1q5zGnauqauwEVTUfmA/QarXu0y5JkiRJkqSpMdmVSMuBs6rjR8C9wPbACmBWV7+ZTYyqGv13FXA2/7vNbU1zSZIkSZIkaT0x2SLS14BnAyTZFdgC+A1wDnBokgcm2RnYBfhRkq2SbNP03wo4ALiyx1ySJEmSJElaT/TczpbkdGBfYPsky4H3AacBpyW5ErgLeE2z/WxJkq8CS4HVwFFVdU+ShwNnJxl95peq6lvNI9Y0lyRJkiRJktYT2VDrNa1Wq9rt9nSnIUmSJEmStNFIMlxVrfHaJrudTZIkSZIkSZsQi0iSJEmSJEnqySKSJEmSJEmSeupZREoyK8lFSZYmWZLkmCZ+UpKrklyR5Owk2zXxhzX9b0vymTFzfTjJ9UluGxN/azP/FUm+neTRA3xHSZIkSZIk9WkiK5FWA8dV1RxgL+CoJHOAC4EnVdVuwNXA8U3/PwB/D7xtnLm+Duw5TvwyoNXMdQZw4lq9hSRJkiRJkqZUzyJSVa2sqoXN9a3AMmDHqrqgqlY33S4BZjZ9bq+q79MpJo2d65KqWjlO/KKqumPsXJIkSZIkSVo/rNWZSElmA3sAl45pei1w3oByet2a5koyL0k7SXtkZGRAj5MkSZIkSVIvEy4iJdkaOBM4tqpu6Yq/h86WtwX9JpPkVUALOGm89qqaX1WtqmoNDQ31+zhJkiRJkiRN0IyJdEqyOZ0C0oKqOqsrfgTwQmD/qqp+EknyHOA9wLOq6s5+5pIkSZIkSdJg9SwiJQlwKrCsqk7uih8IvINO0eeONY2fiCR7AP8CHFhVq/qZS5IkSZIkSYM3ke1sewOHA/slWdT8DgI+A2wDXNjEPjc6IMl1wMnAEUmWN19zI8mJSZYDWzbx9zdDTgK2Bv6jmeucQb2gJEmSJEmS+pc+d6FNm1arVe12e7rTkCRJkiRJ2mgkGa6q1nhta/V1NkmSJEmSJG2aLCJJkiRJkiSpJ4tIkiRJkiRJ6skikiRJkiRJknrqWURKMivJRUmWJlmS5JgmflKSq5JckeTsJNs18S2SfD7J4iSXJ9m3a66/bvovSfLRrvgRSUa6vv72+oG/qSRJkiRJkiZtIiuRVgPHVdUcYC/gqCRzgAuBJ1XVbsDVwPFN/zcAVNWTgecCH0/ygCQPA04C9q+qJwKPSLJ/13O+UlVzm98pA3k7SZIkSZIkDUTPIlJVrayqhc31rcAyYMequqCqVjfdLgFmNtdzgO80/VcBvwVawGOAn1bVSNPvv4CXDug9JEmSJEmSNIXW6kykJLOBPYBLxzS9Fjivub4cODjJjCQ7A08FZgHXAI9PMjvJDOBFTXzUS5utbmck6Y53P39eknaS9sjIyHhdJEmSJEmSNAUmXERKsjVwJnBsVd3SFX8PnS1vC5rQacByoA18EvgBcE9V3Qy8EfgK8D3gOuCeZszXgdnN1rgLgS+Ol0NVza+qVlW1hoaGJpq6JEmSJEmS+jRjIp2SbE6ngLSgqs7qih8BvJDOOUcF0Gxxe0tXnx/QOTOJqvo6nYIRSebRFJGq6saux50CnDjpN5IkSZIkSdLATeTrbAFOBZZV1cld8QOBdwAHV9UdXfEtk2zVXD8XWF1VS5v7HZp/Hwq8iU7BiCSP7HrkwXTOXZIkSZIkSdJ6YiIrkfYGDgcWJ1nUxN4NfBp4IHBhp87EJVV1JLADcH6Se4EVzdhRn0qye3P9waq6url+c5KD6WyLuwk4YtJvJEmSJEmSpIFLswttg9Nqtardbk93GpIkSZIkSRuNJMNV1Rqvba2+ziZJkiRJkqRNk0UkSZIkSZIk9WQRSZIkSZIkST1N5Otss5JclGRpkiVJjmniH0pyRZJFSS5I8qgm/vYmtijJlUnuSfJnTduBSX6S5Jok7+p6xn5JFjb9v5hkIgd+S5IkSZIkaR2ZyEqk1cBxVTUH2As4Kskc4KSq2q2q5gLnAicAVNVJVTW3iR8PfLeqbkqyGfBPwPOBOcBhSeYkeQDwReDQqnoS8AvgNQN9S0mSJEmSJPWlZxGpqlZW1cLm+lZgGbBjVd3S1W0rYLzPvB0GnN5c7wlcU1XXVtVdwJeBQ4CHAXdV1dVNvwuBl07mZSRJkiRJkjQ11upMpCSzgT2AS5v7Dye5HnglzUqkrr5bAgcCZzahHYHru7osb2K/AWYkGf183MuAWWt4/rwk7STtkZGRtUldkiRJkiRJfZhwESnJ1nQKQseOrkKqqvdU1SxgAXD0mCF/BfxPVd10f/NWVQGHAp9I8iPgVuCeNfSdX1WtqmoNDQ1NNHVJkiRJkiT1aUJFpCSb0ykgLaiqs8bpsoD7bkE7lP/dygawgj9dYTSziVFVP6yqfapqT+Bi4GokSZIkSZK03pjI19kCnAosq6qTu+K7dHU7BLiqq+0hwLOA/+zq82NglyQ7J9mCTpHpnKb/Ds2/DwTeCXxusi8kSZIkSZKkwZsxgT57A4cDi5MsamLvBl6X5PHAvXS+qHZk15gXAxdU1e2jgapaneRo4HxgM+C0qlrSNL89yQvpFLU+W1Xf6eOdJEmSJEmSNGDpHEm04Wm1WtVut6c7DUmSJEmSpI1GkuGqao3XtlZfZ5MkSZIkSdKmySKSJEmSJEmSerKIJEmSJEmSpJ4sIkmSJEmSJKmnvotISTZLclmSc5v77yVZ1PxuSPK1Jr5vkt91tZ3QxGcluSjJ0iRLkhzTb06SJEmSJEkarBkDmOMYYBmwLUBV7TPakORM4D+7+n6vql44Zvxq4LiqWphkG2A4yYVVtXQAuUmSJEmSJGkA+lqJlGQm8ALglHHatgX2A752f3NU1cqqWthc30qnILVjP3lJkiRJkiRpsPrdzvZJ4B3AveO0vQj4dlXd0hV7epLLk5yX5IljBySZDewBXDrew5LMS9JO0h4ZGekzdUmSJEmSJE3UpItISV4IrKqq4TV0OQw4vet+IfDoqtod+EfGrFBKsjVwJnDsmMLTH1XV/KpqVVVraGhosqlLkiRJkiRpLfWzEmlv4OAk1wFfBvZL8u8ASbYH9gS+Mdq5qm6pqtua628Cmzf9SLI5nQLSgqo6q4+cJEmSJEmSNAUmXUSqquOramZVzQYOBb5TVa9qml8GnFtVfxjtn+QRSdJc79k8+8YmdiqwrKpOnmw+kiRJkiRJmjr9nom0Jofyp1vZoFNYujLJ5cCngUOrquisaDqczkqmRc3voCnKS5IkSZIkSZOQTh1nw9Nqtardbk93GpIkSZIkSRuNJMNV1RqvbapWIkmSJEmSJGkjYhFJkiRJkiRJPVlEkiRJkiRJUk99FZGSnJZkVZIru2Jzk1zSHJDdbr7ERpJXJrkiyeIkP0iye9eYA5P8JMk1Sd7VT06SJEmSJEkavH5XIn0BOHBM7ETgA1U1FzihuQf4OfCsqnoy8CFgPkCSzYB/Ap4PzAEOSzKnz7wkSZIkSZI0QH0VkarqYuCmsWFg2+b6IcANTd8fVNXNTfwSYGZzvSdwTVVdW1V3AV8GDuknL0mSJEmSJA3WjCmY81jg/CQfo1Ok+stx+rwOOK+53hG4vqttOfC08SZOMg+YB7DTTjsNKF1JkiRJkiT1MhUHa78ReEtVzQLeApza3Zjk2XSKSO9c24mran5VtaqqNTQ0NJBkJUmSJEmS1NtUFJFeA5zVXP8Hne1qACTZDTgFOKSqbmzCK4BZXeNnNjFJkiRJkiStJ6aiiHQD8Kzmej/gpwBJdqJTXDq8qq7u6v9jYJckOyfZAjgUOGcK8pIkSZIkSdIk9XUmUpLTgX2B7ZMsB94HvAH4VJIZwB9ozjCi86W2hwH/nARgdbM1bXWSo4Hzgc2A06pqST95SZIkSZIkabBSVdOdw6S0Wq1qt9vTnYYkSZIkSdJGI8lwVbXGa5uK7WySJEmSJEnayFhEkiRJkiRJUk8WkSRJkiRJktRTzyJSktOSrEpyZVfs/UlWJFnU/A4aM2anJLcleVtX7Loki5v+7a74y5MsSXJvknH33EmSJEmSJGl6TWQl0heAA8eJf6Kq5ja/b45pOxk4b5wxz276dxeLrgReAlw8kYQlSZIkSZK07s3o1aGqLk4ye6ITJnkR8HPg9on0r6plzbiJPkKSJEmSJEnrWD9nIh2d5Ipmu9tDAZJsDbwT+MA4/Qu4IMlwknmTeWCSeUnaSdojIyOTz1ySJEmSJElrZbJFpM8CjwXmAiuBjzfx99PZ5nbbOGOeUVVPAZ4PHJXkmWv70KqaX1WtqmoNDQ1NKnFJkiRJkiStvZ7b2cZTVb8evU7yr8C5ze3TgJclORHYDrg3yR+q6jNVtaIZuyrJ2cCeeA6SJEmSJEnSBmFSRaQkj6yqlc3ti+kcjk1V7dPV5/3AbVX1mSRbAQ+oqlub6wOAD/aVuSRJkiRJktaZnkWkJKcD+wLbJ1kOvA/YN8lcOuccXQf8bY9pHg6c3RyePQP4UlV9q5n/xcA/AkPAN5IsqqrnTeZlJEmSJEmSNDVSVdOdw6S0Wq1qt9vTnYYkSZIkSdJGI8lwVbXGa+vn62ySJEmSJEnaRFhEkiRJkiRJUk8WkSRJkiRJktSTRSRJkiRJkiT11LOIlGRWkouSLE2yJMkxXW1/l+SqJn5iE3tY0/+2JJ8ZM9d/J/lJkkXNb4cm/tZm/iuSfDvJowf9opIkSZIkSZq8GRPosxo4rqoWJtkGGE5yIfBw4BBg96q6c7QgBPwB+HvgSc1vrFdW1djPql0GtKrqjiRvBE4E/noS7yNJkiRJkqQp0HMlUlWtrKqFzfWtwDJgR+CNwEeq6s6mbVXz7+1V9X06xaQJqaqLquqO5vYSYOZavYUkSZIkSZKm1FqdiZRkNrAHcCmwK7BPkkuTfDfJX0xwms83W9n+PknGaX8dcN4anj8vSTtJe2RkZG1SlyRJkiRJUh8mXERKsjVwJnBsVd1CZyvcnwF7AW8HvrqGolC3V1bVk4F9mt/hY57xKqAFnDTe4KqaX1WtqmoNDQ1NNHVJkiRJkiT1aUJFpCSb0ykgLaiqs5rwcuCs6vgRcC+w/f3NU1Urmn9vBb4E7Nn1jOcA7wEOHt0iJ0mSJEmSpPXDRL7OFuBUYFlVndzV9DXg2U2fXYEtgN/czzwzkmzfXG8OvBC4srnfA/gXOgWkVZN6E0mSJEmSJE2ZiXydbW86284WJ1nUxN4NnAacluRK4C7gNVVVAEmuA7YFtkjyIuAA4BfA+U0BaTPgv4B/beY7Cdga+I9mR9wvq+rgfl9OkiRJkiRJg9GziNR8aW1NZx29ag1jZq+h/1PX0P85vfKQJEmSJEnS9Fmrr7NJkiRJkiRp02QRSZIkSZIkST1ZRJIkSZIkSVJPEzlY+341h2jfCtwDrK6qVpIPAYcA9wKrgCOq6oam/77AJ4HNgd9U1bPWNE+/uUmSJEmSJGkw+i4iNZ5dVb/puj+pqv4eIMmbgROAI5NsB/wzcGBV/TLJDj3mkSRJkiRJ0npgSrazVdUtXbdbAdVc/x/grKr6ZdNv1VQ8X5IkSZIkSYM1iCJSARckGU4ybzSY5MNJrgdeSWclEsCuwEOT/HfT/9W95umWZF6SdpL2yMjIAFKXJEmSJEnSRAyiiPSMqnoK8HzgqCTPBKiq91TVLGABcHTTdwbwVOAFwPOAv0+y6/3N062q5ldVq6paQ0NDA0hdkiRJkiRJE9F3EamqVjT/rgLOBvYc02UB8NLmejlwflXd3px9dDGw+wTnkSRJkiRJ0jTpq4iUZKsk24xeAwcAVybZpavbIcBVzfV/As9IMiPJlsDTgGVrmqef3CRJkiRJkjQ4/X6d7eHA2UlG5/pSVX0ryZlJHg/cC/wCOBKgqpYl+RZwRdN2SlVdmeQx483TZ26SJEmSJEkakFRV717roVarVe12e7rTkCRJkiRJ2mgkGa6q1nhtgzhYW5IkSZIkSRs5i0iSJEmSJEnqySKSJEmSJEmSerKIJEmSJEmSpJ4mVERKclqSVUmu7IqdlOSqJFckOTvJdl1txye5JslPkjyviT0+yaKu3y1Jjm3aPtTMsyjJBUkeNdjXlCRJkiRJUj8muhLpC8CBY2IXAk+qqt2Aq4HjAZLMAQ4FntiM+eckm1XVT6pqblXNBZ4K3AGc3cx1UlXt1rSdC5ww6TeSJEmSJEnSwE2oiFRVFwM3jYldUFWrm9tLgJnN9SHAl6vqzqr6OXANsOeYKfcHflZVv2jmuqWrbSug1uotJEmSJEmSNKVmDGie1wJfaa53pFNUGrW8iXU7FDi9O5Dkw8Crgd8Bzx7vIUnmAfMAdtppp76TliRJkiRJ0sT0fbB2kvcAq4EFE+y/BXAw8B/d8ap6T1XNauY5eryxVTW/qlpV1RoaGuovcUmSJEmSJE1YX0WkJEcALwReWVWjW9BWALO6us1sYqOeDyysql+vYdoFwEv7yUuSJEmSJEmDNekiUpIDgXcAB1fVHV1N5wCHJnlgkp2BXYAfdbUfxn23su3SdXsIcNVk85IkSZIkSdLgTehMpCSnA/sC2ydZDryPztfYHghcmATgkqo6sqqWJPkqsJTONrejquqeZp6tgOcCfzvmER9J8njgXuAXwJH9vpgkSZIkSZIGJ/+7C23D0mq1qt1uT3cakiRJkiRJG40kw1XVGq+t74O1JUmSJEmStPGziCRJkiRJkqSeLCJJkiRJkiSpp55FpCSzklyUZGmSJUmOaeJzk1ySZFGSdpI9m/grk1yRZHGSHyTZfcx8myW5LMm5XbHvNfMsSnJDkq8N+D0lSZIkSZLUh4l8nW01cFxVLUyyDTCc5ELgROADVXVekoOa+32BnwPPqqqbkzwfmA88rWu+Y4BlwLajgaraZ/Q6yZnAf/b3WpIkSZIkSRqkniuRqmplVS1srm+lUwDaESj+txD0EOCGps8PqurmJn4JMHN0riQzgRcAp4z3rCTbAvsBX5vEu0iSJEmSJGmKTGQl0h8lmQ3sAVwKHAucn+RjdIpRfznOkNcB53XdfxJ4B7DNGh7xIuDbVXXLGp4/D5gHsNNOO61N6pIkSZIkSerDhA/WTrI1cCZwbFPkeSPwlqqaBbwFOHVM/2fTKSK9s7l/IbCqqobv5zGHAaevqbGq5ldVq6paQ0NDE01dkiRJkiRJfZpQESnJ5nQKSAuq6qwm/Bpg9Po/gD27+u9GZ8vaIVV1YxPeGzg4yXXAl4H9kvx715jtmzm+Mem3kSRJkiRJ0pSYyNfZQmeV0bKqOrmr6QbgWc31fsBPm/470SkuHV5VV492rqrjq2pmVc0GDgW+U1Wv6prvZcC5VfWHPt5HkiRJkiRJU2AiZyLtDRwOLE6yqIm9G3gD8KkkM4A/0JxVBJwAPAz45079idVV1ZrAcw4FPjLx1CVJkiRJkrSupKqmO4dJabVa1W63pzsNSZIkSZKkjUaS4TUtBprwwdqSJEmSJEnadFlEkiRJkiRJUk8WkSRJkiRJktSTRSRJkiRJkiT1ZBFJkiRJkiRJPVlEkiRJkiRJUk8WkSRJkiRJktSTRSRJkiRJkiT1ZBFJkiRJkiRJPVlEkiRJkiRJUk8WkSRJkiRJktSTRSRJkiRJkiT1ZBFJkiRJkiRJPVlEkiRJkiRJUk8WkSRJkiRJktSTRSRJkiRJkiT1ZBFJkiRJkiRJPVlEkiRJkiRJUk8WkSRJkiRJktSTRSRJkiRJkiT1ZBFJkiRJkiRJPVlEkiRJkiRJUk8WkSRJkiRJktSTRSRJkiRJkiT1lKqa7hwmJcmtwE+mOw9Jf7Q98JvpTkIS4N+jtL7xb1Jaf/j3KPX26KoaGq9hxrrOZIB+UlWt6U5CUkeStn+T0vrBv0dp/eLfpLT+8O9R6o/b2SRJkiRJktSTRSRJkiRJkiT1tCEXkeZPdwKS/oR/k9L6w79Haf3i36S0/vDvUerDBnuwtiRJkiRJktadDXklkiRJkiRJktYRi0iSJEmSJEnqab0vIiU5MMlPklyT5F3jtD8wyVea9kuTzJ6GNKVNwgT+Ho9IMpJkUfN7/XTkKW0KkpyWZFWSK9fQniSfbv5er0jylHWdo7QpmcDf5L5Jftf1v5EnrOscpU1FkllJLkqyNMmSJMeM08f/nZQmYb0uIiXZDPgn4PnAHOCwJHPGdHsdcHNVPQ74BPDRdZultGmY4N8jwFeqam7zO2WdJiltWr4AHHg/7c8Hdml+84DProOcpE3ZF7j/v0mA73X9b+QH10FO0qZqNXBcVc0B9gKOGuf/b/V/J///9u41Ro+yjMP49YcWEKpibKJQFAl4AKFFsJWDchBiUJEiFCghSk2DhwiEKBojoJaQGDT6wRMHFVGDNKFULHJoSkBBLNByaEtTNYAEKkQRtBRBtOX2w8zW12Xb93Xb7m671y9pdg7PzHPPJtN5cs89z0qDMKKTSMAU4KGqeqSq/gXMBqb2azMV+HG7PAc4KkmGMEZptOjlfpQ0RKrqduCZDTSZCvykGncBOyfZZWiik0afHu5JSUOkqp6sqvva5dXACmBCv2Y+J6VBGOlJpAnA4x3rK3n5zb+uTVWtAVYBrx2S6KTRpZf7EeDEtiR4TpI3DE1okgbQ6z0raegcnGRJkpuSvH24g5FGg3a6k3cAd/fb5XNSGoSRnkSStGW5HnhTVU0EFvDfKkFJkka7+4Ddq2oS8G3guuENR9r6JRkHXAucU1XPDnc80tZgpCeR/gR0VjLs1m4bsE2SMcCrgaeHJDppdOl6P1bV01X1Yrv6A+DAIYpN0sv18gyVNESq6tmqeq5dvhEYm2T8MIclbbWSjKVJIF1VVXMHaOJzUhqEkZ5EWgS8OckeSbYDpgPz+rWZB5zeLk8Dbq2qGsIYpdGi6/3Y7zvy42i+P5c0POYBH23/+sxBwKqqenK4g5JGqySv75u3M8kUmnG4Lz6lzaC9134IrKiqb66nmc9JaRDGDHcAG1JVa5KcCcwHtgWuqKrlSS4EFlfVPJr/HH6a5CGayQynD1/E0tarx/vx7CTH0fxFjGeAGcMWsLSVS3I1cAQwPslK4MvAWICquhS4EfgA8BDwPPCx4YlUGh16uCenAZ9KsgZ4AZjui09pszkU+AiwLMkD7bYvAm8En5PSxojPLkmSJEmSJHUz0j9nkyRJkiRJ0ghgEkmSJEmSJEldmUSSJEmSJElSVyaRJEmSJEmS1JVJJEmSJEmSpC1EkiuS/CXJgz20PSzJfUnWJJnWb9/XkixPsiLJt5Kk2/lMIkmSpBEtydokDyR5MMn1SXbu0v4rSc7t0ub4JPt0rF+Y5OhNEOuV/Qdom1uSc5LsOJR9SpKkYXUlcEyPbR8DZgA/69yY5BDgUGAisC8wGTi828lMIkmSpJHuharav6r2BZ4BPr0Jznk8sC6JVFVfqqpbNsF5h1SSbYFzAJNIkiSNElV1O82YaJ0keya5Ocm9Se5I8ra27aNVtRR4qf9pgB2A7YDtgbHAn7v1bRJJkiRtSRYCE2D9g6VOSc5IsijJkiTXJtmxffN2HPD1tsJpz74KoiTHJLmm4/gjkvyyXX5fkoVtSfg1ScZtKNAkjyb5atvH4iQHJJmf5OEkn+w4/+1Jbkjy+ySXJtmm3XdqkmVtBdbFHed9Lsk3kiwBzgN2BW5Lclu7/5K2v+VJZvWLZ1Yb/7K+31eScUl+1G5bmuTEwVyvJEkaVpcDZ1XVgcC5wPc21LiqFgK3AU+2/+ZX1YpunZhEkiRJW4S26uYoYF67qZfB0tyqmlxVk4AVwMyq+m17js+1FU4Pd7S/BXhXkp3a9VOA2UnGA+cDR1fVAcBi4DM9hP1YVe0P3EFTej4NOAiY1dFmCnAWTWXUnsAJSXYFLgbeC+wPTE5yfNt+J+DuqppUVRcCTwBHVtWR7f7zquqdNOXphyeZ2NHXX9v4L2l/ZwAXAKuqar+qmgjcuhHXK0mShlj7oucQ4JokDwCXAbt0OWYvYG9gN5oXdO9N8p5ufY3Z6GglSZI2r1e0A6IJNImgBf0GS33tth/g2H2TXATsDIwD5m+oo6pak+Rm4ENJ5gAfBD5PM0fAPsCdbX/b0VRFddOX8FoGjKuq1cDqJC92zO10T1U9ApDkauDdwL+BX1XVU+32q4DDgOuAtcC1G+jz5CQfpxnn7dLGvbTdN7f9eS9wQrt8NDC943fwtyTHDvJ6JUnS0NsG+Hv74qpXHwbuqqrnAJLcBBxM8+Jrgx1JkiSNZC+0g6LdgdDMibRusNTxb+8Bjr0SOLOq9qOp/tmhh/5mAyfTVAEtbhM/ARZ09LVPVc3s4Vwvtj9f6ljuW+97mVf9jum/3t8/q2rtQDuS7EFTYXRUW1V0A/97zX0xrGXDLxMHe72SJGmIVdWzwB+TnASQxqQuhz1GU7E8JslYmhdmfs4mSZK2DlX1PHA28FngeXobLL0SeLIdHJ3WsX11u28gvwYOAM6gSSgB3AUc2pZ+k2SnJG/ZyEvqMyXJHu1cSKcAvwHuoRnYjW8/4zu1jWsgndfyKuAfwKokrwPe30P/C+iYrDzJa9i81ytJkjZCW7m8EHhrkpVJZtKMc2a2cyYuB6a2bScnWQmcBFyWZHl7mjnAwzTV0kuAJVV1fbe+/ZxNkiRtMarq/iRLaZIqpwGXJDmf5i+KzKYZBHW6ALgbeKr92ZdsmQ18P8nZNPMUdfaxtp1MewZwervtqSQzgKuT9H02dz7wh01wWYuA7wB70Uxw+fOqeinJF9r1ADdU1S/Wc/zlwM1JnqiqI5PcD/wOeBy4s4f+LwK+m+RBmgqlWVU1dzNeryRJ2ghVdep6dh0zQNtFNPMe9d++FvjE/9t3qrpVTEuSJGlzSHIEcG5VHTvMoUiSJHXl52ySJEmSJEnqykokSZIkSZIkdWUlkiRJkiRJkroyiSRJkiRJkqSuTCJJkiRJkiSpK5NIkiRJkiRJ6sokkiRJkiRJkrr6DzNEhkcKohYOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "indices = np.argsort(scores)[-0:]  # top 30 features\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)),scores[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [fin_data.columns[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(sel_data)\n",
    "\n",
    "# Project data onto first two principal components\n",
    "projX = pca.transform(sel_data)\n",
    "plt.figure(figsize=(30,15))\n",
    "\n",
    "scatter = plt.scatter(projX[:,0],projX[:,1],c=fin_data.iloc[:,-1],cmap='rainbow')\n",
    "plt.legend(handles=scatter.legend_elements()[0],labels = ['AY.4 (Delta-like)','AY.9 (Delta-like)','AY.12 (Delta-like)'],\n",
    "           title=\"lineage\")\n",
    "plt.title('Projected data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI：0.493544\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans=KMeans(n_clusters=3,random_state=123).fit(sel_data.iloc[:,:-1])\n",
    "ari=adjusted_rand_score(fin_data.iloc[:,-1], kmeans.labels_)  \n",
    "print('ARI：%f'%(ari))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B.1.1.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/Aral/Desktop/毕业论文/数据/SARS-CoV-2 lineage meta data.csv')\n",
    "df = df.dropna()\n",
    "\n",
    "file_dir = 'C:/Users/Aral/Desktop/毕业论文/数据/clinical_variant_files'\n",
    "def getFlist(path):\n",
    "    f = []\n",
    "    for root, dirs, files in os.walk(file_dir):\n",
    "        f.append(files)\n",
    "    return f\n",
    "file_name = getFlist(file_dir)[0]\n",
    "\n",
    "pos_record = {}\n",
    "target2 = list(df[df['lineage']=='B.1.1.7']['INAB sample ID'])\n",
    "for i in range(len(file_name)):\n",
    "    if i != 306:\n",
    "        t = re.findall(r'V[0-9]*',file_name[i])\n",
    "        if t[0] in target2:\n",
    "            test = vcf.Reader(filename = 'C:/Users/Aral/Desktop/毕业论文/数据/clinical_variant_files/'+file_name[i])\n",
    "            for record in test:\n",
    "                if record.POS not in pos_record:\n",
    "                    pos_record[record.POS] = 1\n",
    "                else:\n",
    "                    pos_record[record.POS] += 1\n",
    "\n",
    "res = sorted(pos_record.items(),key = lambda item:item[1],reverse=True)\n",
    "sor_res = {str(k):v for k,v in res}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>14408</th>\n",
       "      <th>23063</th>\n",
       "      <th>24914</th>\n",
       "      <th>21990</th>\n",
       "      <th>16176</th>\n",
       "      <th>3037</th>\n",
       "      <th>5388</th>\n",
       "      <th>23403</th>\n",
       "      <th>28270</th>\n",
       "      <th>11287</th>\n",
       "      <th>...</th>\n",
       "      <th>8240</th>\n",
       "      <th>12374</th>\n",
       "      <th>27987</th>\n",
       "      <th>29440</th>\n",
       "      <th>6706</th>\n",
       "      <th>10646</th>\n",
       "      <th>27261</th>\n",
       "      <th>1839</th>\n",
       "      <th>26158</th>\n",
       "      <th>28665</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1277 rows × 801 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      14408  23063  24914  21990  16176  3037  5388  23403  28270  11287  ...  \\\n",
       "0         4      4      2      4      2     4     1      3      4      3  ...   \n",
       "1         4      4      2      4      2     4     1      3      4      3  ...   \n",
       "2         4      4      2      4      2     4     1      3      4      3  ...   \n",
       "3         4      4      2      4      2     4     1      3      4      3  ...   \n",
       "4         4      4      2      4      2     4     1      3      4      3  ...   \n",
       "...     ...    ...    ...    ...    ...   ...   ...    ...    ...    ...  ...   \n",
       "1272      4      4      2      4      2     4     1      3      4      3  ...   \n",
       "1273      4      4      2      4      2     4     1      3      4      3  ...   \n",
       "1274      4      4      2      4      2     4     1      3      4      3  ...   \n",
       "1275      4      4      2      4      2     4     1      3      4      3  ...   \n",
       "1276      4      4      2      4      2     4     1      3      4      3  ...   \n",
       "\n",
       "      8240  12374  27987  29440  6706  10646  27261  1839  26158  28665  \n",
       "0        0      0      0      0     0      0      0     0      0      0  \n",
       "1        0      0      0      0     0      0      0     0      0      0  \n",
       "2        0      0      0      0     0      0      0     0      0      0  \n",
       "3        0      0      0      0     0      0      0     0      0      0  \n",
       "4        0      0      0      0     0      0      0     0      0      0  \n",
       "...    ...    ...    ...    ...   ...    ...    ...   ...    ...    ...  \n",
       "1272     0      0      0      0     0      0      0     0      0      0  \n",
       "1273     0      0      0      0     0      0      0     0      0      0  \n",
       "1274     0      0      0      0     0      0      0     0      3      0  \n",
       "1275     0      0      0      0     0      0      0     0      0      0  \n",
       "1276     0      0      0      0     0      0      0     0      0      0  \n",
       "\n",
       "[1277 rows x 801 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sor_res_filter = dict(filter(lambda x: x[1] >= 2,sor_res.items()))\n",
    "pos3 = list(sor_res_filter.keys())\n",
    "df2 = pd.read_csv('C:/Users/Aral/Desktop/毕业论文/数据/SARS-CoV-2 lineage meta data.csv')\n",
    "df2 = df2.dropna()\n",
    "\n",
    "x2 = []\n",
    "for i in range(len(file_name)):\n",
    "    tar = [0]*len(pos3)\n",
    "    if i != 306:\n",
    "        t = re.findall(r'V[0-9]*',file_name[i])\n",
    "        if t[0] in target2:\n",
    "            test = vcf.Reader(filename = 'C:/Users/Aral/Desktop/毕业论文/数据/clinical_variant_files/'+file_name[i])\n",
    "            for p in test:\n",
    "                if str(p.POS) in pos3:\n",
    "                    if p.ALT[0] == 'A':\n",
    "                        tar[pos3.index(str(p.POS))] = 1\n",
    "                    if p.ALT[0] == 'C':\n",
    "                        tar[pos3.index(str(p.POS))] = 2\n",
    "                    if p.ALT[0] == 'G':\n",
    "                        tar[pos3.index(str(p.POS))] = 3\n",
    "                    if p.ALT[0] == 'T':\n",
    "                        tar[pos3.index(str(p.POS))] = 4\n",
    "            x2.append(tar)\n",
    "\n",
    "B117_test = pd.DataFrame(x2)\n",
    "B117_test.columns = pos3\n",
    "B117_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.083e+12, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=1.366e+12, with an active set of 52 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=1.203e+12, with an active set of 62 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=1.177e+12, with an active set of 65 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=1.169e+12, with an active set of 66 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=1.080e+12, with an active set of 75 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=1.080e+12, with an active set of 75 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=1.044e+12, with an active set of 80 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 92 iterations, i.e. alpha=1.017e+12, with an active set of 83 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=8.468e+11, with an active set of 102 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 140 iterations, i.e. alpha=7.119e+11, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 153 iterations, i.e. alpha=6.766e+11, with an active set of 140 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=6.564e+11, with an active set of 148 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.213e+11, with an active set of 158 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.213e+11, with an active set of 158 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.213e+11, with an active set of 158 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.210e+11, with an active set of 158 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.202e+11, with an active set of 158 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=6.129e+11, with an active set of 159 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=6.080e+11, with an active set of 159 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=6.068e+11, with an active set of 160 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=5.944e+11, with an active set of 162 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=5.944e+11, with an active set of 162 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 187 iterations, i.e. alpha=5.868e+11, with an active set of 169 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 194 iterations, i.e. alpha=5.563e+11, with an active set of 175 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 197 iterations, i.e. alpha=5.511e+11, with an active set of 178 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 202 iterations, i.e. alpha=5.445e+11, with an active set of 183 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 202 iterations, i.e. alpha=5.445e+11, with an active set of 183 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 211 iterations, i.e. alpha=5.209e+11, with an active set of 191 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 211 iterations, i.e. alpha=5.207e+11, with an active set of 191 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 219 iterations, i.e. alpha=5.086e+11, with an active set of 197 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 221 iterations, i.e. alpha=5.021e+11, with an active set of 199 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 238 iterations, i.e. alpha=4.978e+11, with an active set of 213 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 238 iterations, i.e. alpha=4.978e+11, with an active set of 213 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 239 iterations, i.e. alpha=4.962e+11, with an active set of 214 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=4.717e+11, with an active set of 228 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 255 iterations, i.e. alpha=4.706e+11, with an active set of 229 regressors, and the smallest cholesky pivot element being 9.599e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 255 iterations, i.e. alpha=4.706e+11, with an active set of 229 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=4.653e+11, with an active set of 230 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 263 iterations, i.e. alpha=4.526e+11, with an active set of 237 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 266 iterations, i.e. alpha=4.483e+11, with an active set of 240 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 268 iterations, i.e. alpha=4.351e+11, with an active set of 242 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 268 iterations, i.e. alpha=4.351e+11, with an active set of 242 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 275 iterations, i.e. alpha=4.227e+11, with an active set of 249 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 275 iterations, i.e. alpha=4.225e+11, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 282 iterations, i.e. alpha=4.153e+11, with an active set of 255 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 282 iterations, i.e. alpha=4.153e+11, with an active set of 255 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 282 iterations, i.e. alpha=4.153e+11, with an active set of 255 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=4.135e+11, with an active set of 256 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=4.129e+11, with an active set of 256 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=4.091e+11, with an active set of 259 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=3.977e+11, with an active set of 265 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=3.975e+11, with an active set of 265 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 303 iterations, i.e. alpha=5.011e+11, with an active set of 270 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=5.164e+11, with an active set of 274 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 322 iterations, i.e. alpha=5.246e+11, with an active set of 283 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 331 iterations, i.e. alpha=5.496e+11, with an active set of 289 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 333 iterations, i.e. alpha=5.484e+11, with an active set of 291 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=5.381e+11, with an active set of 311 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 363 iterations, i.e. alpha=5.351e+11, with an active set of 314 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 366 iterations, i.e. alpha=5.339e+11, with an active set of 317 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 366 iterations, i.e. alpha=5.339e+11, with an active set of 317 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 366 iterations, i.e. alpha=5.243e+11, with an active set of 317 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 370 iterations, i.e. alpha=5.158e+11, with an active set of 321 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 382 iterations, i.e. alpha=5.040e+11, with an active set of 332 regressors, and the smallest cholesky pivot element being 7.814e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 382 iterations, i.e. alpha=5.031e+11, with an active set of 332 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 382 iterations, i.e. alpha=5.010e+11, with an active set of 332 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 391 iterations, i.e. alpha=4.938e+11, with an active set of 341 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 391 iterations, i.e. alpha=4.938e+11, with an active set of 341 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=4.910e+11, with an active set of 344 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=4.909e+11, with an active set of 344 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=4.876e+11, with an active set of 344 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=4.860e+11, with an active set of 344 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 397 iterations, i.e. alpha=4.834e+11, with an active set of 346 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 397 iterations, i.e. alpha=4.828e+11, with an active set of 346 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 403 iterations, i.e. alpha=4.796e+11, with an active set of 351 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 412 iterations, i.e. alpha=4.975e+11, with an active set of 357 regressors, and the smallest cholesky pivot element being 9.541e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 427 iterations, i.e. alpha=4.731e+11, with an active set of 370 regressors, and the smallest cholesky pivot element being 7.814e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 429 iterations, i.e. alpha=4.649e+11, with an active set of 372 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 435 iterations, i.e. alpha=4.606e+11, with an active set of 377 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 435 iterations, i.e. alpha=4.602e+11, with an active set of 377 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 435 iterations, i.e. alpha=4.598e+11, with an active set of 377 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 438 iterations, i.e. alpha=4.517e+11, with an active set of 380 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 438 iterations, i.e. alpha=4.515e+11, with an active set of 380 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 438 iterations, i.e. alpha=4.515e+11, with an active set of 380 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 442 iterations, i.e. alpha=4.417e+11, with an active set of 384 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 442 iterations, i.e. alpha=4.383e+11, with an active set of 384 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=1.097e+05, with an active set of 47 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=9.462e+04, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=7.920e+04, with an active set of 68 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=7.392e+04, with an active set of 71 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=6.999e+04, with an active set of 77 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 83 iterations, i.e. alpha=6.631e+04, with an active set of 81 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 87 iterations, i.e. alpha=6.621e+04, with an active set of 85 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 91 iterations, i.e. alpha=6.343e+04, with an active set of 89 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=6.046e+04, with an active set of 98 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=5.973e+04, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=5.973e+04, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=5.973e+04, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=5.478e+04, with an active set of 119 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 122 iterations, i.e. alpha=5.476e+04, with an active set of 120 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=5.336e+04, with an active set of 123 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=4.903e+04, with an active set of 133 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=4.903e+04, with an active set of 133 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 140 iterations, i.e. alpha=4.828e+04, with an active set of 138 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 145 iterations, i.e. alpha=4.783e+04, with an active set of 142 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 155 iterations, i.e. alpha=4.338e+04, with an active set of 150 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 172 iterations, i.e. alpha=4.768e+04, with an active set of 160 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 184 iterations, i.e. alpha=4.708e+04, with an active set of 169 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 186 iterations, i.e. alpha=4.577e+04, with an active set of 171 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 220 iterations, i.e. alpha=4.831e+04, with an active set of 197 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 227 iterations, i.e. alpha=4.860e+04, with an active set of 202 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 233 iterations, i.e. alpha=4.707e+04, with an active set of 208 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 252 iterations, i.e. alpha=5.837e+04, with an active set of 220 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=1.683e+05, with an active set of 234 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 319 iterations, i.e. alpha=1.617e+05, with an active set of 267 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 339 iterations, i.e. alpha=1.573e+05, with an active set of 283 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 345 iterations, i.e. alpha=1.537e+05, with an active set of 287 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=1.589e+05, with an active set of 326 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 407 iterations, i.e. alpha=1.556e+05, with an active set of 339 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 407 iterations, i.e. alpha=1.556e+05, with an active set of 339 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=1.503e+05, with an active set of 359 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=1.503e+05, with an active set of 359 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 428 iterations, i.e. alpha=1.484e+05, with an active set of 359 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 432 iterations, i.e. alpha=1.458e+05, with an active set of 363 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 436 iterations, i.e. alpha=1.427e+05, with an active set of 366 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 439 iterations, i.e. alpha=1.394e+05, with an active set of 369 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 439 iterations, i.e. alpha=1.389e+05, with an active set of 369 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 439 iterations, i.e. alpha=1.384e+05, with an active set of 369 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 442 iterations, i.e. alpha=1.359e+05, with an active set of 372 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 442 iterations, i.e. alpha=1.359e+05, with an active set of 372 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 442 iterations, i.e. alpha=1.359e+05, with an active set of 372 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 442 iterations, i.e. alpha=1.356e+05, with an active set of 372 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 445 iterations, i.e. alpha=1.327e+05, with an active set of 375 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 445 iterations, i.e. alpha=1.321e+05, with an active set of 375 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 445 iterations, i.e. alpha=1.320e+05, with an active set of 375 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 447 iterations, i.e. alpha=1.306e+05, with an active set of 377 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 448 iterations, i.e. alpha=1.293e+05, with an active set of 378 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 449 iterations, i.e. alpha=1.283e+05, with an active set of 379 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 449 iterations, i.e. alpha=1.283e+05, with an active set of 379 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 450 iterations, i.e. alpha=1.280e+05, with an active set of 380 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 450 iterations, i.e. alpha=1.277e+05, with an active set of 380 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 450 iterations, i.e. alpha=1.273e+05, with an active set of 380 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 452 iterations, i.e. alpha=1.240e+05, with an active set of 382 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 452 iterations, i.e. alpha=1.218e+05, with an active set of 382 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 452 iterations, i.e. alpha=1.213e+05, with an active set of 382 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 458 iterations, i.e. alpha=1.201e+05, with an active set of 387 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 458 iterations, i.e. alpha=1.201e+05, with an active set of 387 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 458 iterations, i.e. alpha=1.201e+05, with an active set of 387 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 463 iterations, i.e. alpha=1.184e+05, with an active set of 392 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 463 iterations, i.e. alpha=1.184e+05, with an active set of 392 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 469 iterations, i.e. alpha=1.159e+05, with an active set of 397 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 469 iterations, i.e. alpha=1.139e+05, with an active set of 397 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 469 iterations, i.e. alpha=1.139e+05, with an active set of 397 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 469 iterations, i.e. alpha=1.133e+05, with an active set of 397 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 469 iterations, i.e. alpha=1.133e+05, with an active set of 397 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 470 iterations, i.e. alpha=1.128e+05, with an active set of 398 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 470 iterations, i.e. alpha=1.128e+05, with an active set of 398 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 473 iterations, i.e. alpha=1.123e+05, with an active set of 400 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 476 iterations, i.e. alpha=1.107e+05, with an active set of 402 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 476 iterations, i.e. alpha=1.107e+05, with an active set of 402 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 476 iterations, i.e. alpha=1.107e+05, with an active set of 402 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 476 iterations, i.e. alpha=1.107e+05, with an active set of 402 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 476 iterations, i.e. alpha=1.104e+05, with an active set of 402 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 479 iterations, i.e. alpha=1.094e+05, with an active set of 404 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 486 iterations, i.e. alpha=1.096e+05, with an active set of 408 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 486 iterations, i.e. alpha=1.095e+05, with an active set of 408 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 486 iterations, i.e. alpha=1.078e+05, with an active set of 408 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 486 iterations, i.e. alpha=1.066e+05, with an active set of 408 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 486 iterations, i.e. alpha=1.065e+05, with an active set of 408 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 492 iterations, i.e. alpha=1.051e+05, with an active set of 413 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 492 iterations, i.e. alpha=1.028e+05, with an active set of 413 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 492 iterations, i.e. alpha=1.019e+05, with an active set of 413 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 492 iterations, i.e. alpha=1.016e+05, with an active set of 413 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.558e-06, with an active set of 21 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.558e-06, with an active set of 21 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=8.587e-07, with an active set of 38 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=8.171e-07, with an active set of 40 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=7.789e-07, with an active set of 43 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=7.789e-07, with an active set of 43 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=6.595e-07, with an active set of 61 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=6.429e-07, with an active set of 63 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 77 iterations, i.e. alpha=5.821e-07, with an active set of 75 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 82 iterations, i.e. alpha=5.530e-07, with an active set of 80 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=5.463e-07, with an active set of 82 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=5.629e-07, with an active set of 93 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=5.470e-07, with an active set of 96 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=5.452e-07, with an active set of 97 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 106 iterations, i.e. alpha=5.027e-07, with an active set of 102 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=4.499e-07, with an active set of 114 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 130 iterations, i.e. alpha=4.100e-07, with an active set of 126 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 130 iterations, i.e. alpha=4.100e-07, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 130 iterations, i.e. alpha=4.023e-07, with an active set of 126 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 131 iterations, i.e. alpha=3.952e-07, with an active set of 127 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 131 iterations, i.e. alpha=3.952e-07, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=3.892e-07, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=3.875e-07, with an active set of 131 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 140 iterations, i.e. alpha=3.848e-07, with an active set of 136 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 141 iterations, i.e. alpha=3.839e-07, with an active set of 137 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 141 iterations, i.e. alpha=3.779e-07, with an active set of 137 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 141 iterations, i.e. alpha=3.779e-07, with an active set of 137 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 163 iterations, i.e. alpha=3.526e-07, with an active set of 154 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 163 iterations, i.e. alpha=3.526e-07, with an active set of 154 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 163 iterations, i.e. alpha=3.506e-07, with an active set of 154 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=3.421e-07, with an active set of 160 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=3.395e-07, with an active set of 162 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=3.395e-07, with an active set of 162 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=3.304e-07, with an active set of 166 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=3.264e-07, with an active set of 166 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 184 iterations, i.e. alpha=3.146e-07, with an active set of 175 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 186 iterations, i.e. alpha=3.130e-07, with an active set of 177 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 189 iterations, i.e. alpha=3.091e-07, with an active set of 180 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 190 iterations, i.e. alpha=3.085e-07, with an active set of 181 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 199 iterations, i.e. alpha=2.978e-07, with an active set of 190 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 201 iterations, i.e. alpha=2.939e-07, with an active set of 192 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 207 iterations, i.e. alpha=2.863e-07, with an active set of 198 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 207 iterations, i.e. alpha=2.857e-07, with an active set of 198 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 208 iterations, i.e. alpha=2.844e-07, with an active set of 199 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 209 iterations, i.e. alpha=2.833e-07, with an active set of 200 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 218 iterations, i.e. alpha=2.708e-07, with an active set of 208 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 218 iterations, i.e. alpha=2.699e-07, with an active set of 208 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 218 iterations, i.e. alpha=2.698e-07, with an active set of 208 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 224 iterations, i.e. alpha=2.646e-07, with an active set of 214 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 224 iterations, i.e. alpha=2.645e-07, with an active set of 214 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 225 iterations, i.e. alpha=2.597e-07, with an active set of 215 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 237 iterations, i.e. alpha=2.474e-07, with an active set of 227 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 237 iterations, i.e. alpha=2.474e-07, with an active set of 227 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 240 iterations, i.e. alpha=2.433e-07, with an active set of 230 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 240 iterations, i.e. alpha=2.426e-07, with an active set of 230 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 247 iterations, i.e. alpha=2.373e-07, with an active set of 236 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 250 iterations, i.e. alpha=2.345e-07, with an active set of 239 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 268 iterations, i.e. alpha=2.256e-07, with an active set of 248 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 268 iterations, i.e. alpha=2.248e-07, with an active set of 248 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 268 iterations, i.e. alpha=2.225e-07, with an active set of 248 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 281 iterations, i.e. alpha=2.171e-07, with an active set of 258 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 281 iterations, i.e. alpha=2.153e-07, with an active set of 258 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 281 iterations, i.e. alpha=2.153e-07, with an active set of 258 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=2.143e-07, with an active set of 263 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=2.143e-07, with an active set of 263 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 320 iterations, i.e. alpha=1.959e-07, with an active set of 291 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 321 iterations, i.e. alpha=1.950e-07, with an active set of 292 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 321 iterations, i.e. alpha=1.948e-07, with an active set of 292 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 321 iterations, i.e. alpha=1.946e-07, with an active set of 292 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 321 iterations, i.e. alpha=1.943e-07, with an active set of 292 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 321 iterations, i.e. alpha=1.942e-07, with an active set of 292 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 321 iterations, i.e. alpha=1.938e-07, with an active set of 292 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 326 iterations, i.e. alpha=1.916e-07, with an active set of 297 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 326 iterations, i.e. alpha=1.916e-07, with an active set of 297 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 326 iterations, i.e. alpha=1.914e-07, with an active set of 297 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 326 iterations, i.e. alpha=1.895e-07, with an active set of 297 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 326 iterations, i.e. alpha=1.895e-07, with an active set of 297 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 327 iterations, i.e. alpha=1.882e-07, with an active set of 298 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 329 iterations, i.e. alpha=1.871e-07, with an active set of 300 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 330 iterations, i.e. alpha=1.869e-07, with an active set of 301 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 330 iterations, i.e. alpha=1.867e-07, with an active set of 301 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 331 iterations, i.e. alpha=1.860e-07, with an active set of 302 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 333 iterations, i.e. alpha=1.842e-07, with an active set of 304 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 334 iterations, i.e. alpha=1.841e-07, with an active set of 305 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 334 iterations, i.e. alpha=1.827e-07, with an active set of 305 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 334 iterations, i.e. alpha=1.825e-07, with an active set of 305 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 335 iterations, i.e. alpha=1.823e-07, with an active set of 306 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=1.696e-07, with an active set of 328 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=1.696e-07, with an active set of 328 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=1.683e-07, with an active set of 329 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 366 iterations, i.e. alpha=1.654e-07, with an active set of 334 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 370 iterations, i.e. alpha=1.649e-07, with an active set of 338 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 370 iterations, i.e. alpha=1.649e-07, with an active set of 338 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 370 iterations, i.e. alpha=1.649e-07, with an active set of 338 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 373 iterations, i.e. alpha=1.628e-07, with an active set of 341 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 373 iterations, i.e. alpha=1.626e-07, with an active set of 341 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 376 iterations, i.e. alpha=1.598e-07, with an active set of 344 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 376 iterations, i.e. alpha=1.598e-07, with an active set of 344 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 377 iterations, i.e. alpha=1.597e-07, with an active set of 345 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 379 iterations, i.e. alpha=1.582e-07, with an active set of 346 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 379 iterations, i.e. alpha=1.575e-07, with an active set of 346 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 380 iterations, i.e. alpha=1.572e-07, with an active set of 347 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 380 iterations, i.e. alpha=1.557e-07, with an active set of 347 regressors, and the smallest cholesky pivot element being 9.541e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 380 iterations, i.e. alpha=1.554e-07, with an active set of 347 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 385 iterations, i.e. alpha=1.546e-07, with an active set of 349 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 385 iterations, i.e. alpha=1.540e-07, with an active set of 349 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 386 iterations, i.e. alpha=1.533e-07, with an active set of 350 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 392 iterations, i.e. alpha=1.508e-07, with an active set of 355 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 392 iterations, i.e. alpha=1.508e-07, with an active set of 355 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 392 iterations, i.e. alpha=1.501e-07, with an active set of 355 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=1.492e-07, with an active set of 356 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 396 iterations, i.e. alpha=1.479e-07, with an active set of 358 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 396 iterations, i.e. alpha=1.477e-07, with an active set of 358 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 399 iterations, i.e. alpha=1.446e-07, with an active set of 360 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 402 iterations, i.e. alpha=1.435e-07, with an active set of 363 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 404 iterations, i.e. alpha=1.425e-07, with an active set of 365 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 406 iterations, i.e. alpha=1.394e-07, with an active set of 367 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 410 iterations, i.e. alpha=1.431e-07, with an active set of 369 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 411 iterations, i.e. alpha=1.381e-07, with an active set of 370 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 411 iterations, i.e. alpha=1.379e-07, with an active set of 370 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 411 iterations, i.e. alpha=1.375e-07, with an active set of 370 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 418 iterations, i.e. alpha=1.330e-07, with an active set of 377 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 418 iterations, i.e. alpha=1.322e-07, with an active set of 377 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 424 iterations, i.e. alpha=1.370e-07, with an active set of 379 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 427 iterations, i.e. alpha=1.304e-07, with an active set of 382 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 427 iterations, i.e. alpha=1.304e-07, with an active set of 382 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 429 iterations, i.e. alpha=1.276e-07, with an active set of 384 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 429 iterations, i.e. alpha=1.276e-07, with an active set of 384 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 438 iterations, i.e. alpha=1.243e-07, with an active set of 391 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 445 iterations, i.e. alpha=1.215e-07, with an active set of 397 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 445 iterations, i.e. alpha=1.209e-07, with an active set of 397 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 445 iterations, i.e. alpha=1.205e-07, with an active set of 397 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 445 iterations, i.e. alpha=1.203e-07, with an active set of 397 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 445 iterations, i.e. alpha=1.201e-07, with an active set of 397 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 7, 0, 0])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fsfc.generic import MCFS\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('select', MCFS(30,3)),\n",
    "    ('cluster', KMeans())\n",
    "])\n",
    "pipeline.fit_predict(np.array(B117_test.iloc[:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.083e+12, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=1.366e+12, with an active set of 52 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=1.203e+12, with an active set of 62 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=1.177e+12, with an active set of 65 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=1.169e+12, with an active set of 66 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=1.080e+12, with an active set of 75 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=1.080e+12, with an active set of 75 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=1.044e+12, with an active set of 80 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 92 iterations, i.e. alpha=1.017e+12, with an active set of 83 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=8.468e+11, with an active set of 102 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 140 iterations, i.e. alpha=7.119e+11, with an active set of 128 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 153 iterations, i.e. alpha=6.766e+11, with an active set of 140 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=6.564e+11, with an active set of 148 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.213e+11, with an active set of 158 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.213e+11, with an active set of 158 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.213e+11, with an active set of 158 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.210e+11, with an active set of 158 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.202e+11, with an active set of 158 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=6.129e+11, with an active set of 159 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=6.080e+11, with an active set of 159 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=6.068e+11, with an active set of 160 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=5.944e+11, with an active set of 162 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=5.944e+11, with an active set of 162 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 187 iterations, i.e. alpha=5.868e+11, with an active set of 169 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 194 iterations, i.e. alpha=5.563e+11, with an active set of 175 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 197 iterations, i.e. alpha=5.511e+11, with an active set of 178 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 202 iterations, i.e. alpha=5.445e+11, with an active set of 183 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 202 iterations, i.e. alpha=5.445e+11, with an active set of 183 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 211 iterations, i.e. alpha=5.209e+11, with an active set of 191 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 211 iterations, i.e. alpha=5.207e+11, with an active set of 191 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 219 iterations, i.e. alpha=5.086e+11, with an active set of 197 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 221 iterations, i.e. alpha=5.021e+11, with an active set of 199 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 238 iterations, i.e. alpha=4.978e+11, with an active set of 213 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 238 iterations, i.e. alpha=4.978e+11, with an active set of 213 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 239 iterations, i.e. alpha=4.962e+11, with an active set of 214 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 254 iterations, i.e. alpha=4.717e+11, with an active set of 228 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 255 iterations, i.e. alpha=4.706e+11, with an active set of 229 regressors, and the smallest cholesky pivot element being 9.599e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 255 iterations, i.e. alpha=4.706e+11, with an active set of 229 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=4.653e+11, with an active set of 230 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 263 iterations, i.e. alpha=4.526e+11, with an active set of 237 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 266 iterations, i.e. alpha=4.483e+11, with an active set of 240 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 268 iterations, i.e. alpha=4.351e+11, with an active set of 242 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 268 iterations, i.e. alpha=4.351e+11, with an active set of 242 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 275 iterations, i.e. alpha=4.227e+11, with an active set of 249 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 275 iterations, i.e. alpha=4.225e+11, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 282 iterations, i.e. alpha=4.153e+11, with an active set of 255 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 282 iterations, i.e. alpha=4.153e+11, with an active set of 255 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 282 iterations, i.e. alpha=4.153e+11, with an active set of 255 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=4.135e+11, with an active set of 256 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=4.129e+11, with an active set of 256 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=4.091e+11, with an active set of 259 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=3.977e+11, with an active set of 265 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 292 iterations, i.e. alpha=3.975e+11, with an active set of 265 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 303 iterations, i.e. alpha=5.011e+11, with an active set of 270 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=5.164e+11, with an active set of 274 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 322 iterations, i.e. alpha=5.246e+11, with an active set of 283 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 331 iterations, i.e. alpha=5.496e+11, with an active set of 289 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 333 iterations, i.e. alpha=5.484e+11, with an active set of 291 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=5.381e+11, with an active set of 311 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 363 iterations, i.e. alpha=5.351e+11, with an active set of 314 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 366 iterations, i.e. alpha=5.339e+11, with an active set of 317 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 366 iterations, i.e. alpha=5.339e+11, with an active set of 317 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 366 iterations, i.e. alpha=5.243e+11, with an active set of 317 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 370 iterations, i.e. alpha=5.158e+11, with an active set of 321 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 382 iterations, i.e. alpha=5.040e+11, with an active set of 332 regressors, and the smallest cholesky pivot element being 7.814e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 382 iterations, i.e. alpha=5.031e+11, with an active set of 332 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 382 iterations, i.e. alpha=5.010e+11, with an active set of 332 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 391 iterations, i.e. alpha=4.938e+11, with an active set of 341 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 391 iterations, i.e. alpha=4.938e+11, with an active set of 341 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=4.910e+11, with an active set of 344 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=4.909e+11, with an active set of 344 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=4.876e+11, with an active set of 344 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=4.860e+11, with an active set of 344 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 397 iterations, i.e. alpha=4.834e+11, with an active set of 346 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 397 iterations, i.e. alpha=4.828e+11, with an active set of 346 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 403 iterations, i.e. alpha=4.796e+11, with an active set of 351 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 412 iterations, i.e. alpha=4.975e+11, with an active set of 357 regressors, and the smallest cholesky pivot element being 9.541e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 427 iterations, i.e. alpha=4.731e+11, with an active set of 370 regressors, and the smallest cholesky pivot element being 7.814e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 429 iterations, i.e. alpha=4.649e+11, with an active set of 372 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 435 iterations, i.e. alpha=4.606e+11, with an active set of 377 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 435 iterations, i.e. alpha=4.602e+11, with an active set of 377 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 435 iterations, i.e. alpha=4.598e+11, with an active set of 377 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 438 iterations, i.e. alpha=4.517e+11, with an active set of 380 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 438 iterations, i.e. alpha=4.515e+11, with an active set of 380 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 438 iterations, i.e. alpha=4.515e+11, with an active set of 380 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 442 iterations, i.e. alpha=4.417e+11, with an active set of 384 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 442 iterations, i.e. alpha=4.383e+11, with an active set of 384 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.linear_model import LassoLars, Lars\n",
    "from scipy.linalg import eigh\n",
    "from fsfc.base import KBestFeatureSelector\n",
    "\n",
    "x = np.array(B117_test.iloc[:,:])\n",
    "clusters = 1\n",
    "p=8\n",
    "sigma=1\n",
    "mode='default'\n",
    "alpha=0.01\n",
    "\n",
    "def create_regressor(mode,alpha):\n",
    "    if mode == 'default':\n",
    "        return Lars()\n",
    "    if mode == 'lasso':\n",
    "        return LassoLars(alpha=alpha)\n",
    "    raise ValueError('Unexpected mode ' + mode + '. Expected \"default\" or \"lasso\"')\n",
    "\n",
    "graph = kneighbors_graph(\n",
    "            x,\n",
    "            n_neighbors=p,\n",
    "        )\n",
    "        # Construct the heat matrix\n",
    "w = np.zeros([x.shape[0], x.shape[0]])\n",
    "rows, cols = graph.nonzero()\n",
    "for i, j in zip(rows, cols):\n",
    "    w[i, j] = math.exp(-np.linalg.norm(x[i] - x[j])**2/sigma)\n",
    "\n",
    "# Compute degree and Laplacian matrices\n",
    "degree_vector = np.sum(w, 1)\n",
    "degree = np.diag(degree_vector)\n",
    "laplacian = degree - w\n",
    "\n",
    "# Solve the eigen-problem\n",
    "values, vectors = eigh(laplacian, degree)\n",
    "smallest = vectors[:, 0:clusters].T\n",
    "\n",
    "# Find coefficients for each cluster\n",
    "coefs = []\n",
    "for i in range(clusters):\n",
    "    this_coefs = create_regressor(mode,alpha).fit(x, smallest[i]).coef_\n",
    "    coefs.append(this_coefs)\n",
    "coefs = np.array(coefs)\n",
    "\n",
    "# Compute MCFS-scores\n",
    "scores = np.max(coefs, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "indices = np.argsort(scores)[-30:]  # top 20 features\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)),scores[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [B117_test.columns[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21, 26, 39, 46, 188, 221, 571, 685, 689, 727, 735, 749, 754, 755, 762, 777]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_mutations = [3267,5388,6954,11288,11289,11290,11291,11292,11293,11294,11295,11296,\n",
    "                21765,21766,21767,21768,21769,21770,21991,21992,21993,23063,23271,23604\n",
    "                ,23709,24506,24914,27972,28048,28111,28280,28977]\n",
    "\n",
    "fea_name = []\n",
    "sel_fea = list(pd.Series(scores).sort_values(ascending=False).index[:])\n",
    "for i in sel_fea:\n",
    "    fea_name.append(list(B117_test.columns)[i])\n",
    "rank_def = []\n",
    "sel_def = []\n",
    "for i in range(len(fea_name)):\n",
    "    if int(fea_name[i]) in def_mutations:\n",
    "        rank_def.append(i)\n",
    "        sel_def.append(fea_name[i])\n",
    "rank_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['23604',\n",
       " '23063',\n",
       " '28111',\n",
       " '28977',\n",
       " '6954',\n",
       " '27972',\n",
       " '28280',\n",
       " '28048',\n",
       " '3267',\n",
       " '24506',\n",
       " '24914',\n",
       " '21765',\n",
       " '21769',\n",
       " '23271',\n",
       " '23709',\n",
       " '5388']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sel_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1037: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=5.\n",
      "  \"KMeans is known to have a memory leak on Windows \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18909.599060297598"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B117_SEL = np.array(B117_test.iloc[:,:])[:,list(np.where( scores > 3.0e+17)[0])]\n",
    "Kmeans = KMeans(n_clusters=1)\n",
    "Kmeans.fit(B117_SEL)\n",
    "Kmeans.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(np.where( scores > 3.0e+17)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(B117_SEL[:,:-1])\n",
    "\n",
    "# Project data onto first two principal components\n",
    "projX = pca.transform(B117_SEL[:,:-1])\n",
    "plt.figure(figsize=(30,15))\n",
    "\n",
    "scatter = plt.scatter(projX[:,0],projX[:,1],cmap='rainbow')\n",
    "\n",
    "plt.title('Projected data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_W(X, neighbour_size = 5, t = 1):\n",
    "    n_samples, n_features = np.shape(X)\n",
    "    S=kneighbors_graph(X, neighbour_size+1, mode='distance',metric='euclidean') #sqecludian distance works only with mode=connectivity  results were absurd\n",
    "    S = (-1*(S*S))/(2*t*t)\n",
    "    S=S.tocsc()\n",
    "    S=expm(S) # exponential\n",
    "    S=S.tocsr()\n",
    "    #[1]  M. Belkin and P. Niyogi, “Laplacian Eigenmaps and Spectral Techniques for Embedding and Clustering,” Advances in Neural Information Processing Systems,\n",
    "    #Vol. 14, 2001. Following the paper to make the weights matrix symmetrix we use this method\n",
    "    bigger = np.transpose(S) > S\n",
    "    S = S - S.multiply(bigger) + np.transpose(S).multiply(bigger)\n",
    "    return S\n",
    "\n",
    "def LaplacianScore(X, neighbour_size = 5,  t = 1):\n",
    "    W = construct_W(X,t=t,neighbour_size=neighbour_size)\n",
    "    n_samples, n_features = np.shape(X)\n",
    "    \n",
    "    #construct the diagonal matrix\n",
    "    D=np.array(W.sum(axis=1))\n",
    "    D = scipy.sparse.diags(np.transpose(D), [0])\n",
    "    #construct graph Laplacian L\n",
    "    L=D-W.toarray()\n",
    "\n",
    "    #construct 1= [1,···,1]' \n",
    "    I=np.ones((n_samples,n_features))\n",
    "\n",
    "    #construct fr' => fr= [fr1,...,frn]'\n",
    "    Xt = np.transpose(X)\n",
    "\n",
    "    #construct fr^=fr-(frt D I/It D I)I\n",
    "    t=np.matmul(np.matmul(Xt,D.toarray()),I)/np.matmul(np.matmul(np.transpose(I),D.toarray()),I)\n",
    "    t=t[:,0]\n",
    "    t=np.tile(t,(n_samples,1))\n",
    "    fr=X-t\n",
    "\n",
    "    #Compute Laplacian Score\n",
    "    fr_t=np.transpose(fr)\n",
    "    Lr=np.matmul(np.matmul(fr_t,L),fr)/np.matmul(np.dot(fr_t,D.toarray()),fr)\n",
    "\n",
    "    return np.diag(Lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:38: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'21624': -36.98079447927042,\n",
       " '18618': -13.915974035416486,\n",
       " '26469': -7.624204791064094,\n",
       " '7684': -0.0011285442952700178,\n",
       " '25818': -0.0005040112798038117,\n",
       " '28027': -2.335747606367861e-06,\n",
       " '29253': -1.470969511842295e-06,\n",
       " '17019': -4.005329642460948e-08,\n",
       " '6813': -8.639478195447213e-11,\n",
       " '7675': -8.639478195447213e-11,\n",
       " '23757': -8.639478195447213e-11,\n",
       " '23429': -1.290672262830668e-12,\n",
       " '8453': -9.813082824909354e-17,\n",
       " '27059': -4.0788845847758146e-17,\n",
       " '28657': -2.2854404062265795e-17,\n",
       " '3706': -1.1327753595845307e-17,\n",
       " '3178': -9.548330214782075e-18,\n",
       " '346': -7.982336490566984e-18,\n",
       " '16954': -7.982336490566984e-18,\n",
       " '16182': -1.761713483296737e-18,\n",
       " '2272': -2.192612418339175e-21,\n",
       " '3728': -2.192612418339175e-21,\n",
       " '17502': -2.192612418339175e-21,\n",
       " '18384': -2.192612418339175e-21,\n",
       " '23084': -2.192612418339175e-21,\n",
       " '27754': -2.192612418339175e-21,\n",
       " '15046': -1.1322713227946076e-21,\n",
       " '25481': -1.034275275954654e-21,\n",
       " '10702': -1.0046404814295688e-21,\n",
       " '5175': -5.171325219653559e-22,\n",
       " '24004': -5.171325219653559e-22,\n",
       " '29118': -5.171325219653559e-22,\n",
       " '14724': -5.0231572306035705e-22,\n",
       " '27670': -4.887589465595178e-22,\n",
       " '12008': -4.1943542510914567e-22,\n",
       " '6828': -4.1943542510914557e-22,\n",
       " '3403': -3.563153945131314e-22,\n",
       " '25459': -2.831319662206917e-22,\n",
       " '1514': -2.511567321318079e-22,\n",
       " '2494': -2.511567321318079e-22,\n",
       " '29688': -2.511567321318078e-22,\n",
       " '4784': -2.5115673213180677e-22,\n",
       " '17122': -2.5115673213180677e-22,\n",
       " '20679': -2.5115673213180677e-22,\n",
       " '21621': -2.5115673213180677e-22,\n",
       " '24109': -2.5115673213180677e-22,\n",
       " '21842': -2.375429554345958e-22,\n",
       " '11401': -1.3953123898902049e-22,\n",
       " '4551': -1.2192507390193481e-22,\n",
       " '7384': -1.1877115726528094e-22,\n",
       " '21137': -1.0242650087658184e-22,\n",
       " '28198': -6.382017157572945e-23,\n",
       " '17058': -5.775231114153642e-23,\n",
       " '16707': -5.477629937295524e-23,\n",
       " '22225': -4.387622446570771e-23,\n",
       " '24328': -2.193803331246244e-23,\n",
       " '8683': -2.1938033312462422e-23,\n",
       " '7834': -2.193803331246242e-23,\n",
       " '15222': -2.193803331246242e-23,\n",
       " '151': -2.1938033312462413e-23,\n",
       " '2334': -1.6162388960581232e-23,\n",
       " '29200': -1.4363477831094406e-23,\n",
       " '539': -1.3288658063197038e-23,\n",
       " '23593': -1.0968996926239823e-23,\n",
       " '23191': -1.0968996926239823e-23,\n",
       " '26510': -1.0968996926239823e-23,\n",
       " '10642': -1.0968996926239823e-23,\n",
       " '9223': -1.0968996926239821e-23,\n",
       " '18981': -1.096899692623982e-23,\n",
       " '26822': -1.0968996926239818e-23,\n",
       " '9967': -1.0968996926239818e-23,\n",
       " '21485': -1.0968996926239818e-23,\n",
       " '1519': -1.0968996926239818e-23,\n",
       " '4476': -1.0968996926239818e-23,\n",
       " '8240': -1.0968996926239818e-23,\n",
       " '12374': -1.0968996926239818e-23,\n",
       " '27987': -1.0968996926239818e-23,\n",
       " '29440': -1.0968996926239818e-23,\n",
       " '12128': -1.0968996926239817e-23,\n",
       " '606': -1.0968996926239817e-23,\n",
       " '7162': -1.0968996926239817e-23,\n",
       " '12988': -1.0968996926239817e-23,\n",
       " '15394': -1.0968996926239817e-23,\n",
       " '18557': -1.0968996926239817e-23,\n",
       " '6706': -1.0968996926239817e-23,\n",
       " '27261': -1.0968996926239817e-23,\n",
       " '12295': -1.0968996926239815e-23,\n",
       " '14658': -1.0968996926239815e-23,\n",
       " '20703': -1.0968996926239815e-23,\n",
       " '25677': -1.0968996926239815e-23,\n",
       " '25810': -1.0968996926239815e-23,\n",
       " '2332': -1.0968996926239812e-23,\n",
       " '180': -1.0968996926239811e-23,\n",
       " '6336': -1.0968996926239811e-23,\n",
       " '23896': -1.0968996926239811e-23,\n",
       " '28393': -1.0968996926239811e-23,\n",
       " '1708': -1.0968996926239808e-23,\n",
       " '11967': -1.0968996926239808e-23,\n",
       " '21048': -1.0968996926239808e-23,\n",
       " '29868': -1.0968996926239808e-23,\n",
       " '745': -1.0968996926239808e-23,\n",
       " '3141': -1.0968996926239808e-23,\n",
       " '18303': -1.0968996926239806e-23,\n",
       " '17259': -1.0968996926239805e-23,\n",
       " '26056': -1.0968996926239804e-23,\n",
       " '23628': -1.09689969262398e-23,\n",
       " '26353': -1.09689969262398e-23,\n",
       " '3987': -1.09689969262398e-23,\n",
       " '29810': -1.0509084587827424e-23,\n",
       " '21765': -5.484493530635373e-24,\n",
       " '11698': -5.484493530635371e-24,\n",
       " '29764': -5.484493530635368e-24,\n",
       " '29692': -5.484493530635368e-24,\n",
       " '28141': -3.720807392208307e-24,\n",
       " '5974': -3.35918946608023e-24,\n",
       " '27494': -1.3797424337794764e-26,\n",
       " '5144': -1.3517443121536883e-26,\n",
       " '8950': -1.3517443121536883e-26,\n",
       " '24919': -1.3517443121536883e-26,\n",
       " '18828': -1.3517443121536878e-26,\n",
       " '26060': -1.3517443121536878e-26,\n",
       " '28511': -1.3517443121536878e-26,\n",
       " '29739': -1.3517443121536878e-26,\n",
       " '4464': -1.3517443121536875e-26,\n",
       " '27549': -1.3517443121536875e-26,\n",
       " '28001': -1.3517443121536872e-26,\n",
       " '1839': -9.198282889088064e-27,\n",
       " '5192': -2.6322624118631868e-28,\n",
       " '23416': -2.6322624118631868e-28,\n",
       " '25596': -2.6322624118631868e-28,\n",
       " '29661': -2.6322624118631868e-28,\n",
       " '24695': -1.4532960495295843e-29,\n",
       " '25613': -6.890033021447451e-30,\n",
       " '685': -3.441641170399934e-30,\n",
       " '13788': -3.441641170399934e-30,\n",
       " '17795': -3.1727183647438206e-37,\n",
       " '27263': -3.1727183647438206e-37,\n",
       " '12880': -6.089005519971049e-40,\n",
       " '22992': -6.089005519971049e-40,\n",
       " '12410': 4.6747200317888615e-24,\n",
       " '25536': 4.6747200317888615e-24,\n",
       " '11600': 4.674720031788862e-24,\n",
       " '5268': 4.674720031788862e-24,\n",
       " '10646': 4.674720031788866e-24,\n",
       " '29413': 4.674720031788867e-24,\n",
       " '101': 7.012086354009903e-24,\n",
       " '24374': 7.012086354009903e-24,\n",
       " '6533': 7.012086354009903e-24,\n",
       " '17307': 7.012086354009905e-24,\n",
       " '21929': 7.012086354009906e-24,\n",
       " '13368': 7.012086354009906e-24,\n",
       " '25614': 7.012086354009906e-24,\n",
       " '1507': 7.012086354009906e-24,\n",
       " '29256': 7.012086354009906e-24,\n",
       " '27217': 7.012086354009908e-24,\n",
       " '6843': 7.012086354009909e-24,\n",
       " '11494': 7.012086354009909e-24,\n",
       " '15378': 7.012086354009909e-24,\n",
       " '25685': 7.012086354009909e-24,\n",
       " '27643': 7.012086354009909e-24,\n",
       " '27598': 7.01208635400991e-24,\n",
       " '29449': 7.01208635400991e-24,\n",
       " '8986': 8.337360767535995e-24,\n",
       " '5264': 9.349456880463826e-24,\n",
       " '12741': 2.804857244583967e-23,\n",
       " '26047': 3.72791069876536e-22,\n",
       " '2119': 1.4378778945519873e-18,\n",
       " '25638': 1.4378778945519875e-18,\n",
       " '905': 1.4724486375920274e-18,\n",
       " '27703': 1.700757887564131e-18,\n",
       " '17124': 4.3553374231807324e-18,\n",
       " '9443': 4.458962119645628e-18,\n",
       " '7063': 9.359102980175235e-18,\n",
       " '8917': 9.712197088086159e-18,\n",
       " '27240': 9.712197088086159e-18,\n",
       " '21691': 1.1419328604095111e-17,\n",
       " '526': 1.5077439432882067e-17,\n",
       " '2062': 1.615764251732685e-17,\n",
       " '10408': 1.891761834502085e-17,\n",
       " '21855': 1.891761834502085e-17,\n",
       " '19887': 2.3404680679855385e-17,\n",
       " '28295': 2.3404680679855385e-17,\n",
       " '843': 2.805275001147101e-17,\n",
       " '8802': 2.805275001147101e-17,\n",
       " '19374': 2.805275001147101e-17,\n",
       " '26052': 2.805275001147101e-17,\n",
       " '8140': 3.3485941815981864e-17,\n",
       " '10969': 3.819272781482054e-17,\n",
       " '20595': 6.371776274209149e-17,\n",
       " '25146': 6.845801529885782e-17,\n",
       " '911': 1.0970700192250473e-12,\n",
       " '8650': 1.0970700192250473e-12,\n",
       " '12439': 3.448294228688347e-10,\n",
       " '13126': 3.448294228688347e-10,\n",
       " '23083': 3.448294228688347e-10,\n",
       " '27641': 3.448294228688347e-10,\n",
       " '15101': 0.0001277232681413958,\n",
       " '23277': 0.000470041063142502,\n",
       " '29543': 0.0026405220769836,\n",
       " '27804': 0.010505112453667037,\n",
       " '269': 0.01340623238223006,\n",
       " '25785': 0.015799532277440013,\n",
       " '26622': 0.03456640535019362,\n",
       " '7600': 0.038705556057510825,\n",
       " '28739': 0.04224900907261657,\n",
       " '2221': 0.06350071924376291,\n",
       " '1309': 0.0643231108439321,\n",
       " '16887': 0.07223521740506922,\n",
       " '18060': 0.07648767083231349,\n",
       " '7034': 0.08286026171960784,\n",
       " '5284': 0.09412665187206144,\n",
       " '13536': 0.10916951876729326,\n",
       " '25218': 0.10916951876729326,\n",
       " '27615': 0.10916951876729326,\n",
       " '2146': 0.1259562475215051,\n",
       " '17733': 0.13092630765280497,\n",
       " '4510': 0.1409366400759161,\n",
       " '15981': 0.14382797551364124,\n",
       " '24814': 0.14607960683511995,\n",
       " '25954': 0.1596596813317018,\n",
       " '1119': 0.19715942763654692,\n",
       " '21036': 0.22112760512826313,\n",
       " '29466': 0.24078834044658834,\n",
       " '6446': 0.25142088431047377,\n",
       " '28747': 0.25142088431047377,\n",
       " '18987': 0.25828475377986376,\n",
       " '25916': 0.27027872716602497,\n",
       " '26010': 0.2800335349285608,\n",
       " '3675': 0.28787961686249647,\n",
       " '5840': 0.28787961686249675,\n",
       " '21575': 0.28999200724955276,\n",
       " '4021': 0.3149280326232106,\n",
       " '18180': 0.3149280326232106,\n",
       " '5339': 0.32268854262469543,\n",
       " '14206': 0.32268854262469543,\n",
       " '23302': 0.32268854262469543,\n",
       " '28960': 0.32268854262469543,\n",
       " '174': 0.3583853084176335,\n",
       " '10188': 0.37035184130300886,\n",
       " '27389': 0.40578660790289495,\n",
       " '3646': 0.4061117250251073,\n",
       " '29077': 0.4061292433610772,\n",
       " '25593': 0.40652760465484333,\n",
       " '29119': 0.40652760465484333,\n",
       " '1746': 0.4077582965373234,\n",
       " '12809': 0.4091796876928329,\n",
       " '21761': 0.41269647465316206,\n",
       " '683': 0.41433528873172754,\n",
       " '19586': 0.42504861140365635,\n",
       " '1973': 0.43320403627808673,\n",
       " '12235': 0.4448601699100422,\n",
       " '21769': 0.4451767234477371,\n",
       " '7308': 0.4462244359873045,\n",
       " '5230': 0.4502547342429279,\n",
       " '20148': 0.45756065668917967,\n",
       " '25784': 0.45813855434597306,\n",
       " '18936': 0.46239985372221093,\n",
       " '23441': 0.46239985372221093,\n",
       " '24378': 0.46239985372221093,\n",
       " '29140': 0.46798969400734625,\n",
       " '15352': 0.4764473220462228,\n",
       " '29461': 0.4807584533309087,\n",
       " '1779': 0.48126441365730577,\n",
       " '2233': 0.48126441365730577,\n",
       " '20594': 0.48126441365730577,\n",
       " '25413': 0.48126441365730577,\n",
       " '29733': 0.48126441365730577,\n",
       " '26230': 0.49643130505001437,\n",
       " '23972': 0.5005604456252384,\n",
       " '88': 0.5285830902907672,\n",
       " '1573': 0.5290349400282589,\n",
       " '13425': 0.5352218863799963,\n",
       " '27534': 0.5352218863799963,\n",
       " '22244': 0.538079309074536,\n",
       " '15924': 0.5484129226527786,\n",
       " '7267': 0.5583989420402468,\n",
       " '7393': 0.5586611262963488,\n",
       " '1913': 0.5613474930365728,\n",
       " '7042': 0.5671833961626775,\n",
       " '22908': 0.5671833961626775,\n",
       " '608': 0.5767334783678506,\n",
       " '21974': 0.5770039375765855,\n",
       " '25624': 0.5780432415075812,\n",
       " '22104': 0.6022212859490574,\n",
       " '11650': 0.6069109252902156,\n",
       " '28091': 0.6277555933108513,\n",
       " '17211': 0.6348912770814755,\n",
       " '18600': 0.6361551370671101,\n",
       " '24095': 0.6515971090828572,\n",
       " '25244': 0.6555902650366074,\n",
       " '28320': 0.6555902650366074,\n",
       " '25726': 0.6593515684337574,\n",
       " '3305': 0.6616194225850477,\n",
       " '14511': 0.6713789168243499,\n",
       " '23986': 0.6737810995878468,\n",
       " '4809': 0.6908086944244908,\n",
       " '8083': 0.6908617690560671,\n",
       " '8179': 0.6949698693338844,\n",
       " '27881': 0.7022685496997828,\n",
       " '28011': 0.7095819493695271,\n",
       " '8106': 0.7125389977667966,\n",
       " '17977': 0.7232571926364256,\n",
       " '26620': 0.7240323051189449,\n",
       " '14318': 0.7325671769061795,\n",
       " '17334': 0.7375015964513081,\n",
       " '9803': 0.7396051930988643,\n",
       " '27406': 0.7405828493779535,\n",
       " '29774': 0.7448189180402172,\n",
       " '5481': 0.7489942385412951,\n",
       " '9246': 0.7572130694501632,\n",
       " '5427': 0.7631563570704136,\n",
       " '463': 0.784501632702887,\n",
       " '28896': 0.7875247078244682,\n",
       " '7429': 0.7917262391517331,\n",
       " '19164': 0.8018221655731043,\n",
       " '2144': 0.8176379453270755,\n",
       " '27867': 0.8262174381787735,\n",
       " '27870': 0.8262174381787735,\n",
       " '27880': 0.8262174381787735,\n",
       " '27883': 0.8262174381787735,\n",
       " '19572': 0.8299141868967645,\n",
       " '19602': 0.8367863491928736,\n",
       " '5907': 0.8369041476938143,\n",
       " '25549': 0.8381885907369852,\n",
       " '24418': 0.8495676346951154,\n",
       " '9391': 0.8537476381578329,\n",
       " '4321': 0.8540672261394382,\n",
       " '8146': 0.8540672261394382,\n",
       " '28146': 0.8563200368972949,\n",
       " '1427': 0.8573503374551442,\n",
       " '25401': 0.8573503374551442,\n",
       " '20279': 0.8594040294127034,\n",
       " '28214': 0.859783829844608,\n",
       " '21082': 0.865912307166822,\n",
       " '21083': 0.865912307166822,\n",
       " '28423': 0.8663024408382264,\n",
       " '3871': 0.8676350710193395,\n",
       " '12801': 0.874845787798923,\n",
       " '22471': 0.8770839747641149,\n",
       " '8964': 0.8832522917900226,\n",
       " '25822': 0.8878663006034516,\n",
       " '29648': 0.8901884422185624,\n",
       " '7967': 0.8966869717426719,\n",
       " '27509': 0.8966869717426719,\n",
       " '17406': 0.8966869717426736,\n",
       " '23030': 0.9007892255094679,\n",
       " '10504': 0.9053642334185041,\n",
       " '5884': 0.9054070154077057,\n",
       " '10228': 0.9097868308445964,\n",
       " '1812': 0.9119760330244804,\n",
       " '12049': 0.9129952699632123,\n",
       " '14877': 0.9184769903807216,\n",
       " '19018': 0.9191699176322586,\n",
       " '28541': 0.9201920826851498,\n",
       " '3635': 0.9216686804409085,\n",
       " '5055': 0.922446509016814,\n",
       " '27741': 0.923336276691811,\n",
       " '9112': 0.9253493902357005,\n",
       " '835': 0.925470069875686,\n",
       " '19687': 0.9256569823081648,\n",
       " '28315': 0.9293474170223303,\n",
       " '21595': 0.9327544262658332,\n",
       " '3338': 0.9369302936651622,\n",
       " '92': 0.9369700466135306,\n",
       " '27607': 0.9388037555546589,\n",
       " '22004': 0.9400873650893976,\n",
       " '5622': 0.941269325019654,\n",
       " '18105': 0.9419389768571169,\n",
       " '17193': 0.9439110613687745,\n",
       " '9190': 0.9441237233964221,\n",
       " '13348': 0.9447528672160168,\n",
       " '4540': 0.945547585843978,\n",
       " '19133': 0.945555006119552,\n",
       " '19129': 0.9455550061195523,\n",
       " '1148': 0.9457316359650499,\n",
       " '26256': 0.9464787794091899,\n",
       " '5812': 0.9467095998562535,\n",
       " '4973': 0.9485294054686898,\n",
       " '4795': 0.9488555163579097,\n",
       " '27773': 0.9488555163579097,\n",
       " '27393': 0.9508259672410083,\n",
       " '4499': 0.9519383848579818,\n",
       " '26873': 0.9519383848579825,\n",
       " '10252': 0.9529811183630634,\n",
       " '13792': 0.9542229858828403,\n",
       " '5826': 0.955410441241716,\n",
       " '8841': 0.9564968119717714,\n",
       " '5572': 0.9591997168060962,\n",
       " '27384': 0.9593408243386107,\n",
       " '6025': 0.9594778729216217,\n",
       " '9056': 0.9594778729216217,\n",
       " '26167': 0.9594778729216217,\n",
       " '13993': 0.9609964624030242,\n",
       " '22021': 0.9618066264809529,\n",
       " '25599': 0.9632638482097652,\n",
       " '27561': 0.9641058112332113,\n",
       " '28948': 0.9681626043016485,\n",
       " '27002': 0.9684438770217666,\n",
       " '20133': 0.9691375336114045,\n",
       " '16726': 0.9703245485984808,\n",
       " '24155': 0.9712888336305466,\n",
       " '7029': 0.9714061716661306,\n",
       " '25165': 0.9723046943535212,\n",
       " '14925': 0.9733275510625145,\n",
       " '20991': 0.9734084432119483,\n",
       " '4868': 0.9747770248052184,\n",
       " '11653': 0.9747770248052184,\n",
       " '23481': 0.9747770248052184,\n",
       " '10189': 0.9756724576638812,\n",
       " '25886': 0.9757018940798059,\n",
       " '7291': 0.9757018940798061,\n",
       " '20091': 0.9758918047951507,\n",
       " '2432': 0.9759930373769665,\n",
       " '17427': 0.9767697634998583,\n",
       " '3887': 0.9777924085907893,\n",
       " '10286': 0.9777924085907895,\n",
       " '10369': 0.9778161987352161,\n",
       " '29708': 0.9783045394303158,\n",
       " '29724': 0.9785519382782233,\n",
       " '20844': 0.9794062517552862,\n",
       " '5512': 0.9795400399522394,\n",
       " '21608': 0.9800752958310983,\n",
       " '17233': 0.9801778784055951,\n",
       " '25050': 0.9804130405061182,\n",
       " '21807': 0.9806085479450889,\n",
       " '14874': 0.9812015647547393,\n",
       " '26058': 0.9816065599372814,\n",
       " '27780': 0.9826530987194362,\n",
       " '7299': 0.9831784934648531,\n",
       " '625': 0.9844110127629866,\n",
       " '15911': 0.9851117805254525,\n",
       " '4012': 0.9855889887111547,\n",
       " '982': 0.985805200435346,\n",
       " '2201': 0.985805200435346,\n",
       " '17938': 0.985805200435346,\n",
       " '28171': 0.985805200435346,\n",
       " '15907': 0.9860051864565388,\n",
       " '25511': 0.9860159297926694,\n",
       " '929': 0.9861807948386009,\n",
       " '22014': 0.9874466599251336,\n",
       " '509': 0.9875552718443855,\n",
       " '29659': 0.9877646562409514,\n",
       " '27946': 0.9879040845063181,\n",
       " '214': 0.9886590080242726,\n",
       " '10741': 0.9892118272621546,\n",
       " '19709': 0.9892118272621546,\n",
       " '17615': 0.9892757581332601,\n",
       " '11758': 0.9894625228789989,\n",
       " '17814': 0.9894625228789989,\n",
       " '14186': 0.9895621888977594,\n",
       " '22681': 0.9897481287609925,\n",
       " '8637': 0.9906802218881168,\n",
       " '16770': 0.990876587864046,\n",
       " '29737': 0.9910578141654829,\n",
       " '21568': 0.9912753881092223,\n",
       " '13119': 0.9913054226860952,\n",
       " '29877': 0.9915096755772442,\n",
       " '18647': 0.9922116347534963,\n",
       " '29431': 0.9923447527468592,\n",
       " '22852': 0.9926228635103361,\n",
       " '7751': 0.9926228635103362,\n",
       " '15979': 0.9926510986568982,\n",
       " '664': 0.9926510986568983,\n",
       " '6982': 0.9926510986568983,\n",
       " '8084': 0.9926510986568983,\n",
       " '13487': 0.9926510986568983,\n",
       " '14599': 0.9926510986568983,\n",
       " '17976': 0.9926510986568983,\n",
       " '27711': 0.9926510986568983,\n",
       " '28313': 0.9926510986568983,\n",
       " '29098': 0.9926510986568983,\n",
       " '160': 0.9934291437936932,\n",
       " '5842': 0.9935615658880297,\n",
       " '7840': 0.9935615658880297,\n",
       " '8767': 0.9935615658880297,\n",
       " '19542': 0.9935615658880297,\n",
       " '25639': 0.9935615658880297,\n",
       " '25701': 0.9935615658880297,\n",
       " '25937': 0.9935615658880297,\n",
       " '28727': 0.9935615658880297,\n",
       " '29402': 0.9935615658880297,\n",
       " '10138': 0.993575002930716,\n",
       " '18417': 0.9935909775250668,\n",
       " '22320': 0.99388406389276,\n",
       " '6541': 0.9940604611564406,\n",
       " '29742': 0.994389640584789,\n",
       " '18079': 0.9945731073923488,\n",
       " '19017': 0.9945949031680975,\n",
       " '22381': 0.994883201058777,\n",
       " '6812': 0.9949543351057142,\n",
       " '10870': 0.995090388318806,\n",
       " '20489': 0.9952022826137705,\n",
       " '25466': 0.9952022826137705,\n",
       " '8854': 0.9952039004151458,\n",
       " '27596': 0.9952039004151458,\n",
       " '23604': 0.9954478145147507,\n",
       " '25947': 0.9954728717687904,\n",
       " '27625': 0.9955453552225186,\n",
       " '2952': 0.9955792132222506,\n",
       " '22825': 0.9956101136470187,\n",
       " '2659': 0.9956315653538568,\n",
       " '19079': 0.9958199406838519,\n",
       " '11809': 0.9958199406838537,\n",
       " '20474': 0.9960345329053406,\n",
       " '19524': 0.9960714020541168,\n",
       " '29769': 0.9962915681332694,\n",
       " '10029': 0.9963799539340923,\n",
       " '29535': 0.9964213145858583,\n",
       " '21077': 0.9965605655836869,\n",
       " '10157': 0.9968096931986458,\n",
       " '11564': 0.9970835243876149,\n",
       " '25708': 0.9971161669716876,\n",
       " '4839': 0.9971395229494215,\n",
       " '5979': 0.9971395229494215,\n",
       " '6037': 0.9972316218254721,\n",
       " '25046': 0.9972316218254721,\n",
       " '12357': 0.9972725170797696,\n",
       " '25640': 0.9972840910681916,\n",
       " '17134': 0.9975737048492112,\n",
       " '1930': 0.9977082763506375,\n",
       " '11696': 0.9977864922673895,\n",
       " '1126': 0.9980579057369438,\n",
       " '25513': 0.998266205768678,\n",
       " '24370': 0.9983040931316178,\n",
       " '26158': 0.9984549614252004,\n",
       " '23202': 0.998644353775149,\n",
       " '29377': 0.9987069358558355,\n",
       " '29043': 0.9987339124195287,\n",
       " '25047': 0.9990034659263987,\n",
       " '29614': 0.9992941775293036,\n",
       " '4720': 0.9992949548155585,\n",
       " '1570': 0.9993644964826359,\n",
       " '1192': 0.9994224543990136,\n",
       " '13665': 0.9995099459810455,\n",
       " '18513': 0.9995340461233388,\n",
       " '28326': 0.9995355446359414,\n",
       " '24812': 0.9996137667068845,\n",
       " '26458': 0.9996699200592433,\n",
       " '14055': 0.9997125415148815,\n",
       " '2599': 0.9998002065682066,\n",
       " '4763': 0.9998002065682066,\n",
       " '23739': 0.9998879581965346,\n",
       " '3483': 0.9999175326196464,\n",
       " '16401': 0.9999352564681009,\n",
       " '23983': 0.9999352564681009,\n",
       " '2340': 0.9999382090774509,\n",
       " '2544': 0.9999447787051767,\n",
       " '15627': 0.9999447787051767,\n",
       " '26604': 0.9999447787051767,\n",
       " '5878': 0.9999537506704917,\n",
       " '13329': 0.9999584172118166,\n",
       " '20487': 0.9999610493326864,\n",
       " '21707': 0.9999685390606223,\n",
       " '28079': 0.9999701604183542,\n",
       " '16329': 0.9999729588444507,\n",
       " '21492': 0.9999903642419398,\n",
       " '28076': 0.9999903642419398,\n",
       " '6806': 0.9999968340349842,\n",
       " '12193': 0.9999968340349864,\n",
       " '14529': 0.9999968340349864,\n",
       " '28665': 1.0000009614335823,\n",
       " '27107': 1.0000010348963724,\n",
       " '1601': 1.0000010983231074,\n",
       " '3330': 1.0000010983231074,\n",
       " '13059': 1.0000011242126383,\n",
       " '29405': 1.0000012915908714,\n",
       " '8051': 1.0000015030093223,\n",
       " '4646': 1.0000015030093226,\n",
       " '24082': 1.0000017063878694,\n",
       " '29744': 1.0000017063878694,\n",
       " '20936': 1.0000017502473686,\n",
       " '10605': 1.000002083369732,\n",
       " '3946': 1.000002083369741,\n",
       " '2102': 1.000002313190112,\n",
       " '2919': 1.000002313190112,\n",
       " '10030': 1.000002313190112,\n",
       " '884': 1.0000023169671746,\n",
       " '13643': 1.0000023169671746,\n",
       " '18397': 1.0000023169671746,\n",
       " '27364': 1.0000023339706603,\n",
       " '20511': 1.0000028117753559,\n",
       " '4182': 1.0000033955033825,\n",
       " '23121': 1.0000038765710069,\n",
       " '29649': 1.0000039385131971,\n",
       " '11851': 1.0000039385131987,\n",
       " '25122': 1.0000039385131987,\n",
       " '26885': 1.0000039385131987,\n",
       " '20428': 1.0000048230679925,\n",
       " '23009': 1.0000048230679925,\n",
       " '15194': 1.0000048403476134,\n",
       " '18651': 1.0000048637154093,\n",
       " '21302': 1.0000048637154093,\n",
       " '25855': 1.0000048637154093,\n",
       " '13297': 1.000005557044673,\n",
       " '8480': 1.0000064096688224,\n",
       " '23741': 1.0000064096688224,\n",
       " '11185': 1.0000070300740926,\n",
       " '14931': 1.0000070300740926,\n",
       " '21600': 1.0000070300740926,\n",
       " '5128': 1.000007030074094,\n",
       " '28980': 1.0000100565878918,\n",
       " '24621': 1.0000107973298904,\n",
       " '12525': 1.0000114706345735,\n",
       " '18501': 1.0000114706345735,\n",
       " '21848': 1.0000114706345735,\n",
       " '28021': 1.0000114706345735,\n",
       " '16376': 1.0000130876333697,\n",
       " '17561': 1.0000130876333697,\n",
       " '21641': 1.0000130876333697,\n",
       " '4288': 1.0000152372145013,\n",
       " '13410': 1.0000152372145013,\n",
       " '19567': 1.0000152372145013,\n",
       " '1077': 1.0000152898228534,\n",
       " '17676': 1.0000152898228534,\n",
       " '28877': 1.0000152898228534,\n",
       " '28878': 1.0000152898228534,\n",
       " '22264': 1.0000159340499006,\n",
       " '1347': 1.0000161551623459,\n",
       " '11704': 1.0000161551623459,\n",
       " '25135': 1.0000161551623459,\n",
       " '25437': 1.0000161551623459,\n",
       " '6063': 1.000016155162346,\n",
       " '21549': 1.0000170314377936,\n",
       " '24844': 1.0000183946162284,\n",
       " '15360': 1.0000296062121725,\n",
       " '23114': 1.0000296062121725,\n",
       " '29422': 1.0000296062121725,\n",
       " '29645': 1.0000296062121725,\n",
       " '78': 1.000032460136334,\n",
       " '1174': 1.000032460136334,\n",
       " '17010': 1.000032460136334,\n",
       " '21336': 1.0000324601363342,\n",
       " '2091': 1.0000328808244083,\n",
       " '832': 1.0000360250759714,\n",
       " '2862': 1.0000360250759714,\n",
       " '7936': 1.0000390688659293,\n",
       " '22450': 1.000039068865939,\n",
       " '10376': 1.0000395276425884,\n",
       " '22016': 1.0000431206755702,\n",
       " '28279': 1.0000691252211915,\n",
       " '29781': 1.0000691252211915,\n",
       " '27630': 1.0001319875328116,\n",
       " '9430': 1.0001794669890007,\n",
       " '14757': 1.0001794669890007,\n",
       " '29627': 1.0001794669890007,\n",
       " '27765': 1.0001816573641096,\n",
       " '24028': 1.0001924902223294,\n",
       " '1288': 1.0001933527654583,\n",
       " '27707': 1.0002042695364879,\n",
       " '19854': 1.0002433615658426,\n",
       " '29465': 1.0002643555641841,\n",
       " '21646': 1.0005902042290185,\n",
       " '26801': 1.0006718220728947,\n",
       " '15240': 1.0010946720843559,\n",
       " '2304': 1.001197825900556,\n",
       " '23683': 1.0012409723694278,\n",
       " '17331': 1.0017830380669872,\n",
       " '28253': 1.0019570635989605,\n",
       " '21': 1.0019835009933076,\n",
       " '5310': 1.0022851534766837,\n",
       " '20475': 1.0023754945613288,\n",
       " '20178': 1.0028976193404446,\n",
       " '26645': 1.00303266440947,\n",
       " '12970': 1.0036737359775878,\n",
       " '3913': 1.0039683946410818,\n",
       " '11083': 1.0039811469840558,\n",
       " '10519': 1.0042632817658306,\n",
       " '28416': 1.0042632817658306,\n",
       " '5077': 1.004422177524139,\n",
       " '21736': 1.0045465467210763,\n",
       " '3253': 1.0054615955340278,\n",
       " '11455': 1.0072114178050011,\n",
       " '24014': 1.0072428029828555,\n",
       " '6968': 1.0073441816417998,\n",
       " '8155': 1.0073441816417998,\n",
       " '21586': 1.0073441816417998,\n",
       " '23176': 1.0073441816417998,\n",
       " '84': 1.007416127039606,\n",
       " '17221': 1.008463634432655,\n",
       " '23625': 1.0086029447697447,\n",
       " '12854': 1.0093037950825174,\n",
       " '10904': 1.0101484227241875,\n",
       " '12747': 1.0101552999205285,\n",
       " '1392': 1.0103225086407222,\n",
       " '18996': 1.010666396933145,\n",
       " '106': 1.0107749058498068,\n",
       " '1627': 1.0120801874652638,\n",
       " '14268': 1.0120801874652638,\n",
       " '17850': 1.0120801874652638,\n",
       " '5830': 1.0123635286670496,\n",
       " '29167': 1.01237341584293,\n",
       " '25720': 1.012720443718084,\n",
       " '22747': 1.0133524051461713,\n",
       " '13045': 1.013769943639721,\n",
       " '18798': 1.0142556485258707,\n",
       " '26463': 1.0155803299465627,\n",
       " '25521': 1.016590854320367,\n",
       " '11243': 1.0166129790377434,\n",
       " '29269': 1.0170513139021484,\n",
       " '27005': 1.0173898935036736,\n",
       " '2167': 1.0174595027983282,\n",
       " '22985': 1.0174595027983282,\n",
       " '1684': 1.0178911671595352,\n",
       " '2110': 1.0188118178275076,\n",
       " '14120': 1.0188124067198296,\n",
       " '3122': 1.0195168672696087,\n",
       " '8139': 1.0195168672696087,\n",
       " '16101': 1.0195168672696087,\n",
       " '25831': 1.0195264520006764,\n",
       " '14022': 1.0195627304486126,\n",
       " '4752': 1.0195682315982044,\n",
       " '27659': 1.0198987093246543,\n",
       " '15543': 1.019929787575263,\n",
       " '12114': 1.0210601351147441,\n",
       " '21614': 1.0220424942450923,\n",
       " '11782': 1.022809173559556,\n",
       " '5549': 1.02336752067404,\n",
       " '19955': 1.024397892064219,\n",
       " '4136': 1.0257705582495211,\n",
       " '2453': 1.0283193623094413,\n",
       " '24914': 1.0305566051237791,\n",
       " '29149': 1.0315347332808666,\n",
       " '10323': 1.0315794963915015,\n",
       " '18756': 1.0316438274181225,\n",
       " '16293': 1.0317483181219662,\n",
       " '21194': 1.0332305730939264,\n",
       " '4957': 1.0395484064404854,\n",
       " '29081': 1.0407558914226807,\n",
       " '6594': 1.0432717234568365,\n",
       " '21305': 1.0432770589766713,\n",
       " '21304': 1.0432786822925335,\n",
       " '12085': 1.0452081575933385,\n",
       " '8031': 1.0493828221993662,\n",
       " '2508': 1.0493828221993684,\n",
       " '29766': 1.0502164642610883,\n",
       " '5301': 1.0545590811195864,\n",
       " '20102': 1.056910337005056,\n",
       " '27390': 1.0601469003736925,\n",
       " '3990': 1.0601536821871844,\n",
       " '15096': 1.0843362110570949,\n",
       " '28880': 1.0855960948848533,\n",
       " '19482': 1.085758423411304,\n",
       " '25026': 1.0907509357924252,\n",
       " '23419': 1.091067497429503,\n",
       " '27220': 1.0912380094946348,\n",
       " '23287': 1.0983031689874274,\n",
       " '28881': 1.1019762894585399,\n",
       " '28883': 1.102547688926427,\n",
       " '28882': 1.1025481871606104,\n",
       " '5944': 1.1036472023206405,\n",
       " '3933': 1.1060051959687314,\n",
       " '11750': 1.1062050024999344,\n",
       " '23709': 1.1174623230607488,\n",
       " '28209': 1.1191568808091235,\n",
       " '140': 1.1191632497318078,\n",
       " '28271': 1.1191632497509985,\n",
       " '18568': 1.1192632839754384,\n",
       " '25844': 1.119433128288336,\n",
       " '27972': 1.1199782712961162,\n",
       " '28048': 1.1200037772800508,\n",
       " '21990': 1.1241949341774986,\n",
       " '28095': 1.1281362643162343,\n",
       " '28111': 1.1369256352152508,\n",
       " '23063': 1.1375161763798913,\n",
       " '23403': 1.142127060505556,\n",
       " '9891': 1.1517082770308427,\n",
       " '29540': 1.152989581979497,\n",
       " '5388': 1.182049096061439,\n",
       " '3037': 1.1866251868563222,\n",
       " '11287': 1.1937321296191654,\n",
       " '241': 1.2262194164688631,\n",
       " '5142': 1.2559095195002927,\n",
       " '16176': 1.2872718854563303,\n",
       " '23271': 1.3003293492296086,\n",
       " '21764': 1.3018242284927886,\n",
       " '5986': 1.32036157064047,\n",
       " '28977': 1.3698880228936599,\n",
       " '1441': 1.3751100284387168,\n",
       " '11522': 1.4482854647206393,\n",
       " '28270': 1.4823554891620103,\n",
       " '28281': 1.4823710556229006,\n",
       " '28280': 1.4824151546391418,\n",
       " '28282': 1.4824221922891243,\n",
       " '682': 1.4825148496135347,\n",
       " '3267': 1.5463422103152824,\n",
       " '24506': 1.5674778753205687,\n",
       " '14676': 1.5750171862125002,\n",
       " '15279': 1.586083491721227,\n",
       " '6954': 1.6016215815473351,\n",
       " '913': 1.7528433795967149,\n",
       " '17142': 66.55109535607615}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls =LaplacianScore(np.array(B117_test.iloc[:,:]))\n",
    "B117_SEL = np.array(B117_test.iloc[:,:])[:,list(np.where( ls < 0.001)[0])]\n",
    "B117_score = {}\n",
    "for i in range(len(B117_test.columns)):\n",
    "    \n",
    "    if str(list(ls)[i]) != 'nan':\n",
    "        B117_score[list(B117_test.columns)[i]] = list(ls)[i]\n",
    "res = sorted(B117_score.items(),key = lambda item:item[1],reverse=False)\n",
    "sor_res = {str(k):v for k,v in res}\n",
    "sor_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[109,\n",
       " 251,\n",
       " 495,\n",
       " 720,\n",
       " 752,\n",
       " 758,\n",
       " 759,\n",
       " 762,\n",
       " 763,\n",
       " 767,\n",
       " 773,\n",
       " 776,\n",
       " 781,\n",
       " 784,\n",
       " 785,\n",
       " 788]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_mutations = [3267,5388,6954,11288,11289,11290,11291,11292,11293,11294,11295,11296,\n",
    "                21765,21766,21767,21768,21769,21770,21991,21992,21993,23063,23271,23604\n",
    "                ,23709,24506,24914,27972,28048,28111,28280,28977]\n",
    "\n",
    "rank_def = []\n",
    "sel_def = []\n",
    "for i in range(len(list(sor_res.keys()))):\n",
    "    if int(list(sor_res.keys())[i]) in def_mutations:\n",
    "        rank_def.append(i)\n",
    "        sel_def.append(list(sor_res.keys())[i])\n",
    "rank_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['21765',\n",
       " '21769',\n",
       " '23604',\n",
       " '24914',\n",
       " '23709',\n",
       " '27972',\n",
       " '28048',\n",
       " '28111',\n",
       " '23063',\n",
       " '5388',\n",
       " '23271',\n",
       " '28977',\n",
       " '28280',\n",
       " '3267',\n",
       " '24506',\n",
       " '6954']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_def"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B.1.617.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/Aral/Desktop/毕业论文/数据/SARS-CoV-2 lineage meta data.csv')\n",
    "df = df.dropna()\n",
    "\n",
    "file_dir = 'C:/Users/Aral/Desktop/毕业论文/数据/clinical_variant_files'\n",
    "def getFlist(path):\n",
    "    f = []\n",
    "    for root, dirs, files in os.walk(file_dir):\n",
    "        f.append(files)\n",
    "    return f\n",
    "file_name = getFlist(file_dir)[0]\n",
    "\n",
    "pos_record = {}\n",
    "target2 = list(df[df['lineage']=='B.1.617.2']['INAB sample ID'])\n",
    "for i in range(len(file_name)):\n",
    "    if i != 306:\n",
    "        t = re.findall(r'V[0-9]*',file_name[i])\n",
    "        if t[0] in target2:\n",
    "            test = vcf.Reader(filename = 'C:/Users/Aral/Desktop/毕业论文/数据/clinical_variant_files/'+file_name[i])\n",
    "            for record in test:\n",
    "                if record.POS not in pos_record:\n",
    "                    pos_record[record.POS] = 1\n",
    "                else:\n",
    "                    pos_record[record.POS] += 1\n",
    "\n",
    "res = sorted(pos_record.items(),key = lambda item:item[1],reverse=True)\n",
    "sor_res = {str(k):v for k,v in res}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3037</th>\n",
       "      <th>14408</th>\n",
       "      <th>23403</th>\n",
       "      <th>28270</th>\n",
       "      <th>28881</th>\n",
       "      <th>16466</th>\n",
       "      <th>26767</th>\n",
       "      <th>15451</th>\n",
       "      <th>27638</th>\n",
       "      <th>27752</th>\n",
       "      <th>...</th>\n",
       "      <th>26985</th>\n",
       "      <th>29119</th>\n",
       "      <th>6310</th>\n",
       "      <th>12400</th>\n",
       "      <th>28156</th>\n",
       "      <th>29072</th>\n",
       "      <th>12890</th>\n",
       "      <th>15251</th>\n",
       "      <th>18568</th>\n",
       "      <th>20761</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>968 rows × 435 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     3037  14408  23403  28270  28881  16466  26767  15451  27638  27752  ...  \\\n",
       "0       4      4      3      4      4      4      2      1      2      4  ...   \n",
       "1       4      4      3      4      4      4      2      1      2      4  ...   \n",
       "2       4      4      3      4      4      4      2      1      2      4  ...   \n",
       "3       4      4      3      4      4      4      2      0      2      4  ...   \n",
       "4       4      4      3      4      4      4      2      1      2      4  ...   \n",
       "..    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  ...   \n",
       "963     4      4      3      4      4      4      2      1      2      4  ...   \n",
       "964     4      4      3      4      4      4      2      1      2      4  ...   \n",
       "965     4      4      3      4      4      4      2      1      2      4  ...   \n",
       "966     4      4      3      0      0      4      2      0      0      0  ...   \n",
       "967     4      4      3      4      4      4      2      1      2      4  ...   \n",
       "\n",
       "     26985  29119  6310  12400  28156  29072  12890  15251  18568  20761  \n",
       "0        0      0     0      0      0      0      0      0      0      0  \n",
       "1        0      0     0      0      0      0      0      0      0      0  \n",
       "2        0      0     0      0      0      0      0      0      0      0  \n",
       "3        0      0     0      0      0      0      0      0      0      0  \n",
       "4        0      0     0      0      0      0      0      0      0      0  \n",
       "..     ...    ...   ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "963      0      0     0      0      0      0      0      0      0      0  \n",
       "964      0      0     0      0      0      0      0      0      0      0  \n",
       "965      0      0     0      0      0      0      0      0      0      0  \n",
       "966      0      0     0      0      0      0      0      0      0      0  \n",
       "967      0      0     0      0      0      0      0      0      0      3  \n",
       "\n",
       "[968 rows x 435 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sor_res_filter = dict(filter(lambda x: x[1] >= 2,sor_res.items()))\n",
    "pos3 = list(sor_res_filter.keys())\n",
    "df2 = pd.read_csv('C:/Users/Aral/Desktop/毕业论文/数据/SARS-CoV-2 lineage meta data.csv')\n",
    "df2 = df2.dropna()\n",
    "\n",
    "x2 = []\n",
    "for i in range(len(file_name)):\n",
    "    tar = [0]*len(pos3)\n",
    "    if i != 306:\n",
    "        t = re.findall(r'V[0-9]*',file_name[i])\n",
    "        if t[0] in target2:\n",
    "            test = vcf.Reader(filename = 'C:/Users/Aral/Desktop/毕业论文/数据/clinical_variant_files/'+file_name[i])\n",
    "            for p in test:\n",
    "                if str(p.POS) in pos3:\n",
    "                    if p.ALT[0] == 'A':\n",
    "                        tar[pos3.index(str(p.POS))] = 1\n",
    "                    if p.ALT[0] == 'C':\n",
    "                        tar[pos3.index(str(p.POS))] = 2\n",
    "                    if p.ALT[0] == 'G':\n",
    "                        tar[pos3.index(str(p.POS))] = 3\n",
    "                    if p.ALT[0] == 'T':\n",
    "                        tar[pos3.index(str(p.POS))] = 4\n",
    "            x2.append(tar)\n",
    "\n",
    "B16172_test = pd.DataFrame(x2)\n",
    "B16172_test.columns = pos3\n",
    "B16172_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.295e+05, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.866e+05, with an active set of 3 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.866e+05, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.108e+05, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.043e+05, with an active set of 11 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.023e+05, with an active set of 11 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=5.095e+04, with an active set of 21 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=4.927e+04, with an active set of 21 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=4.411e+04, with an active set of 24 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=3.887e+04, with an active set of 28 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=2.812e+04, with an active set of 39 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=2.368e+04, with an active set of 45 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=2.368e+04, with an active set of 45 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=2.282e+04, with an active set of 48 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=2.183e+04, with an active set of 51 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=2.047e+04, with an active set of 57 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=1.772e+04, with an active set of 68 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=1.772e+04, with an active set of 68 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 91 iterations, i.e. alpha=1.298e+04, with an active set of 89 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 92 iterations, i.e. alpha=1.256e+04, with an active set of 90 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=1.246e+04, with an active set of 93 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 97 iterations, i.e. alpha=1.228e+04, with an active set of 94 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 99 iterations, i.e. alpha=1.202e+04, with an active set of 96 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=1.156e+04, with an active set of 99 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=1.156e+04, with an active set of 99 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=1.155e+04, with an active set of 99 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=1.034e+04, with an active set of 107 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=9.828e+03, with an active set of 114 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=9.828e+03, with an active set of 114 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=9.716e+03, with an active set of 116 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=9.133e+03, with an active set of 121 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 127 iterations, i.e. alpha=8.938e+03, with an active set of 123 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 131 iterations, i.e. alpha=8.741e+03, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 136 iterations, i.e. alpha=8.609e+03, with an active set of 131 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 136 iterations, i.e. alpha=8.609e+03, with an active set of 131 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=8.074e+03, with an active set of 137 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=8.074e+03, with an active set of 137 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=7.552e+03, with an active set of 145 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 152 iterations, i.e. alpha=7.550e+03, with an active set of 146 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 152 iterations, i.e. alpha=7.480e+03, with an active set of 146 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=6.987e+03, with an active set of 154 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=6.981e+03, with an active set of 154 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=6.887e+03, with an active set of 154 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=6.829e+03, with an active set of 154 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.396e+03, with an active set of 163 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 172 iterations, i.e. alpha=6.377e+03, with an active set of 164 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 172 iterations, i.e. alpha=6.349e+03, with an active set of 164 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 185 iterations, i.e. alpha=5.656e+03, with an active set of 177 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 185 iterations, i.e. alpha=5.656e+03, with an active set of 177 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 186 iterations, i.e. alpha=5.514e+03, with an active set of 178 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 189 iterations, i.e. alpha=5.426e+03, with an active set of 181 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 189 iterations, i.e. alpha=5.426e+03, with an active set of 181 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 193 iterations, i.e. alpha=5.209e+03, with an active set of 185 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 193 iterations, i.e. alpha=5.209e+03, with an active set of 185 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 193 iterations, i.e. alpha=5.209e+03, with an active set of 185 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 193 iterations, i.e. alpha=5.172e+03, with an active set of 185 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 204 iterations, i.e. alpha=4.883e+03, with an active set of 195 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 204 iterations, i.e. alpha=4.883e+03, with an active set of 195 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 206 iterations, i.e. alpha=4.761e+03, with an active set of 197 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 206 iterations, i.e. alpha=4.759e+03, with an active set of 197 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 207 iterations, i.e. alpha=4.695e+03, with an active set of 198 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 207 iterations, i.e. alpha=4.695e+03, with an active set of 198 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 207 iterations, i.e. alpha=4.667e+03, with an active set of 198 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 209 iterations, i.e. alpha=4.616e+03, with an active set of 199 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 210 iterations, i.e. alpha=4.578e+03, with an active set of 200 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 210 iterations, i.e. alpha=4.578e+03, with an active set of 200 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 215 iterations, i.e. alpha=4.472e+03, with an active set of 205 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 215 iterations, i.e. alpha=4.472e+03, with an active set of 205 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 215 iterations, i.e. alpha=4.472e+03, with an active set of 205 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 218 iterations, i.e. alpha=4.423e+03, with an active set of 208 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 221 iterations, i.e. alpha=4.396e+03, with an active set of 211 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 221 iterations, i.e. alpha=4.396e+03, with an active set of 211 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 223 iterations, i.e. alpha=4.356e+03, with an active set of 213 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 223 iterations, i.e. alpha=4.333e+03, with an active set of 213 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 230 iterations, i.e. alpha=4.146e+03, with an active set of 220 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 234 iterations, i.e. alpha=3.974e+03, with an active set of 223 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 234 iterations, i.e. alpha=3.969e+03, with an active set of 223 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 234 iterations, i.e. alpha=3.946e+03, with an active set of 223 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 239 iterations, i.e. alpha=3.868e+03, with an active set of 228 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 239 iterations, i.e. alpha=3.868e+03, with an active set of 228 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 242 iterations, i.e. alpha=3.742e+03, with an active set of 230 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 242 iterations, i.e. alpha=3.741e+03, with an active set of 230 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 243 iterations, i.e. alpha=3.726e+03, with an active set of 231 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 245 iterations, i.e. alpha=3.670e+03, with an active set of 233 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 250 iterations, i.e. alpha=3.518e+03, with an active set of 237 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 253 iterations, i.e. alpha=3.417e+03, with an active set of 240 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 253 iterations, i.e. alpha=3.416e+03, with an active set of 240 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 255 iterations, i.e. alpha=3.364e+03, with an active set of 242 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 260 iterations, i.e. alpha=3.161e+03, with an active set of 246 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 260 iterations, i.e. alpha=3.160e+03, with an active set of 246 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 260 iterations, i.e. alpha=3.139e+03, with an active set of 246 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 260 iterations, i.e. alpha=3.094e+03, with an active set of 246 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 268 iterations, i.e. alpha=3.015e+03, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=2.986e+03, with an active set of 250 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 285 iterations, i.e. alpha=3.696e+03, with an active set of 261 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 285 iterations, i.e. alpha=3.489e+03, with an active set of 261 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 285 iterations, i.e. alpha=3.488e+03, with an active set of 261 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 285 iterations, i.e. alpha=3.487e+03, with an active set of 261 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 285 iterations, i.e. alpha=3.475e+03, with an active set of 261 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 285 iterations, i.e. alpha=3.377e+03, with an active set of 261 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 285 iterations, i.e. alpha=3.345e+03, with an active set of 261 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 285 iterations, i.e. alpha=3.345e+03, with an active set of 261 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=3.312e+03, with an active set of 263 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=3.233e+03, with an active set of 266 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=3.232e+03, with an active set of 266 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=3.230e+03, with an active set of 266 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=3.229e+03, with an active set of 266 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=3.228e+03, with an active set of 266 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 291 iterations, i.e. alpha=3.008e+03, with an active set of 267 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 291 iterations, i.e. alpha=2.729e+03, with an active set of 267 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 291 iterations, i.e. alpha=2.698e+03, with an active set of 267 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 291 iterations, i.e. alpha=2.679e+03, with an active set of 267 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 291 iterations, i.e. alpha=2.679e+03, with an active set of 267 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 291 iterations, i.e. alpha=2.606e+03, with an active set of 267 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 291 iterations, i.e. alpha=2.588e+03, with an active set of 267 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 291 iterations, i.e. alpha=2.586e+03, with an active set of 267 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 294 iterations, i.e. alpha=2.560e+03, with an active set of 270 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 294 iterations, i.e. alpha=2.525e+03, with an active set of 270 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 294 iterations, i.e. alpha=2.514e+03, with an active set of 270 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 294 iterations, i.e. alpha=2.512e+03, with an active set of 270 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 294 iterations, i.e. alpha=2.484e+03, with an active set of 270 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 294 iterations, i.e. alpha=2.484e+03, with an active set of 270 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 295 iterations, i.e. alpha=2.482e+03, with an active set of 271 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 300 iterations, i.e. alpha=2.436e+03, with an active set of 276 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 302 iterations, i.e. alpha=2.406e+03, with an active set of 278 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 302 iterations, i.e. alpha=2.395e+03, with an active set of 278 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 302 iterations, i.e. alpha=2.394e+03, with an active set of 278 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 302 iterations, i.e. alpha=2.373e+03, with an active set of 278 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 302 iterations, i.e. alpha=2.366e+03, with an active set of 278 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 302 iterations, i.e. alpha=2.201e+03, with an active set of 278 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 302 iterations, i.e. alpha=2.200e+03, with an active set of 278 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 302 iterations, i.e. alpha=2.198e+03, with an active set of 278 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 302 iterations, i.e. alpha=2.141e+03, with an active set of 278 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 302 iterations, i.e. alpha=2.134e+03, with an active set of 278 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 302 iterations, i.e. alpha=2.133e+03, with an active set of 278 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 302 iterations, i.e. alpha=2.132e+03, with an active set of 278 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 302 iterations, i.e. alpha=2.014e+03, with an active set of 278 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 302 iterations, i.e. alpha=2.001e+03, with an active set of 278 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 306 iterations, i.e. alpha=1.883e+03, with an active set of 281 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 306 iterations, i.e. alpha=1.858e+03, with an active set of 281 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 306 iterations, i.e. alpha=1.857e+03, with an active set of 281 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 307 iterations, i.e. alpha=1.818e+03, with an active set of 282 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=1.774e+03, with an active set of 283 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 309 iterations, i.e. alpha=1.722e+03, with an active set of 284 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 309 iterations, i.e. alpha=1.721e+03, with an active set of 284 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 309 iterations, i.e. alpha=1.720e+03, with an active set of 284 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 309 iterations, i.e. alpha=1.653e+03, with an active set of 284 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 309 iterations, i.e. alpha=1.653e+03, with an active set of 284 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 309 iterations, i.e. alpha=1.642e+03, with an active set of 284 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 311 iterations, i.e. alpha=1.537e+03, with an active set of 285 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 311 iterations, i.e. alpha=1.528e+03, with an active set of 285 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 315 iterations, i.e. alpha=1.454e+03, with an active set of 288 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 318 iterations, i.e. alpha=1.452e+03, with an active set of 289 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 318 iterations, i.e. alpha=1.421e+03, with an active set of 289 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 320 iterations, i.e. alpha=1.366e+03, with an active set of 290 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 321 iterations, i.e. alpha=1.302e+03, with an active set of 291 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 325 iterations, i.e. alpha=1.357e+03, with an active set of 293 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 326 iterations, i.e. alpha=1.274e+03, with an active set of 294 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 326 iterations, i.e. alpha=1.204e+03, with an active set of 294 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 326 iterations, i.e. alpha=1.199e+03, with an active set of 294 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 327 iterations, i.e. alpha=1.123e+03, with an active set of 295 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 328 iterations, i.e. alpha=1.104e+03, with an active set of 296 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 328 iterations, i.e. alpha=1.097e+03, with an active set of 296 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 328 iterations, i.e. alpha=1.058e+03, with an active set of 296 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 328 iterations, i.e. alpha=1.048e+03, with an active set of 296 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 328 iterations, i.e. alpha=1.029e+03, with an active set of 296 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 330 iterations, i.e. alpha=9.830e+02, with an active set of 298 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 330 iterations, i.e. alpha=9.767e+02, with an active set of 298 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 332 iterations, i.e. alpha=9.474e+02, with an active set of 300 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 336 iterations, i.e. alpha=9.148e+02, with an active set of 303 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 338 iterations, i.e. alpha=8.878e+02, with an active set of 304 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 338 iterations, i.e. alpha=8.877e+02, with an active set of 304 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 338 iterations, i.e. alpha=8.873e+02, with an active set of 304 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 338 iterations, i.e. alpha=8.873e+02, with an active set of 304 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 338 iterations, i.e. alpha=8.872e+02, with an active set of 304 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 338 iterations, i.e. alpha=8.870e+02, with an active set of 304 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 338 iterations, i.e. alpha=8.813e+02, with an active set of 304 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 338 iterations, i.e. alpha=8.807e+02, with an active set of 304 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 338 iterations, i.e. alpha=8.734e+02, with an active set of 304 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 339 iterations, i.e. alpha=8.594e+02, with an active set of 305 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 339 iterations, i.e. alpha=8.368e+02, with an active set of 305 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 339 iterations, i.e. alpha=8.161e+02, with an active set of 305 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 339 iterations, i.e. alpha=8.155e+02, with an active set of 305 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 339 iterations, i.e. alpha=8.155e+02, with an active set of 305 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 339 iterations, i.e. alpha=8.151e+02, with an active set of 305 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 340 iterations, i.e. alpha=8.070e+02, with an active set of 306 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 340 iterations, i.e. alpha=8.068e+02, with an active set of 306 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 340 iterations, i.e. alpha=8.066e+02, with an active set of 306 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 340 iterations, i.e. alpha=8.066e+02, with an active set of 306 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 340 iterations, i.e. alpha=8.064e+02, with an active set of 306 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 340 iterations, i.e. alpha=8.063e+02, with an active set of 306 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 340 iterations, i.e. alpha=8.059e+02, with an active set of 306 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 340 iterations, i.e. alpha=8.058e+02, with an active set of 306 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 340 iterations, i.e. alpha=8.042e+02, with an active set of 306 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 340 iterations, i.e. alpha=7.854e+02, with an active set of 306 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 340 iterations, i.e. alpha=7.853e+02, with an active set of 306 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 340 iterations, i.e. alpha=7.852e+02, with an active set of 306 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 340 iterations, i.e. alpha=7.850e+02, with an active set of 306 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 340 iterations, i.e. alpha=7.849e+02, with an active set of 306 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 340 iterations, i.e. alpha=7.847e+02, with an active set of 306 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 340 iterations, i.e. alpha=7.844e+02, with an active set of 306 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=7.741e+02, with an active set of 307 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=7.664e+02, with an active set of 307 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 342 iterations, i.e. alpha=7.535e+02, with an active set of 308 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 342 iterations, i.e. alpha=7.447e+02, with an active set of 308 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 342 iterations, i.e. alpha=7.444e+02, with an active set of 308 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 342 iterations, i.e. alpha=7.443e+02, with an active set of 308 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 342 iterations, i.e. alpha=7.442e+02, with an active set of 308 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 342 iterations, i.e. alpha=7.441e+02, with an active set of 308 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 342 iterations, i.e. alpha=7.438e+02, with an active set of 308 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 342 iterations, i.e. alpha=7.437e+02, with an active set of 308 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 342 iterations, i.e. alpha=7.436e+02, with an active set of 308 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 342 iterations, i.e. alpha=7.348e+02, with an active set of 308 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 342 iterations, i.e. alpha=7.340e+02, with an active set of 308 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 342 iterations, i.e. alpha=6.983e+02, with an active set of 308 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 342 iterations, i.e. alpha=6.909e+02, with an active set of 308 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 342 iterations, i.e. alpha=6.907e+02, with an active set of 308 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 342 iterations, i.e. alpha=6.865e+02, with an active set of 308 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 344 iterations, i.e. alpha=6.657e+02, with an active set of 309 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 344 iterations, i.e. alpha=6.655e+02, with an active set of 309 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 345 iterations, i.e. alpha=6.090e+02, with an active set of 310 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 346 iterations, i.e. alpha=6.057e+02, with an active set of 311 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 346 iterations, i.e. alpha=6.054e+02, with an active set of 311 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 346 iterations, i.e. alpha=6.053e+02, with an active set of 311 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 346 iterations, i.e. alpha=6.047e+02, with an active set of 311 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 346 iterations, i.e. alpha=5.810e+02, with an active set of 311 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 346 iterations, i.e. alpha=5.639e+02, with an active set of 311 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=5.499e+02, with an active set of 313 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=5.497e+02, with an active set of 313 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=5.050e+02, with an active set of 313 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=5.012e+02, with an active set of 313 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=4.910e+02, with an active set of 313 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=4.718e+02, with an active set of 313 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=4.275e+02, with an active set of 313 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=4.217e+02, with an active set of 313 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 349 iterations, i.e. alpha=4.156e+02, with an active set of 314 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=3.624e+02, with an active set of 315 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=3.460e+02, with an active set of 315 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=3.108e+02, with an active set of 316 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=2.928e+02, with an active set of 316 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=2.747e+02, with an active set of 316 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=2.736e+02, with an active set of 316 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=2.519e+02, with an active set of 316 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=2.068e+02, with an active set of 318 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=2.061e+02, with an active set of 318 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=2.061e+02, with an active set of 318 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=2.059e+02, with an active set of 318 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=2.042e+02, with an active set of 318 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=2.042e+02, with an active set of 318 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=1.855e+02, with an active set of 319 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=1.854e+02, with an active set of 319 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=1.854e+02, with an active set of 319 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=1.606e+02, with an active set of 319 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=1.538e+02, with an active set of 319 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=1.422e+02, with an active set of 319 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=1.373e+02, with an active set of 319 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=1.345e+02, with an active set of 319 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=1.334e+02, with an active set of 319 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=1.319e+02, with an active set of 319 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=1.196e+02, with an active set of 319 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=1.046e+02, with an active set of 319 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=1.003e+02, with an active set of 319 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=1.003e+02, with an active set of 319 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=1.002e+02, with an active set of 319 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=1.002e+02, with an active set of 319 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=1.002e+02, with an active set of 319 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=9.429e+01, with an active set of 319 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=9.424e+01, with an active set of 319 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=9.417e+01, with an active set of 319 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=9.415e+01, with an active set of 319 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=9.413e+01, with an active set of 319 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=9.410e+01, with an active set of 319 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=9.136e+01, with an active set of 319 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.887e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.880e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.880e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.879e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.877e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.877e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.876e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.875e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.875e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.875e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.873e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.873e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.865e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.863e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.713e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.442e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.435e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.348e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.346e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.344e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.343e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.342e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.341e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.339e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.339e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.339e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.334e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.330e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.330e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=6.972e+01, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=6.967e+01, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=6.310e+01, with an active set of 321 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=6.157e+01, with an active set of 321 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=5.805e+01, with an active set of 321 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=5.563e+01, with an active set of 321 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=5.469e+01, with an active set of 321 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=5.452e+01, with an active set of 321 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=5.451e+01, with an active set of 321 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=5.450e+01, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=5.449e+01, with an active set of 321 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=5.448e+01, with an active set of 321 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=5.337e+01, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=5.088e+01, with an active set of 321 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=4.536e+01, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=4.534e+01, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=4.532e+01, with an active set of 321 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=4.531e+01, with an active set of 321 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=4.530e+01, with an active set of 321 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=4.414e+01, with an active set of 321 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=4.240e+01, with an active set of 321 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=4.080e+01, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=3.871e+01, with an active set of 321 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 358 iterations, i.e. alpha=3.639e+01, with an active set of 322 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 358 iterations, i.e. alpha=3.272e+01, with an active set of 322 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 358 iterations, i.e. alpha=3.084e+01, with an active set of 322 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 358 iterations, i.e. alpha=3.082e+01, with an active set of 322 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 358 iterations, i.e. alpha=3.081e+01, with an active set of 322 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 358 iterations, i.e. alpha=2.530e+01, with an active set of 322 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=1.851e+01, with an active set of 324 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=1.817e+01, with an active set of 324 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=1.793e+01, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=1.635e+01, with an active set of 324 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=1.199e+01, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=1.185e+01, with an active set of 324 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.791e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.775e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.769e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.764e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.764e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.761e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.725e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.601e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.600e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.594e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.593e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.589e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.589e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.588e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.588e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.588e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.587e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.587e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.586e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.585e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.585e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.584e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.581e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.580e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.579e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.579e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.576e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.543e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.468e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.375e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.373e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.366e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.366e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.365e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.365e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.364e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.364e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.363e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.362e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.362e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.362e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.361e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.360e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.359e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.359e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.359e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.358e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.358e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.357e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.357e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.357e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.356e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.355e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.351e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.347e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.315e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.269e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.106e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=7.817e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=5.941e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=4.708e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=4.636e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=4.602e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=4.599e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=4.598e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=4.596e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=4.595e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=4.595e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=4.594e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=4.594e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=4.593e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=4.590e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=4.584e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=4.582e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=4.122e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=4.083e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=4.073e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=3.753e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=3.524e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=3.517e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=3.351e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=1.515e+00, with an active set of 325 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=1.381e+00, with an active set of 325 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=1.123e+00, with an active set of 325 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=1.050e+00, with an active set of 325 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=1.022e+00, with an active set of 325 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=9.050e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=9.049e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=6.773e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.982e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.461e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.304e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.301e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.301e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.300e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.297e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.297e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.297e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.296e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.296e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.296e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.295e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.295e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.294e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.294e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.293e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.293e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.293e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.293e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.293e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.292e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.292e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.292e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.291e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.290e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.289e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.289e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.289e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.289e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.288e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.285e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.285e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.284e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.278e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=4.950e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=4.763e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=4.681e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=2.272e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=6.036e+06, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=6.036e+06, with an active set of 2 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=3.018e+06, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=3.018e+06, with an active set of 6 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.690e+06, with an active set of 9 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=2.545e+06, with an active set of 9 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.299e+06, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.127e+06, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=9.549e+05, with an active set of 22 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=8.360e+05, with an active set of 25 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=5.856e+05, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=4.754e+05, with an active set of 38 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=2.958e+05, with an active set of 69 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=2.958e+05, with an active set of 69 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=2.899e+05, with an active set of 71 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=2.842e+05, with an active set of 72 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=2.824e+05, with an active set of 74 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=2.824e+05, with an active set of 74 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=2.455e+05, with an active set of 84 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=2.450e+05, with an active set of 84 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 95 iterations, i.e. alpha=2.376e+05, with an active set of 91 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=2.243e+05, with an active set of 95 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=2.243e+05, with an active set of 95 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=2.151e+05, with an active set of 104 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=2.149e+05, with an active set of 105 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=2.058e+05, with an active set of 110 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 119 iterations, i.e. alpha=1.994e+05, with an active set of 113 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 119 iterations, i.e. alpha=1.994e+05, with an active set of 113 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=1.979e+05, with an active set of 115 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=1.979e+05, with an active set of 115 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=1.979e+05, with an active set of 115 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=1.892e+05, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 129 iterations, i.e. alpha=1.831e+05, with an active set of 123 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=1.748e+05, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=1.748e+05, with an active set of 129 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=1.748e+05, with an active set of 129 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 136 iterations, i.e. alpha=1.711e+05, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 136 iterations, i.e. alpha=1.679e+05, with an active set of 130 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 140 iterations, i.e. alpha=1.633e+05, with an active set of 133 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 149 iterations, i.e. alpha=1.572e+05, with an active set of 141 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 153 iterations, i.e. alpha=1.530e+05, with an active set of 144 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 160 iterations, i.e. alpha=1.487e+05, with an active set of 151 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 160 iterations, i.e. alpha=1.487e+05, with an active set of 151 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 160 iterations, i.e. alpha=1.476e+05, with an active set of 151 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 163 iterations, i.e. alpha=1.416e+05, with an active set of 153 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=1.401e+05, with an active set of 155 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 173 iterations, i.e. alpha=1.362e+05, with an active set of 161 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 181 iterations, i.e. alpha=1.318e+05, with an active set of 168 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 183 iterations, i.e. alpha=1.303e+05, with an active set of 170 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 183 iterations, i.e. alpha=1.303e+05, with an active set of 170 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 183 iterations, i.e. alpha=1.286e+05, with an active set of 170 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 185 iterations, i.e. alpha=1.250e+05, with an active set of 172 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 186 iterations, i.e. alpha=1.234e+05, with an active set of 173 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 187 iterations, i.e. alpha=1.224e+05, with an active set of 174 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 200 iterations, i.e. alpha=1.183e+05, with an active set of 183 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 200 iterations, i.e. alpha=1.183e+05, with an active set of 183 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 207 iterations, i.e. alpha=1.132e+05, with an active set of 189 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 214 iterations, i.e. alpha=1.158e+05, with an active set of 194 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 218 iterations, i.e. alpha=1.120e+05, with an active set of 198 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 220 iterations, i.e. alpha=1.093e+05, with an active set of 199 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 220 iterations, i.e. alpha=1.093e+05, with an active set of 199 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 228 iterations, i.e. alpha=1.007e+05, with an active set of 206 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 234 iterations, i.e. alpha=9.668e+04, with an active set of 212 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 234 iterations, i.e. alpha=9.667e+04, with an active set of 212 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 235 iterations, i.e. alpha=9.301e+04, with an active set of 213 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 235 iterations, i.e. alpha=9.301e+04, with an active set of 213 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 235 iterations, i.e. alpha=9.262e+04, with an active set of 213 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 235 iterations, i.e. alpha=9.262e+04, with an active set of 213 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 239 iterations, i.e. alpha=9.186e+04, with an active set of 217 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 243 iterations, i.e. alpha=9.097e+04, with an active set of 219 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 243 iterations, i.e. alpha=9.029e+04, with an active set of 219 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 247 iterations, i.e. alpha=9.020e+04, with an active set of 222 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 259 iterations, i.e. alpha=9.382e+04, with an active set of 228 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 259 iterations, i.e. alpha=9.331e+04, with an active set of 228 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 259 iterations, i.e. alpha=9.331e+04, with an active set of 228 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 261 iterations, i.e. alpha=9.083e+04, with an active set of 230 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 261 iterations, i.e. alpha=9.083e+04, with an active set of 230 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 262 iterations, i.e. alpha=8.986e+04, with an active set of 231 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 263 iterations, i.e. alpha=8.724e+04, with an active set of 232 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 264 iterations, i.e. alpha=8.572e+04, with an active set of 233 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 264 iterations, i.e. alpha=8.421e+04, with an active set of 233 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=8.101e+04, with an active set of 238 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=8.101e+04, with an active set of 238 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=8.101e+04, with an active set of 238 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 270 iterations, i.e. alpha=7.745e+04, with an active set of 239 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 270 iterations, i.e. alpha=7.712e+04, with an active set of 239 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 273 iterations, i.e. alpha=7.470e+04, with an active set of 242 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 273 iterations, i.e. alpha=7.470e+04, with an active set of 242 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 273 iterations, i.e. alpha=7.463e+04, with an active set of 242 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 273 iterations, i.e. alpha=7.463e+04, with an active set of 242 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 276 iterations, i.e. alpha=7.300e+04, with an active set of 245 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 276 iterations, i.e. alpha=7.296e+04, with an active set of 245 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 276 iterations, i.e. alpha=7.262e+04, with an active set of 245 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 305 iterations, i.e. alpha=5.894e+05, with an active set of 260 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 305 iterations, i.e. alpha=5.894e+05, with an active set of 260 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 305 iterations, i.e. alpha=5.760e+05, with an active set of 260 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 310 iterations, i.e. alpha=5.399e+05, with an active set of 263 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 319 iterations, i.e. alpha=9.596e+05, with an active set of 266 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 325 iterations, i.e. alpha=9.569e+05, with an active set of 269 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 329 iterations, i.e. alpha=9.152e+05, with an active set of 272 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=8.694e+05, with an active set of 282 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 346 iterations, i.e. alpha=8.131e+05, with an active set of 286 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 346 iterations, i.e. alpha=7.888e+05, with an active set of 286 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 346 iterations, i.e. alpha=7.697e+05, with an active set of 286 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=7.628e+05, with an active set of 288 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=7.563e+05, with an active set of 288 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 352 iterations, i.e. alpha=7.111e+05, with an active set of 290 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 352 iterations, i.e. alpha=7.110e+05, with an active set of 290 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 352 iterations, i.e. alpha=7.036e+05, with an active set of 290 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=7.005e+05, with an active set of 291 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=6.965e+05, with an active set of 292 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=6.965e+05, with an active set of 292 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=6.963e+05, with an active set of 292 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=6.962e+05, with an active set of 292 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=6.811e+05, with an active set of 292 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=6.804e+05, with an active set of 292 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=6.750e+05, with an active set of 292 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=6.732e+05, with an active set of 292 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=6.728e+05, with an active set of 292 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=6.727e+05, with an active set of 292 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=6.707e+05, with an active set of 292 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=6.662e+05, with an active set of 293 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=6.648e+05, with an active set of 293 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=6.643e+05, with an active set of 293 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=6.628e+05, with an active set of 293 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=6.591e+05, with an active set of 293 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=6.580e+05, with an active set of 293 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=6.566e+05, with an active set of 293 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=6.559e+05, with an active set of 293 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=6.558e+05, with an active set of 293 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=6.555e+05, with an active set of 293 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=6.545e+05, with an active set of 293 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=6.538e+05, with an active set of 293 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=6.536e+05, with an active set of 293 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=6.526e+05, with an active set of 293 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=6.518e+05, with an active set of 293 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=6.509e+05, with an active set of 293 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=6.467e+05, with an active set of 293 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=6.413e+05, with an active set of 293 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=6.413e+05, with an active set of 293 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=6.410e+05, with an active set of 293 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=6.408e+05, with an active set of 293 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=6.407e+05, with an active set of 293 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=6.400e+05, with an active set of 293 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=6.381e+05, with an active set of 293 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=6.380e+05, with an active set of 293 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=6.375e+05, with an active set of 293 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=6.368e+05, with an active set of 293 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=6.365e+05, with an active set of 293 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=6.362e+05, with an active set of 293 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=6.355e+05, with an active set of 293 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=6.304e+05, with an active set of 293 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=6.244e+05, with an active set of 293 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=6.228e+05, with an active set of 293 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=6.221e+05, with an active set of 293 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=6.214e+05, with an active set of 293 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=6.168e+05, with an active set of 293 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=6.124e+05, with an active set of 293 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=6.109e+05, with an active set of 295 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=6.039e+05, with an active set of 295 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 358 iterations, i.e. alpha=6.014e+05, with an active set of 296 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 358 iterations, i.e. alpha=5.999e+05, with an active set of 296 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=5.999e+05, with an active set of 297 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=5.999e+05, with an active set of 297 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=5.998e+05, with an active set of 297 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=5.929e+05, with an active set of 297 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=5.913e+05, with an active set of 297 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=5.866e+05, with an active set of 297 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=5.824e+05, with an active set of 297 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=5.784e+05, with an active set of 297 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=5.747e+05, with an active set of 297 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=5.649e+05, with an active set of 297 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=5.640e+05, with an active set of 297 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=5.618e+05, with an active set of 297 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=5.565e+05, with an active set of 297 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=5.234e+05, with an active set of 297 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=4.937e+05, with an active set of 298 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=4.936e+05, with an active set of 298 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 370 iterations, i.e. alpha=4.483e+05, with an active set of 304 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 370 iterations, i.e. alpha=4.313e+05, with an active set of 304 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 370 iterations, i.e. alpha=4.180e+05, with an active set of 304 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 370 iterations, i.e. alpha=4.142e+05, with an active set of 304 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 373 iterations, i.e. alpha=3.621e+05, with an active set of 307 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 376 iterations, i.e. alpha=3.254e+05, with an active set of 309 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 376 iterations, i.e. alpha=3.126e+05, with an active set of 309 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 376 iterations, i.e. alpha=3.027e+05, with an active set of 309 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 376 iterations, i.e. alpha=3.021e+05, with an active set of 309 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 376 iterations, i.e. alpha=3.016e+05, with an active set of 309 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 376 iterations, i.e. alpha=2.907e+05, with an active set of 309 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 376 iterations, i.e. alpha=2.787e+05, with an active set of 309 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 382 iterations, i.e. alpha=2.555e+05, with an active set of 314 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 382 iterations, i.e. alpha=2.444e+05, with an active set of 314 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 383 iterations, i.e. alpha=2.251e+05, with an active set of 315 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 383 iterations, i.e. alpha=2.086e+05, with an active set of 315 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 383 iterations, i.e. alpha=2.020e+05, with an active set of 315 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 383 iterations, i.e. alpha=1.948e+05, with an active set of 315 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 384 iterations, i.e. alpha=1.846e+05, with an active set of 316 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 384 iterations, i.e. alpha=1.823e+05, with an active set of 316 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 384 iterations, i.e. alpha=1.816e+05, with an active set of 316 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 384 iterations, i.e. alpha=1.805e+05, with an active set of 316 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 384 iterations, i.e. alpha=1.804e+05, with an active set of 316 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 384 iterations, i.e. alpha=1.803e+05, with an active set of 316 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 384 iterations, i.e. alpha=1.802e+05, with an active set of 316 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 384 iterations, i.e. alpha=1.802e+05, with an active set of 316 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 384 iterations, i.e. alpha=1.800e+05, with an active set of 316 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 384 iterations, i.e. alpha=1.791e+05, with an active set of 316 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 384 iterations, i.e. alpha=1.790e+05, with an active set of 316 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 384 iterations, i.e. alpha=1.787e+05, with an active set of 316 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 384 iterations, i.e. alpha=1.786e+05, with an active set of 316 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 384 iterations, i.e. alpha=1.786e+05, with an active set of 316 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 384 iterations, i.e. alpha=1.785e+05, with an active set of 316 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 384 iterations, i.e. alpha=1.785e+05, with an active set of 316 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 384 iterations, i.e. alpha=1.785e+05, with an active set of 316 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 384 iterations, i.e. alpha=1.784e+05, with an active set of 316 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 384 iterations, i.e. alpha=1.784e+05, with an active set of 316 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 384 iterations, i.e. alpha=1.784e+05, with an active set of 316 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 384 iterations, i.e. alpha=1.784e+05, with an active set of 316 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 384 iterations, i.e. alpha=1.783e+05, with an active set of 316 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 384 iterations, i.e. alpha=1.783e+05, with an active set of 316 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 384 iterations, i.e. alpha=1.782e+05, with an active set of 316 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 384 iterations, i.e. alpha=1.782e+05, with an active set of 316 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 384 iterations, i.e. alpha=1.782e+05, with an active set of 316 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 384 iterations, i.e. alpha=1.779e+05, with an active set of 316 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 384 iterations, i.e. alpha=1.778e+05, with an active set of 316 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 384 iterations, i.e. alpha=1.777e+05, with an active set of 316 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 384 iterations, i.e. alpha=1.776e+05, with an active set of 316 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 384 iterations, i.e. alpha=1.775e+05, with an active set of 316 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 384 iterations, i.e. alpha=1.775e+05, with an active set of 316 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 384 iterations, i.e. alpha=1.774e+05, with an active set of 316 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 384 iterations, i.e. alpha=1.774e+05, with an active set of 316 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 384 iterations, i.e. alpha=1.773e+05, with an active set of 316 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 384 iterations, i.e. alpha=1.773e+05, with an active set of 316 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 384 iterations, i.e. alpha=1.770e+05, with an active set of 316 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 384 iterations, i.e. alpha=1.761e+05, with an active set of 316 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 384 iterations, i.e. alpha=1.759e+05, with an active set of 316 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 384 iterations, i.e. alpha=1.748e+05, with an active set of 316 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 384 iterations, i.e. alpha=1.726e+05, with an active set of 316 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 384 iterations, i.e. alpha=1.723e+05, with an active set of 316 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 385 iterations, i.e. alpha=1.716e+05, with an active set of 317 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 385 iterations, i.e. alpha=1.688e+05, with an active set of 317 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 385 iterations, i.e. alpha=1.673e+05, with an active set of 317 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 385 iterations, i.e. alpha=1.633e+05, with an active set of 317 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 385 iterations, i.e. alpha=1.631e+05, with an active set of 317 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 385 iterations, i.e. alpha=1.555e+05, with an active set of 317 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 387 iterations, i.e. alpha=1.483e+05, with an active set of 318 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 387 iterations, i.e. alpha=1.458e+05, with an active set of 318 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 389 iterations, i.e. alpha=1.380e+05, with an active set of 320 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 389 iterations, i.e. alpha=1.319e+05, with an active set of 320 regressors, and the smallest cholesky pivot element being 8.025e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=1.122e+05, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=1.121e+05, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=1.092e+05, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=1.001e+05, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=9.119e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=8.912e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=7.744e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=4.743e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=4.736e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=4.727e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=4.130e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=3.812e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=3.610e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=3.232e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=3.157e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=2.213e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=2.195e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=2.112e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=2.068e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=2.025e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=2.010e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=1.997e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=1.992e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=1.983e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=1.980e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=1.979e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=1.978e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=1.977e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=1.976e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=1.976e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=1.976e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=1.975e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=1.975e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=1.975e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=1.974e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=1.974e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=1.974e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=1.974e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=1.974e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=1.973e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=1.973e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=1.973e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=1.973e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=1.973e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=1.973e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=1.972e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=1.972e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=1.969e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=1.969e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=1.969e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=1.968e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=1.961e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=1.956e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=1.951e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=1.900e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=1.835e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=1.777e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=1.508e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=1.408e+04, with an active set of 321 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 392 iterations, i.e. alpha=8.569e+03, with an active set of 323 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=7.370e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 8.025e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=3.990e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=3.532e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=2.887e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=2.714e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=2.414e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=2.391e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=2.218e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=2.128e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=2.107e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=2.088e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=2.086e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=2.083e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=2.080e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=2.077e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=2.075e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=2.074e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=2.073e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=2.073e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=2.073e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=2.072e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=2.072e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=2.072e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=2.072e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=2.071e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=2.071e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=2.071e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=2.070e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=2.070e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=2.070e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=2.070e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=2.070e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=2.069e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=2.069e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=2.069e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=2.069e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=2.068e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=2.067e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=2.067e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=2.067e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=2.067e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=2.066e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=2.066e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=2.065e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=2.064e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=2.056e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=1.990e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=1.816e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=1.422e+03, with an active set of 324 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=7.990e+02, with an active set of 324 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=7.050e+02, with an active set of 324 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=4.735e+02, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 393 iterations, i.e. alpha=4.243e+02, with an active set of 324 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=3.449e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=1.325e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=1.173e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=9.583e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=9.041e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=9.013e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=8.386e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=7.940e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=7.351e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=7.237e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=7.078e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.966e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.932e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.901e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.896e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.890e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.889e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.888e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.886e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.883e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.883e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.882e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.882e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.881e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.881e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.879e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.879e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.878e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.877e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.877e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.874e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.874e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.873e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.873e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.873e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.871e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.869e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.869e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.869e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.868e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.868e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.868e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.868e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.867e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.866e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.866e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.864e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.863e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.862e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.852e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.842e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.821e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.809e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.758e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.726e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=6.617e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=5.001e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=4.907e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 8.025e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=2.661e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 394 iterations, i.e. alpha=2.340e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=4.048e+06, with an active set of 2 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=4.957e+05, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=4.723e+05, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=4.135e+05, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=3.602e+05, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=2.211e+05, with an active set of 72 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 77 iterations, i.e. alpha=2.125e+05, with an active set of 76 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 77 iterations, i.e. alpha=2.069e+05, with an active set of 76 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 77 iterations, i.e. alpha=2.066e+05, with an active set of 76 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 77 iterations, i.e. alpha=2.066e+05, with an active set of 76 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=1.727e+05, with an active set of 84 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 91 iterations, i.e. alpha=1.656e+05, with an active set of 89 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 92 iterations, i.e. alpha=1.626e+05, with an active set of 90 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 92 iterations, i.e. alpha=1.626e+05, with an active set of 90 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 94 iterations, i.e. alpha=1.563e+05, with an active set of 92 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=1.387e+05, with an active set of 105 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=1.387e+05, with an active set of 105 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=1.347e+05, with an active set of 107 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 122 iterations, i.e. alpha=1.284e+05, with an active set of 117 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=1.279e+05, with an active set of 118 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=1.267e+05, with an active set of 118 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=1.193e+05, with an active set of 119 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=1.159e+05, with an active set of 120 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 130 iterations, i.e. alpha=1.145e+05, with an active set of 121 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 130 iterations, i.e. alpha=1.145e+05, with an active set of 121 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 130 iterations, i.e. alpha=1.145e+05, with an active set of 121 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 131 iterations, i.e. alpha=1.122e+05, with an active set of 122 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 133 iterations, i.e. alpha=1.096e+05, with an active set of 124 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 134 iterations, i.e. alpha=1.063e+05, with an active set of 125 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 137 iterations, i.e. alpha=1.051e+05, with an active set of 127 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=1.013e+05, with an active set of 131 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=1.013e+05, with an active set of 131 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 145 iterations, i.e. alpha=9.717e+04, with an active set of 134 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 147 iterations, i.e. alpha=9.659e+04, with an active set of 136 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 150 iterations, i.e. alpha=9.446e+04, with an active set of 139 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=9.322e+04, with an active set of 140 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=9.322e+04, with an active set of 140 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=9.290e+04, with an active set of 140 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=9.277e+04, with an active set of 140 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 155 iterations, i.e. alpha=8.841e+04, with an active set of 143 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 167 iterations, i.e. alpha=8.221e+04, with an active set of 153 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 178 iterations, i.e. alpha=7.934e+04, with an active set of 160 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 178 iterations, i.e. alpha=7.934e+04, with an active set of 160 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 186 iterations, i.e. alpha=7.876e+04, with an active set of 166 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 186 iterations, i.e. alpha=7.866e+04, with an active set of 166 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 187 iterations, i.e. alpha=7.601e+04, with an active set of 167 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 197 iterations, i.e. alpha=7.324e+04, with an active set of 176 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 199 iterations, i.e. alpha=7.262e+04, with an active set of 178 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 203 iterations, i.e. alpha=7.138e+04, with an active set of 182 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 205 iterations, i.e. alpha=7.056e+04, with an active set of 184 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 205 iterations, i.e. alpha=6.989e+04, with an active set of 184 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 207 iterations, i.e. alpha=6.756e+04, with an active set of 186 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 207 iterations, i.e. alpha=6.729e+04, with an active set of 186 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 211 iterations, i.e. alpha=6.561e+04, with an active set of 189 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 217 iterations, i.e. alpha=6.390e+04, with an active set of 194 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 218 iterations, i.e. alpha=6.380e+04, with an active set of 195 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 220 iterations, i.e. alpha=6.356e+04, with an active set of 197 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 220 iterations, i.e. alpha=6.356e+04, with an active set of 197 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 220 iterations, i.e. alpha=6.355e+04, with an active set of 197 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 220 iterations, i.e. alpha=6.353e+04, with an active set of 197 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 220 iterations, i.e. alpha=6.300e+04, with an active set of 197 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 223 iterations, i.e. alpha=6.021e+04, with an active set of 200 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 223 iterations, i.e. alpha=6.021e+04, with an active set of 200 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 223 iterations, i.e. alpha=5.977e+04, with an active set of 200 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 223 iterations, i.e. alpha=5.965e+04, with an active set of 200 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 226 iterations, i.e. alpha=5.920e+04, with an active set of 203 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 226 iterations, i.e. alpha=5.898e+04, with an active set of 203 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 229 iterations, i.e. alpha=5.753e+04, with an active set of 206 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 229 iterations, i.e. alpha=5.753e+04, with an active set of 206 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 231 iterations, i.e. alpha=5.660e+04, with an active set of 208 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 231 iterations, i.e. alpha=5.635e+04, with an active set of 208 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 231 iterations, i.e. alpha=5.610e+04, with an active set of 208 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 232 iterations, i.e. alpha=5.430e+04, with an active set of 209 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 232 iterations, i.e. alpha=5.430e+04, with an active set of 209 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 232 iterations, i.e. alpha=5.409e+04, with an active set of 209 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 232 iterations, i.e. alpha=5.385e+04, with an active set of 209 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 240 iterations, i.e. alpha=5.091e+04, with an active set of 216 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 242 iterations, i.e. alpha=5.033e+04, with an active set of 218 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 242 iterations, i.e. alpha=5.033e+04, with an active set of 218 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 244 iterations, i.e. alpha=4.956e+04, with an active set of 220 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 244 iterations, i.e. alpha=4.956e+04, with an active set of 220 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 248 iterations, i.e. alpha=4.929e+04, with an active set of 224 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 248 iterations, i.e. alpha=4.877e+04, with an active set of 224 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 249 iterations, i.e. alpha=4.815e+04, with an active set of 225 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 249 iterations, i.e. alpha=4.713e+04, with an active set of 225 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 249 iterations, i.e. alpha=4.712e+04, with an active set of 225 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 249 iterations, i.e. alpha=4.710e+04, with an active set of 225 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 249 iterations, i.e. alpha=4.696e+04, with an active set of 225 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 249 iterations, i.e. alpha=4.660e+04, with an active set of 225 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=4.543e+04, with an active set of 230 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=4.543e+04, with an active set of 230 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 256 iterations, i.e. alpha=4.542e+04, with an active set of 230 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 265 iterations, i.e. alpha=4.325e+04, with an active set of 237 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=4.223e+04, with an active set of 241 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=4.223e+04, with an active set of 241 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=4.223e+04, with an active set of 241 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=3.924e+04, with an active set of 246 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=3.924e+04, with an active set of 246 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=3.924e+04, with an active set of 246 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 274 iterations, i.e. alpha=3.912e+04, with an active set of 246 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=3.756e+04, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=3.752e+04, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 277 iterations, i.e. alpha=3.752e+04, with an active set of 249 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=3.650e+04, with an active set of 252 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 280 iterations, i.e. alpha=3.650e+04, with an active set of 252 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=3.541e+04, with an active set of 255 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=3.533e+04, with an active set of 255 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=3.505e+04, with an active set of 255 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=3.451e+04, with an active set of 255 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 283 iterations, i.e. alpha=3.352e+04, with an active set of 255 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 285 iterations, i.e. alpha=3.330e+04, with an active set of 257 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 291 iterations, i.e. alpha=3.115e+04, with an active set of 262 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 294 iterations, i.e. alpha=3.036e+04, with an active set of 265 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 294 iterations, i.e. alpha=3.036e+04, with an active set of 265 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 294 iterations, i.e. alpha=3.035e+04, with an active set of 265 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 294 iterations, i.e. alpha=3.023e+04, with an active set of 265 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 296 iterations, i.e. alpha=2.998e+04, with an active set of 267 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 300 iterations, i.e. alpha=2.887e+04, with an active set of 271 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 300 iterations, i.e. alpha=2.886e+04, with an active set of 271 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 300 iterations, i.e. alpha=2.884e+04, with an active set of 271 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 301 iterations, i.e. alpha=2.829e+04, with an active set of 272 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 301 iterations, i.e. alpha=2.747e+04, with an active set of 272 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 301 iterations, i.e. alpha=2.717e+04, with an active set of 272 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 301 iterations, i.e. alpha=2.717e+04, with an active set of 272 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 301 iterations, i.e. alpha=2.714e+04, with an active set of 272 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 301 iterations, i.e. alpha=2.709e+04, with an active set of 272 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 301 iterations, i.e. alpha=2.695e+04, with an active set of 272 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 311 iterations, i.e. alpha=2.706e+04, with an active set of 280 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 311 iterations, i.e. alpha=2.706e+04, with an active set of 280 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 311 iterations, i.e. alpha=2.705e+04, with an active set of 280 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 312 iterations, i.e. alpha=2.642e+04, with an active set of 281 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 316 iterations, i.e. alpha=2.491e+04, with an active set of 285 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 317 iterations, i.e. alpha=2.432e+04, with an active set of 286 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 317 iterations, i.e. alpha=2.432e+04, with an active set of 286 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 319 iterations, i.e. alpha=2.409e+04, with an active set of 287 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 319 iterations, i.e. alpha=2.407e+04, with an active set of 287 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 324 iterations, i.e. alpha=2.352e+04, with an active set of 292 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 324 iterations, i.e. alpha=2.352e+04, with an active set of 292 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 324 iterations, i.e. alpha=2.341e+04, with an active set of 292 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 325 iterations, i.e. alpha=2.276e+04, with an active set of 293 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 325 iterations, i.e. alpha=2.272e+04, with an active set of 293 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 325 iterations, i.e. alpha=2.267e+04, with an active set of 293 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 325 iterations, i.e. alpha=2.252e+04, with an active set of 293 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 325 iterations, i.e. alpha=2.252e+04, with an active set of 293 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 325 iterations, i.e. alpha=2.251e+04, with an active set of 293 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 325 iterations, i.e. alpha=2.248e+04, with an active set of 293 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 325 iterations, i.e. alpha=2.247e+04, with an active set of 293 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 325 iterations, i.e. alpha=2.247e+04, with an active set of 293 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 327 iterations, i.e. alpha=2.196e+04, with an active set of 295 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 327 iterations, i.e. alpha=2.150e+04, with an active set of 295 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 327 iterations, i.e. alpha=2.057e+04, with an active set of 295 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 327 iterations, i.e. alpha=2.043e+04, with an active set of 295 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 327 iterations, i.e. alpha=2.033e+04, with an active set of 295 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 331 iterations, i.e. alpha=1.930e+04, with an active set of 298 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 331 iterations, i.e. alpha=1.928e+04, with an active set of 298 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 331 iterations, i.e. alpha=1.926e+04, with an active set of 298 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 334 iterations, i.e. alpha=1.898e+04, with an active set of 299 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 336 iterations, i.e. alpha=1.883e+04, with an active set of 301 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 337 iterations, i.e. alpha=1.868e+04, with an active set of 302 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 337 iterations, i.e. alpha=1.868e+04, with an active set of 302 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 337 iterations, i.e. alpha=1.867e+04, with an active set of 302 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 338 iterations, i.e. alpha=1.810e+04, with an active set of 303 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 339 iterations, i.e. alpha=1.810e+04, with an active set of 304 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 339 iterations, i.e. alpha=1.809e+04, with an active set of 304 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 339 iterations, i.e. alpha=1.800e+04, with an active set of 304 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 339 iterations, i.e. alpha=1.791e+04, with an active set of 304 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 339 iterations, i.e. alpha=1.781e+04, with an active set of 304 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 339 iterations, i.e. alpha=1.757e+04, with an active set of 304 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 339 iterations, i.e. alpha=1.755e+04, with an active set of 304 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 339 iterations, i.e. alpha=1.755e+04, with an active set of 304 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 339 iterations, i.e. alpha=1.755e+04, with an active set of 304 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=1.665e+04, with an active set of 305 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=1.663e+04, with an active set of 305 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=1.663e+04, with an active set of 305 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=1.654e+04, with an active set of 305 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=1.654e+04, with an active set of 305 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=1.617e+04, with an active set of 305 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 347 iterations, i.e. alpha=1.593e+04, with an active set of 308 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=1.543e+04, with an active set of 309 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=1.539e+04, with an active set of 309 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=1.539e+04, with an active set of 309 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=1.539e+04, with an active set of 309 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=1.533e+04, with an active set of 309 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=1.411e+04, with an active set of 309 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=1.316e+04, with an active set of 309 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=1.312e+04, with an active set of 310 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=1.308e+04, with an active set of 310 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=1.301e+04, with an active set of 310 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=1.287e+04, with an active set of 310 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=1.236e+04, with an active set of 311 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=1.235e+04, with an active set of 311 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=1.234e+04, with an active set of 311 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=1.152e+04, with an active set of 311 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=1.151e+04, with an active set of 311 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=1.140e+04, with an active set of 311 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=1.114e+04, with an active set of 311 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=1.114e+04, with an active set of 311 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=1.113e+04, with an active set of 311 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=1.076e+04, with an active set of 311 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=9.815e+03, with an active set of 311 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=9.786e+03, with an active set of 311 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=9.333e+03, with an active set of 311 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=9.331e+03, with an active set of 311 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=9.330e+03, with an active set of 311 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 353 iterations, i.e. alpha=8.574e+03, with an active set of 311 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=8.486e+03, with an active set of 312 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=8.471e+03, with an active set of 312 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=8.465e+03, with an active set of 312 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=8.464e+03, with an active set of 312 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=8.461e+03, with an active set of 312 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=8.453e+03, with an active set of 312 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=8.429e+03, with an active set of 312 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=8.421e+03, with an active set of 312 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=8.412e+03, with an active set of 312 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=8.408e+03, with an active set of 312 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=7.845e+03, with an active set of 312 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=7.750e+03, with an active set of 312 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=7.156e+03, with an active set of 312 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=6.961e+03, with an active set of 313 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=6.554e+03, with an active set of 315 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=6.553e+03, with an active set of 315 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=6.547e+03, with an active set of 315 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=6.489e+03, with an active set of 315 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=6.147e+03, with an active set of 315 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=6.068e+03, with an active set of 315 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=6.015e+03, with an active set of 315 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=5.938e+03, with an active set of 315 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=5.938e+03, with an active set of 315 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=5.863e+03, with an active set of 315 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 359 iterations, i.e. alpha=5.825e+03, with an active set of 315 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=5.465e+03, with an active set of 316 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=5.465e+03, with an active set of 316 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=5.281e+03, with an active set of 316 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=5.277e+03, with an active set of 316 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=5.277e+03, with an active set of 316 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=5.275e+03, with an active set of 316 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=5.274e+03, with an active set of 316 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=5.265e+03, with an active set of 316 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=5.263e+03, with an active set of 316 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=5.237e+03, with an active set of 316 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=5.144e+03, with an active set of 316 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=5.028e+03, with an active set of 316 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=5.022e+03, with an active set of 316 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=5.016e+03, with an active set of 316 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=5.006e+03, with an active set of 316 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 360 iterations, i.e. alpha=4.988e+03, with an active set of 316 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=4.752e+03, with an active set of 317 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=4.745e+03, with an active set of 317 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=4.500e+03, with an active set of 317 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=4.470e+03, with an active set of 317 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=4.281e+03, with an active set of 317 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=4.277e+03, with an active set of 317 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=4.080e+03, with an active set of 318 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=3.827e+03, with an active set of 318 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=3.823e+03, with an active set of 318 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=3.823e+03, with an active set of 318 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=3.808e+03, with an active set of 318 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=3.781e+03, with an active set of 318 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=3.780e+03, with an active set of 318 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=3.779e+03, with an active set of 318 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=3.778e+03, with an active set of 318 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=3.778e+03, with an active set of 318 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=3.775e+03, with an active set of 318 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=3.451e+03, with an active set of 318 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=3.449e+03, with an active set of 318 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=3.448e+03, with an active set of 318 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=3.447e+03, with an active set of 318 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=3.409e+03, with an active set of 318 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=3.401e+03, with an active set of 318 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=3.296e+03, with an active set of 318 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=3.167e+03, with an active set of 318 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=3.052e+03, with an active set of 318 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 363 iterations, i.e. alpha=2.537e+03, with an active set of 319 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 364 iterations, i.e. alpha=2.305e+03, with an active set of 320 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 364 iterations, i.e. alpha=2.129e+03, with an active set of 320 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 364 iterations, i.e. alpha=1.803e+03, with an active set of 320 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 364 iterations, i.e. alpha=1.699e+03, with an active set of 320 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 364 iterations, i.e. alpha=1.394e+03, with an active set of 320 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 364 iterations, i.e. alpha=1.350e+03, with an active set of 320 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 364 iterations, i.e. alpha=1.329e+03, with an active set of 320 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 365 iterations, i.e. alpha=1.283e+03, with an active set of 321 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 365 iterations, i.e. alpha=1.277e+03, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 365 iterations, i.e. alpha=1.277e+03, with an active set of 321 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 365 iterations, i.e. alpha=1.276e+03, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 365 iterations, i.e. alpha=1.276e+03, with an active set of 321 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 365 iterations, i.e. alpha=1.275e+03, with an active set of 321 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 365 iterations, i.e. alpha=1.266e+03, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 365 iterations, i.e. alpha=1.266e+03, with an active set of 321 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 365 iterations, i.e. alpha=1.265e+03, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 365 iterations, i.e. alpha=1.259e+03, with an active set of 321 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 367 iterations, i.e. alpha=1.234e+03, with an active set of 323 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 367 iterations, i.e. alpha=1.115e+03, with an active set of 323 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 367 iterations, i.e. alpha=1.101e+03, with an active set of 323 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 367 iterations, i.e. alpha=1.090e+03, with an active set of 323 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 367 iterations, i.e. alpha=1.090e+03, with an active set of 323 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 367 iterations, i.e. alpha=1.089e+03, with an active set of 323 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 367 iterations, i.e. alpha=1.089e+03, with an active set of 323 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 367 iterations, i.e. alpha=1.088e+03, with an active set of 323 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 367 iterations, i.e. alpha=1.088e+03, with an active set of 323 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 367 iterations, i.e. alpha=1.087e+03, with an active set of 323 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 367 iterations, i.e. alpha=1.068e+03, with an active set of 323 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 367 iterations, i.e. alpha=1.056e+03, with an active set of 323 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 367 iterations, i.e. alpha=1.048e+03, with an active set of 323 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 367 iterations, i.e. alpha=1.027e+03, with an active set of 323 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 367 iterations, i.e. alpha=1.025e+03, with an active set of 323 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 367 iterations, i.e. alpha=1.024e+03, with an active set of 323 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 367 iterations, i.e. alpha=1.024e+03, with an active set of 323 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 367 iterations, i.e. alpha=1.023e+03, with an active set of 323 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 367 iterations, i.e. alpha=8.993e+02, with an active set of 323 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=5.648e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=5.648e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=5.647e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=5.641e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=5.640e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=5.637e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=5.634e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=5.633e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=5.235e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=5.208e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=5.193e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=5.186e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=5.183e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=5.181e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=5.181e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=5.179e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=5.178e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=5.176e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=5.176e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=5.169e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=5.145e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=5.132e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=4.254e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=3.845e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=3.800e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=3.794e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=3.636e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=3.266e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=3.131e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=3.066e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 5.475e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=3.030e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=3.030e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=3.029e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=3.028e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=3.027e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=3.027e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=3.026e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=3.025e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=3.025e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=3.024e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=3.024e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=3.024e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=3.023e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=3.023e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=2.996e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=2.801e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=2.304e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=2.203e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=2.096e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=1.941e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=1.919e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=1.625e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=1.622e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=1.617e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=1.615e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=1.484e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=1.197e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=1.178e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=1.161e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=1.161e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=1.160e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=1.159e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=1.159e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=1.155e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=1.137e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=1.013e+02, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=9.885e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=9.822e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=9.814e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=9.813e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=9.812e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=9.811e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=9.809e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=9.806e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=9.805e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=9.803e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=9.801e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=9.800e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=9.799e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=9.795e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=9.789e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=9.788e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=9.787e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=6.418e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=5.684e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=5.573e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=3.784e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 369 iterations, i.e. alpha=1.219e+01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 6, 0, 6, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 6, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 6, 6, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 1, 1, 0,\n",
       "       2, 0, 1, 1, 1, 0, 2, 0, 1, 1, 1, 7, 3, 0, 6, 1, 0, 0, 6, 7, 0, 1,\n",
       "       1, 6, 6, 6, 1, 4, 1, 0, 3, 1, 1, 0, 0, 0, 0, 1, 0, 7, 0, 6, 0, 1,\n",
       "       0, 0, 7, 6, 0, 0, 0, 1, 1, 0, 7, 6, 1, 5, 6, 1, 1, 1, 0, 1, 1, 1,\n",
       "       4, 0, 6, 2, 6, 1, 0, 1, 0, 0, 6, 1, 1, 0, 0, 0, 0, 0, 0, 0, 3, 0,\n",
       "       0, 2, 0, 0, 0, 7, 7, 0, 6, 0, 1, 6, 2, 0, 3, 3, 0, 0, 0, 0, 0, 1,\n",
       "       0, 2, 2, 0, 0, 0, 0, 0, 0, 6, 0, 0, 6, 0, 6, 0, 6, 0, 3, 4, 0, 0,\n",
       "       0, 0, 0, 6, 0, 1, 0, 0, 1, 1, 0, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 5, 0, 6, 0, 1, 0, 0, 0, 0, 6, 0, 1,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 5, 0, 0, 5,\n",
       "       0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 3, 0, 0, 0, 6, 1, 5, 0, 0, 6,\n",
       "       0, 5, 1, 0, 0, 5, 3, 0, 3, 1, 3, 1, 0, 0, 0, 0, 6, 1, 0, 0, 5, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 5, 2, 0, 1, 1, 1, 3, 1, 0, 0, 1, 1, 4, 1, 0, 0, 1, 1, 5, 1, 0,\n",
       "       6, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 4, 0, 0, 6, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 4, 0, 0, 0, 5, 1, 1, 1, 1,\n",
       "       2, 0, 0, 0, 2, 1, 5, 0, 0, 3, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       5, 0, 0, 5, 0, 0, 1, 1, 0, 3, 2, 0, 6, 1, 1, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 3, 1, 2, 3, 1, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 3, 1, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 2, 2, 0, 0, 7, 1, 2, 2, 2, 2, 2, 1, 0, 0,\n",
       "       2, 0, 0, 1, 1, 1, 1, 1, 7, 1, 1, 0, 0, 0, 0, 1, 3, 1, 2, 1, 1, 0,\n",
       "       2, 2, 7, 7, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 2, 0, 1, 0, 1, 2, 5,\n",
       "       2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 0, 6, 0, 0, 5, 5, 1, 0, 7,\n",
       "       1, 0, 2, 0, 1, 0, 0, 0, 1, 0, 0, 1, 5, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 6, 0, 7, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 3, 1,\n",
       "       1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 7, 2, 0, 0, 0, 0, 3, 0, 1, 0, 1, 1,\n",
       "       0, 0, 3, 0, 0, 0, 3, 0, 3, 1, 0, 0, 0, 6, 1, 0, 3, 7, 0, 1, 2, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 2, 3, 0, 2, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0,\n",
       "       1, 1, 0, 0, 6, 1, 1, 5, 0, 3, 0, 0, 0, 0, 0, 0, 1, 0, 0, 5, 3, 3,\n",
       "       4, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 5, 2, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 0, 3, 1, 1, 3, 0, 5, 3, 0, 0, 1, 0, 5, 1, 5, 0, 0, 0, 3, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 7, 0, 0, 1, 0, 0, 0, 0,\n",
       "       7, 1, 0, 4, 0, 1, 0, 6, 0, 0, 0, 3, 7, 0, 0, 0, 5, 1, 1, 1, 1, 1,\n",
       "       0, 1, 3, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 6, 0, 1, 1, 0, 4, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 1, 5, 0, 0, 0, 0, 0, 0, 0, 0, 1, 6, 0, 4,\n",
       "       1, 1, 6, 1, 1, 0, 0, 1, 1, 5, 0, 1, 1, 0, 0, 0, 0, 5, 0, 1, 1, 1,\n",
       "       1, 2, 2, 1, 0, 0, 0, 0, 0, 1, 3, 7, 0, 6, 1, 6, 7, 1, 6, 0, 1, 6,\n",
       "       0, 0, 0, 0, 6, 6, 6, 1, 6, 2, 4, 0, 4, 4, 0, 4, 4, 4, 0, 0, 4, 0,\n",
       "       0, 4, 0, 0, 0, 0, 0, 0, 7, 4, 0, 0, 0, 4, 0, 0, 7, 0, 0, 7, 0, 0])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fsfc.generic import MCFS\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('select', MCFS(30,3)),\n",
    "    ('cluster', KMeans())\n",
    "])\n",
    "pipeline.fit_predict(np.array(B16172_test.iloc[:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=3.295e+05, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.866e+05, with an active set of 3 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.866e+05, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=2.108e+05, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.043e+05, with an active set of 11 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.023e+05, with an active set of 11 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=5.095e+04, with an active set of 21 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=4.927e+04, with an active set of 21 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=4.411e+04, with an active set of 24 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=3.887e+04, with an active set of 28 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=2.812e+04, with an active set of 39 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=2.368e+04, with an active set of 45 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=2.368e+04, with an active set of 45 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=2.282e+04, with an active set of 48 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=2.183e+04, with an active set of 51 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=2.047e+04, with an active set of 57 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=1.772e+04, with an active set of 68 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=1.772e+04, with an active set of 68 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 91 iterations, i.e. alpha=1.298e+04, with an active set of 89 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 92 iterations, i.e. alpha=1.256e+04, with an active set of 90 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=1.246e+04, with an active set of 93 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 97 iterations, i.e. alpha=1.228e+04, with an active set of 94 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 99 iterations, i.e. alpha=1.202e+04, with an active set of 96 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=1.156e+04, with an active set of 99 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=1.156e+04, with an active set of 99 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=1.155e+04, with an active set of 99 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=1.034e+04, with an active set of 107 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=9.828e+03, with an active set of 114 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=9.828e+03, with an active set of 114 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=9.716e+03, with an active set of 116 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=9.133e+03, with an active set of 121 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 127 iterations, i.e. alpha=8.938e+03, with an active set of 123 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 131 iterations, i.e. alpha=8.741e+03, with an active set of 127 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 136 iterations, i.e. alpha=8.609e+03, with an active set of 131 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 136 iterations, i.e. alpha=8.609e+03, with an active set of 131 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=8.074e+03, with an active set of 137 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=8.074e+03, with an active set of 137 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=7.552e+03, with an active set of 145 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 152 iterations, i.e. alpha=7.550e+03, with an active set of 146 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 152 iterations, i.e. alpha=7.480e+03, with an active set of 146 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=6.987e+03, with an active set of 154 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=6.981e+03, with an active set of 154 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=6.887e+03, with an active set of 154 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=6.829e+03, with an active set of 154 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=6.396e+03, with an active set of 163 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 172 iterations, i.e. alpha=6.377e+03, with an active set of 164 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 172 iterations, i.e. alpha=6.349e+03, with an active set of 164 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 185 iterations, i.e. alpha=5.656e+03, with an active set of 177 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 185 iterations, i.e. alpha=5.656e+03, with an active set of 177 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 186 iterations, i.e. alpha=5.514e+03, with an active set of 178 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 189 iterations, i.e. alpha=5.426e+03, with an active set of 181 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 189 iterations, i.e. alpha=5.426e+03, with an active set of 181 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 193 iterations, i.e. alpha=5.209e+03, with an active set of 185 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 193 iterations, i.e. alpha=5.209e+03, with an active set of 185 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 193 iterations, i.e. alpha=5.209e+03, with an active set of 185 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 193 iterations, i.e. alpha=5.172e+03, with an active set of 185 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 204 iterations, i.e. alpha=4.883e+03, with an active set of 195 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 204 iterations, i.e. alpha=4.883e+03, with an active set of 195 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 206 iterations, i.e. alpha=4.761e+03, with an active set of 197 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 206 iterations, i.e. alpha=4.759e+03, with an active set of 197 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 207 iterations, i.e. alpha=4.695e+03, with an active set of 198 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 207 iterations, i.e. alpha=4.695e+03, with an active set of 198 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 207 iterations, i.e. alpha=4.667e+03, with an active set of 198 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 209 iterations, i.e. alpha=4.616e+03, with an active set of 199 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 210 iterations, i.e. alpha=4.578e+03, with an active set of 200 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 210 iterations, i.e. alpha=4.578e+03, with an active set of 200 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 215 iterations, i.e. alpha=4.472e+03, with an active set of 205 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 215 iterations, i.e. alpha=4.472e+03, with an active set of 205 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 215 iterations, i.e. alpha=4.472e+03, with an active set of 205 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 218 iterations, i.e. alpha=4.423e+03, with an active set of 208 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 221 iterations, i.e. alpha=4.396e+03, with an active set of 211 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 221 iterations, i.e. alpha=4.396e+03, with an active set of 211 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 223 iterations, i.e. alpha=4.356e+03, with an active set of 213 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 223 iterations, i.e. alpha=4.333e+03, with an active set of 213 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 230 iterations, i.e. alpha=4.146e+03, with an active set of 220 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 234 iterations, i.e. alpha=3.974e+03, with an active set of 223 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 234 iterations, i.e. alpha=3.969e+03, with an active set of 223 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 234 iterations, i.e. alpha=3.946e+03, with an active set of 223 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 239 iterations, i.e. alpha=3.868e+03, with an active set of 228 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 239 iterations, i.e. alpha=3.868e+03, with an active set of 228 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 242 iterations, i.e. alpha=3.742e+03, with an active set of 230 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 242 iterations, i.e. alpha=3.741e+03, with an active set of 230 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 243 iterations, i.e. alpha=3.726e+03, with an active set of 231 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 245 iterations, i.e. alpha=3.670e+03, with an active set of 233 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 250 iterations, i.e. alpha=3.518e+03, with an active set of 237 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 253 iterations, i.e. alpha=3.417e+03, with an active set of 240 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 253 iterations, i.e. alpha=3.416e+03, with an active set of 240 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 255 iterations, i.e. alpha=3.364e+03, with an active set of 242 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 260 iterations, i.e. alpha=3.161e+03, with an active set of 246 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 260 iterations, i.e. alpha=3.160e+03, with an active set of 246 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 260 iterations, i.e. alpha=3.139e+03, with an active set of 246 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 260 iterations, i.e. alpha=3.094e+03, with an active set of 246 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 268 iterations, i.e. alpha=3.015e+03, with an active set of 249 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=2.986e+03, with an active set of 250 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 285 iterations, i.e. alpha=3.696e+03, with an active set of 261 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 285 iterations, i.e. alpha=3.489e+03, with an active set of 261 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 285 iterations, i.e. alpha=3.488e+03, with an active set of 261 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 285 iterations, i.e. alpha=3.487e+03, with an active set of 261 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 285 iterations, i.e. alpha=3.475e+03, with an active set of 261 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 285 iterations, i.e. alpha=3.377e+03, with an active set of 261 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 285 iterations, i.e. alpha=3.345e+03, with an active set of 261 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 285 iterations, i.e. alpha=3.345e+03, with an active set of 261 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 287 iterations, i.e. alpha=3.312e+03, with an active set of 263 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=3.233e+03, with an active set of 266 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=3.232e+03, with an active set of 266 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=3.230e+03, with an active set of 266 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=3.229e+03, with an active set of 266 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 290 iterations, i.e. alpha=3.228e+03, with an active set of 266 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 291 iterations, i.e. alpha=3.008e+03, with an active set of 267 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 291 iterations, i.e. alpha=2.729e+03, with an active set of 267 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 291 iterations, i.e. alpha=2.698e+03, with an active set of 267 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 291 iterations, i.e. alpha=2.679e+03, with an active set of 267 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 291 iterations, i.e. alpha=2.679e+03, with an active set of 267 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 291 iterations, i.e. alpha=2.606e+03, with an active set of 267 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 291 iterations, i.e. alpha=2.588e+03, with an active set of 267 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 291 iterations, i.e. alpha=2.586e+03, with an active set of 267 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 294 iterations, i.e. alpha=2.560e+03, with an active set of 270 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 294 iterations, i.e. alpha=2.525e+03, with an active set of 270 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 294 iterations, i.e. alpha=2.514e+03, with an active set of 270 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 294 iterations, i.e. alpha=2.512e+03, with an active set of 270 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 294 iterations, i.e. alpha=2.484e+03, with an active set of 270 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 294 iterations, i.e. alpha=2.484e+03, with an active set of 270 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 295 iterations, i.e. alpha=2.482e+03, with an active set of 271 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 300 iterations, i.e. alpha=2.436e+03, with an active set of 276 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 302 iterations, i.e. alpha=2.406e+03, with an active set of 278 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 302 iterations, i.e. alpha=2.395e+03, with an active set of 278 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 302 iterations, i.e. alpha=2.394e+03, with an active set of 278 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 302 iterations, i.e. alpha=2.373e+03, with an active set of 278 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 302 iterations, i.e. alpha=2.366e+03, with an active set of 278 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 302 iterations, i.e. alpha=2.201e+03, with an active set of 278 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 302 iterations, i.e. alpha=2.200e+03, with an active set of 278 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 302 iterations, i.e. alpha=2.198e+03, with an active set of 278 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 302 iterations, i.e. alpha=2.141e+03, with an active set of 278 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 302 iterations, i.e. alpha=2.134e+03, with an active set of 278 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 302 iterations, i.e. alpha=2.133e+03, with an active set of 278 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 302 iterations, i.e. alpha=2.132e+03, with an active set of 278 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 302 iterations, i.e. alpha=2.014e+03, with an active set of 278 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 302 iterations, i.e. alpha=2.001e+03, with an active set of 278 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 306 iterations, i.e. alpha=1.883e+03, with an active set of 281 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 306 iterations, i.e. alpha=1.858e+03, with an active set of 281 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 306 iterations, i.e. alpha=1.857e+03, with an active set of 281 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 307 iterations, i.e. alpha=1.818e+03, with an active set of 282 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=1.774e+03, with an active set of 283 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 309 iterations, i.e. alpha=1.722e+03, with an active set of 284 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 309 iterations, i.e. alpha=1.721e+03, with an active set of 284 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 309 iterations, i.e. alpha=1.720e+03, with an active set of 284 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 309 iterations, i.e. alpha=1.653e+03, with an active set of 284 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 309 iterations, i.e. alpha=1.653e+03, with an active set of 284 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 309 iterations, i.e. alpha=1.642e+03, with an active set of 284 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 311 iterations, i.e. alpha=1.537e+03, with an active set of 285 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 311 iterations, i.e. alpha=1.528e+03, with an active set of 285 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 315 iterations, i.e. alpha=1.454e+03, with an active set of 288 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 318 iterations, i.e. alpha=1.452e+03, with an active set of 289 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 318 iterations, i.e. alpha=1.421e+03, with an active set of 289 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 320 iterations, i.e. alpha=1.366e+03, with an active set of 290 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 321 iterations, i.e. alpha=1.302e+03, with an active set of 291 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 325 iterations, i.e. alpha=1.357e+03, with an active set of 293 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 326 iterations, i.e. alpha=1.274e+03, with an active set of 294 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 326 iterations, i.e. alpha=1.204e+03, with an active set of 294 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 326 iterations, i.e. alpha=1.199e+03, with an active set of 294 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 327 iterations, i.e. alpha=1.123e+03, with an active set of 295 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 328 iterations, i.e. alpha=1.104e+03, with an active set of 296 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 328 iterations, i.e. alpha=1.097e+03, with an active set of 296 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 328 iterations, i.e. alpha=1.058e+03, with an active set of 296 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 328 iterations, i.e. alpha=1.048e+03, with an active set of 296 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 328 iterations, i.e. alpha=1.029e+03, with an active set of 296 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 330 iterations, i.e. alpha=9.830e+02, with an active set of 298 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 330 iterations, i.e. alpha=9.767e+02, with an active set of 298 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 332 iterations, i.e. alpha=9.474e+02, with an active set of 300 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 336 iterations, i.e. alpha=9.148e+02, with an active set of 303 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 338 iterations, i.e. alpha=8.878e+02, with an active set of 304 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 338 iterations, i.e. alpha=8.877e+02, with an active set of 304 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 338 iterations, i.e. alpha=8.873e+02, with an active set of 304 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 338 iterations, i.e. alpha=8.873e+02, with an active set of 304 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 338 iterations, i.e. alpha=8.872e+02, with an active set of 304 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 338 iterations, i.e. alpha=8.870e+02, with an active set of 304 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 338 iterations, i.e. alpha=8.813e+02, with an active set of 304 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 338 iterations, i.e. alpha=8.807e+02, with an active set of 304 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 338 iterations, i.e. alpha=8.734e+02, with an active set of 304 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 339 iterations, i.e. alpha=8.594e+02, with an active set of 305 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 339 iterations, i.e. alpha=8.368e+02, with an active set of 305 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 339 iterations, i.e. alpha=8.161e+02, with an active set of 305 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 339 iterations, i.e. alpha=8.155e+02, with an active set of 305 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 339 iterations, i.e. alpha=8.155e+02, with an active set of 305 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 339 iterations, i.e. alpha=8.151e+02, with an active set of 305 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 340 iterations, i.e. alpha=8.070e+02, with an active set of 306 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 340 iterations, i.e. alpha=8.068e+02, with an active set of 306 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 340 iterations, i.e. alpha=8.066e+02, with an active set of 306 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 340 iterations, i.e. alpha=8.066e+02, with an active set of 306 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 340 iterations, i.e. alpha=8.064e+02, with an active set of 306 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 340 iterations, i.e. alpha=8.063e+02, with an active set of 306 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 340 iterations, i.e. alpha=8.059e+02, with an active set of 306 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 340 iterations, i.e. alpha=8.058e+02, with an active set of 306 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 340 iterations, i.e. alpha=8.042e+02, with an active set of 306 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 340 iterations, i.e. alpha=7.854e+02, with an active set of 306 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 340 iterations, i.e. alpha=7.853e+02, with an active set of 306 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 340 iterations, i.e. alpha=7.852e+02, with an active set of 306 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 340 iterations, i.e. alpha=7.850e+02, with an active set of 306 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 340 iterations, i.e. alpha=7.849e+02, with an active set of 306 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 340 iterations, i.e. alpha=7.847e+02, with an active set of 306 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 340 iterations, i.e. alpha=7.844e+02, with an active set of 306 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=7.741e+02, with an active set of 307 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=7.664e+02, with an active set of 307 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 342 iterations, i.e. alpha=7.535e+02, with an active set of 308 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 342 iterations, i.e. alpha=7.447e+02, with an active set of 308 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 342 iterations, i.e. alpha=7.444e+02, with an active set of 308 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 342 iterations, i.e. alpha=7.443e+02, with an active set of 308 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 342 iterations, i.e. alpha=7.442e+02, with an active set of 308 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 342 iterations, i.e. alpha=7.441e+02, with an active set of 308 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 342 iterations, i.e. alpha=7.438e+02, with an active set of 308 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 342 iterations, i.e. alpha=7.437e+02, with an active set of 308 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 342 iterations, i.e. alpha=7.436e+02, with an active set of 308 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 342 iterations, i.e. alpha=7.348e+02, with an active set of 308 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 342 iterations, i.e. alpha=7.340e+02, with an active set of 308 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 342 iterations, i.e. alpha=6.983e+02, with an active set of 308 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 342 iterations, i.e. alpha=6.909e+02, with an active set of 308 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 342 iterations, i.e. alpha=6.907e+02, with an active set of 308 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 342 iterations, i.e. alpha=6.865e+02, with an active set of 308 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 344 iterations, i.e. alpha=6.657e+02, with an active set of 309 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 344 iterations, i.e. alpha=6.655e+02, with an active set of 309 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 345 iterations, i.e. alpha=6.090e+02, with an active set of 310 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 346 iterations, i.e. alpha=6.057e+02, with an active set of 311 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 346 iterations, i.e. alpha=6.054e+02, with an active set of 311 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 346 iterations, i.e. alpha=6.053e+02, with an active set of 311 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 346 iterations, i.e. alpha=6.047e+02, with an active set of 311 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 346 iterations, i.e. alpha=5.810e+02, with an active set of 311 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 346 iterations, i.e. alpha=5.639e+02, with an active set of 311 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=5.499e+02, with an active set of 313 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=5.497e+02, with an active set of 313 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=5.050e+02, with an active set of 313 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=5.012e+02, with an active set of 313 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=4.910e+02, with an active set of 313 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=4.718e+02, with an active set of 313 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=4.275e+02, with an active set of 313 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 348 iterations, i.e. alpha=4.217e+02, with an active set of 313 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 349 iterations, i.e. alpha=4.156e+02, with an active set of 314 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=3.624e+02, with an active set of 315 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 350 iterations, i.e. alpha=3.460e+02, with an active set of 315 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=3.108e+02, with an active set of 316 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=2.928e+02, with an active set of 316 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=2.747e+02, with an active set of 316 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=2.736e+02, with an active set of 316 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=2.519e+02, with an active set of 316 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=2.068e+02, with an active set of 318 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=2.061e+02, with an active set of 318 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=2.061e+02, with an active set of 318 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=2.059e+02, with an active set of 318 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=2.042e+02, with an active set of 318 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 354 iterations, i.e. alpha=2.042e+02, with an active set of 318 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=1.855e+02, with an active set of 319 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=1.854e+02, with an active set of 319 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=1.854e+02, with an active set of 319 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=1.606e+02, with an active set of 319 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=1.538e+02, with an active set of 319 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=1.422e+02, with an active set of 319 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=1.373e+02, with an active set of 319 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=1.345e+02, with an active set of 319 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=1.334e+02, with an active set of 319 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=1.319e+02, with an active set of 319 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=1.196e+02, with an active set of 319 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=1.046e+02, with an active set of 319 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=1.003e+02, with an active set of 319 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=1.003e+02, with an active set of 319 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=1.002e+02, with an active set of 319 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=1.002e+02, with an active set of 319 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=1.002e+02, with an active set of 319 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=9.429e+01, with an active set of 319 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=9.424e+01, with an active set of 319 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=9.417e+01, with an active set of 319 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=9.415e+01, with an active set of 319 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=9.413e+01, with an active set of 319 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=9.410e+01, with an active set of 319 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 355 iterations, i.e. alpha=9.136e+01, with an active set of 319 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.887e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.880e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.880e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.879e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.877e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.877e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.876e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.875e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.875e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.875e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.873e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.873e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.865e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.863e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.713e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.442e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.435e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.348e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.346e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.344e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.343e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.342e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.341e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.339e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.339e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.339e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.334e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.330e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 356 iterations, i.e. alpha=8.330e+01, with an active set of 320 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=6.972e+01, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=6.967e+01, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=6.310e+01, with an active set of 321 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=6.157e+01, with an active set of 321 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=5.805e+01, with an active set of 321 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=5.563e+01, with an active set of 321 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=5.469e+01, with an active set of 321 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=5.452e+01, with an active set of 321 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=5.451e+01, with an active set of 321 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=5.450e+01, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=5.449e+01, with an active set of 321 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=5.448e+01, with an active set of 321 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=5.337e+01, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=5.088e+01, with an active set of 321 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=4.536e+01, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=4.534e+01, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=4.532e+01, with an active set of 321 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=4.531e+01, with an active set of 321 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=4.530e+01, with an active set of 321 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=4.414e+01, with an active set of 321 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=4.240e+01, with an active set of 321 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=4.080e+01, with an active set of 321 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 357 iterations, i.e. alpha=3.871e+01, with an active set of 321 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 358 iterations, i.e. alpha=3.639e+01, with an active set of 322 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 358 iterations, i.e. alpha=3.272e+01, with an active set of 322 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 358 iterations, i.e. alpha=3.084e+01, with an active set of 322 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 358 iterations, i.e. alpha=3.082e+01, with an active set of 322 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 358 iterations, i.e. alpha=3.081e+01, with an active set of 322 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 358 iterations, i.e. alpha=2.530e+01, with an active set of 322 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=1.851e+01, with an active set of 324 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=1.817e+01, with an active set of 324 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=1.793e+01, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=1.635e+01, with an active set of 324 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=1.199e+01, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=1.185e+01, with an active set of 324 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.791e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.775e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.769e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.764e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.764e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.761e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.725e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.601e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.600e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.594e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.593e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.589e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.589e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.588e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.588e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.588e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.587e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.587e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.586e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.585e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.585e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.584e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.581e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.580e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.579e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.579e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.576e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.543e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.468e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.375e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.373e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.366e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.366e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.365e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.365e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.364e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.364e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.363e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.362e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.362e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.362e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.361e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.360e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.359e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.359e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.359e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.358e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.358e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.357e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.357e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.357e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.356e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.355e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.351e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.347e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.315e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.269e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=9.106e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=7.817e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=5.941e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=4.708e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=4.636e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=4.602e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=4.599e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=4.598e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=4.596e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=4.595e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=4.595e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=4.594e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=4.594e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=4.593e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=4.590e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=4.584e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=4.582e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=4.122e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=4.083e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=4.073e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=3.753e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=3.524e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=3.517e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 361 iterations, i.e. alpha=3.351e+00, with an active set of 324 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=1.515e+00, with an active set of 325 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=1.381e+00, with an active set of 325 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=1.123e+00, with an active set of 325 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=1.050e+00, with an active set of 325 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=1.022e+00, with an active set of 325 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=9.050e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=9.049e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=6.773e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.982e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.461e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.304e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.301e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.301e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.300e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.297e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.297e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.297e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.296e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.296e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.296e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.295e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.295e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.294e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.294e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.293e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.293e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.293e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.293e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.293e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.292e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.292e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.292e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.291e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.290e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.289e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.289e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.289e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.289e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.288e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.285e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.285e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.284e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=5.278e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=4.950e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=4.763e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=4.681e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n",
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:660: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 362 iterations, i.e. alpha=2.272e-01, with an active set of 325 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning,\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.linear_model import LassoLars, Lars\n",
    "from scipy.linalg import eigh\n",
    "from fsfc.base import KBestFeatureSelector\n",
    "\n",
    "x = np.array(B16172_test.iloc[:,:])\n",
    "clusters = 1\n",
    "p=8\n",
    "sigma=1\n",
    "mode='default'\n",
    "alpha=0.01\n",
    "\n",
    "def create_regressor(mode,alpha):\n",
    "    if mode == 'default':\n",
    "        return Lars()\n",
    "    if mode == 'lasso':\n",
    "        return LassoLars(alpha=alpha)\n",
    "    raise ValueError('Unexpected mode ' + mode + '. Expected \"default\" or \"lasso\"')\n",
    "\n",
    "graph = kneighbors_graph(\n",
    "            x,\n",
    "            n_neighbors=p,\n",
    "        )\n",
    "        # Construct the heat matrix\n",
    "w = np.zeros([x.shape[0], x.shape[0]])\n",
    "rows, cols = graph.nonzero()\n",
    "for i, j in zip(rows, cols):\n",
    "    w[i, j] = math.exp(-np.linalg.norm(x[i] - x[j])**2/sigma)\n",
    "\n",
    "# Compute degree and Laplacian matrices\n",
    "degree_vector = np.sum(w, 1)\n",
    "degree = np.diag(degree_vector)\n",
    "laplacian = degree - w\n",
    "\n",
    "# Solve the eigen-problem\n",
    "values, vectors = eigh(laplacian, degree)\n",
    "smallest = vectors[:, 0:clusters].T\n",
    "\n",
    "# Find coefficients for each cluster\n",
    "coefs = []\n",
    "for i in range(clusters):\n",
    "    this_coefs = create_regressor(mode,alpha).fit(x, smallest[i]).coef_\n",
    "    coefs.append(this_coefs)\n",
    "coefs = np.array(coefs)\n",
    "\n",
    "# Compute MCFS-scores\n",
    "scores = np.max(coefs, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "indices = np.argsort(scores)[-20:]  # top 20 features\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)),scores[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [B16172_test.columns[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11,\n",
       " 14,\n",
       " 16,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 51,\n",
       " 60,\n",
       " 63,\n",
       " 72,\n",
       " 78,\n",
       " 329,\n",
       " 338,\n",
       " 354,\n",
       " 357,\n",
       " 373,\n",
       " 397,\n",
       " 400,\n",
       " 402,\n",
       " 416,\n",
       " 420,\n",
       " 421]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_mutations = [22028,22029.22030,23402,23403,23404,28143,28144,28145,25468,25469,25470,23603,23604,23605,14381,14382,14383,26766,26767,26768,16439,16440,\n",
    "16441,28880,28881,28882,21617,21618,21619,29402,29403,29404,15425,15426,15427,22994,22995,22996,28460,28461,28462,22916,22917,22918,24410,\n",
    "24411,24412,27751,27752,27753,27637,27638,27639,10028,10029,10030,11201,11202,11203,19193,19194,19195,4181,4182,4183,9053,9054,9055,28916,\n",
    "28917,28918,27873,27874,27875,6401,6402,6403,7124,7125,7126]\n",
    "fea_name = []\n",
    "sel_fea = list(pd.Series(scores).sort_values(ascending=False).index[:])\n",
    "for i in sel_fea:\n",
    "    fea_name.append(list(B16172_test.columns)[i])\n",
    "rank_def = []\n",
    "sel_def = []\n",
    "for i in range(len(fea_name)):\n",
    "    if int(fea_name[i]) in def_mutations:\n",
    "        rank_def.append(i)\n",
    "        sel_def.append(fea_name[i])\n",
    "rank_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['27638',\n",
       " '22917',\n",
       " '11201',\n",
       " '26767',\n",
       " '6402',\n",
       " '21618',\n",
       " '23604',\n",
       " '28461',\n",
       " '4181',\n",
       " '29402',\n",
       " '22028',\n",
       " '27874',\n",
       " '28881',\n",
       " '24410',\n",
       " '27752',\n",
       " '25469',\n",
       " '7124',\n",
       " '28916',\n",
       " '9053',\n",
       " '10029',\n",
       " '22995',\n",
       " '23403']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1037: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  \"KMeans is known to have a memory leak on Windows \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23608.538223140516"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B16172_SEL = np.array(B16172_test.iloc[:,:])[:,list(np.where( scores > 1.0e+7)[0])]\n",
    "Kmeans = KMeans(n_clusters=1)\n",
    "Kmeans.fit(B16172_SEL)\n",
    "Kmeans.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(B16172_SEL[:,:-1])\n",
    "\n",
    "# Project data onto first two principal components\n",
    "projX = pca.transform(B16172_SEL[:,:-1])\n",
    "plt.figure(figsize=(30,15))\n",
    "\n",
    "scatter = plt.scatter(projX[:,0],projX[:,1],cmap='rainbow')\n",
    "\n",
    "plt.title('Projected data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aral\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:38: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'18905': -10.923605699609698,\n",
       " '2969': -0.7166422945658393,\n",
       " '20641': -0.544628681667829,\n",
       " '5931': -0.005120105656847968,\n",
       " '20930': -0.0005696369668344014,\n",
       " '745': -1.2376794797788315e-15,\n",
       " '6730': -1.2376794797788315e-15,\n",
       " '15906': -1.2376794797788315e-15,\n",
       " '25471': -1.2376794797788315e-15,\n",
       " '3393': -2.0816709667737015e-16,\n",
       " '20268': -1.2496305997565019e-16,\n",
       " '5513': -1.1077976737772125e-16,\n",
       " '20368': -1.1077976737772125e-16,\n",
       " '2165': -6.273280833872533e-17,\n",
       " '16070': -3.952372522581998e-17,\n",
       " '11606': -3.075010217388053e-17,\n",
       " '29095': -3.075010217388053e-17,\n",
       " '2944': -2.6280712553617486e-17,\n",
       " '27566': -2.6280712553617486e-17,\n",
       " '27629': -2.6280712553617486e-17,\n",
       " '19441': -2.5190474241074027e-17,\n",
       " '19690': -2.5190474241074027e-17,\n",
       " '23695': -2.0948150038687477e-17,\n",
       " '21255': -1.0108596923862922e-17,\n",
       " '28899': -1.0108596923862922e-17,\n",
       " '28903': -1.0108596923862922e-17,\n",
       " '29705': -1.0108596923862922e-17,\n",
       " '10376': -2.2879985518679963e-18,\n",
       " '27281': -7.678985540964571e-22,\n",
       " '9130': -7.678985540964569e-22,\n",
       " '21761': -6.731123083543634e-22,\n",
       " '28018': -4.298514761070058e-22,\n",
       " '24959': -3.8394420317592556e-22,\n",
       " '121': -3.839442031759253e-22,\n",
       " '29081': -3.739485370139228e-22,\n",
       " '2078': -3.439274634778152e-22,\n",
       " '8926': -2.865657572487423e-22,\n",
       " '5131': -2.1492360788512182e-22,\n",
       " '20477': -2.1492360788512135e-22,\n",
       " '3047': -2.1492360788512135e-22,\n",
       " '4901': -2.1492360788512135e-22,\n",
       " '8303': -2.1492360788512135e-22,\n",
       " '13892': -2.1492360788512135e-22,\n",
       " '18651': -2.1492360788512135e-22,\n",
       " '18747': -2.1492360788512135e-22,\n",
       " '20578': -2.1492360788512135e-22,\n",
       " '21658': -2.1492360788512135e-22,\n",
       " '22959': -2.0258061318879207e-22,\n",
       " '22858': -1.9197083314503117e-22,\n",
       " '25793': -1.9197083314503115e-22,\n",
       " '29754': -1.9197083314503105e-22,\n",
       " '932': -1.91970833145031e-22,\n",
       " '27948': -1.91970833145031e-22,\n",
       " '25726': -1.9197083314503098e-22,\n",
       " '11580': -1.9197083314503091e-22,\n",
       " '25599': -1.9197083314503091e-22,\n",
       " '3638': -1.919708331450309e-22,\n",
       " '22484': -1.919708331450309e-22,\n",
       " '6373': -1.9197083314503087e-22,\n",
       " '1772': -1.9197083314503084e-22,\n",
       " '5869': -1.9197083314503084e-22,\n",
       " '14937': -1.9197083314503082e-22,\n",
       " '29527': -1.919708331450308e-22,\n",
       " '19999': -1.919708331450308e-22,\n",
       " '2659': -1.919708331450308e-22,\n",
       " '6354': -1.919708331450308e-22,\n",
       " '25775': -1.919708331450308e-22,\n",
       " '1346': -1.9197083314503077e-22,\n",
       " '26062': -1.9197083314503075e-22,\n",
       " '11454': -1.9197083314503068e-22,\n",
       " '4886': -1.7680383821915279e-22,\n",
       " '622': -1.4688933611212225e-22,\n",
       " '13953': -1.432819318922516e-22,\n",
       " '17250': -1.0456135427096034e-22,\n",
       " '21952': -1.0456135427096032e-22,\n",
       " '14604': -6.651743580479794e-23,\n",
       " '23270': -1.569573117222291e-24,\n",
       " '29128': -1.569573117222291e-24,\n",
       " '14925': -4.229324571742317e-26,\n",
       " '29420': -4.229324571742317e-26,\n",
       " '15470': -4.229324571742317e-26,\n",
       " '4012': -4.229324571742317e-26,\n",
       " '27290': -4.229324571742317e-26,\n",
       " '18546': -4.229324571742312e-26,\n",
       " '21365': -2.7465714998631957e-29,\n",
       " '27877': -1.7623541484278096e-29,\n",
       " '22363': 1.0587872709828186e-29,\n",
       " '19006': 1.4749353130066212e-29,\n",
       " '19186': 1.4749353130066212e-29,\n",
       " '3553': 8.879331930544074e-19,\n",
       " '23656': 1.84165220766856e-17,\n",
       " '25448': 3.003447715860583e-17,\n",
       " '2919': 3.441981623869536e-17,\n",
       " '2272': 5.0008187905986326e-17,\n",
       " '7194': 5.0008187905986326e-17,\n",
       " '17004': 5.0008187905986326e-17,\n",
       " '22981': 5.0008187905986326e-17,\n",
       " '27573': 5.0008187905986326e-17,\n",
       " '11365': 5.919195610202217e-17,\n",
       " '21624': 0.0003367596591042855,\n",
       " '17562': 0.0008778898147558622,\n",
       " '16377': 0.0022347482197222373,\n",
       " '5689': 0.0029687984318939975,\n",
       " '25445': 0.004945780045798294,\n",
       " '29716': 0.010629003999979625,\n",
       " '26152': 0.014786219745188577,\n",
       " '22310': 0.014788923268457294,\n",
       " '28109': 0.017182316332568403,\n",
       " '23481': 0.028772471663374405,\n",
       " '4276': 0.04358248430398642,\n",
       " '17122': 0.05339367050538538,\n",
       " '21910': 0.06386908841621108,\n",
       " '21911': 0.06386908841621108,\n",
       " '13188': 0.08433656423314546,\n",
       " '21': 0.08502078182582845,\n",
       " '25047': 0.09577752995181482,\n",
       " '514': 0.11222294509670791,\n",
       " '7420': 0.19834320340353245,\n",
       " '26786': 0.21439557791442382,\n",
       " '27745': 0.21855590452870122,\n",
       " '2746': 0.21855590452870138,\n",
       " '29557': 0.21855590452870138,\n",
       " '10323': 0.2534615585213078,\n",
       " '11514': 0.2925106543091366,\n",
       " '64': 0.3097986306430247,\n",
       " '4162': 0.3347957499795761,\n",
       " '22104': 0.3386867061327547,\n",
       " '11418': 0.33944459073392225,\n",
       " '9891': 0.36250881812032476,\n",
       " '22388': 0.36572099200316566,\n",
       " '19009': 0.3913521694465624,\n",
       " '2150': 0.3945079279377454,\n",
       " '18713': 0.4120245176567427,\n",
       " '26828': 0.4120245176567427,\n",
       " '24124': 0.4203233794820711,\n",
       " '8634': 0.4639988784050896,\n",
       " '3728': 0.4688393189488803,\n",
       " '1758': 0.49027861054093996,\n",
       " '5184': 0.5282233896944207,\n",
       " '27294': 0.5799508724771004,\n",
       " '11332': 0.5837526522104178,\n",
       " '21740': 0.5855568804385484,\n",
       " '4891': 0.5975304221381337,\n",
       " '22792': 0.6197956699130476,\n",
       " '10029': 0.6336382424722442,\n",
       " '4181': 0.6355453622806803,\n",
       " '14343': 0.6404318903509655,\n",
       " '3334': 0.6788703215185737,\n",
       " '15888': 0.6788703215185737,\n",
       " '8073': 0.6808299766526549,\n",
       " '9943': 0.6808299766526552,\n",
       " '20679': 0.7014332498803921,\n",
       " '1048': 0.7057042022070349,\n",
       " '8986': 0.7160565678341225,\n",
       " '22227': 0.7378040075593928,\n",
       " '29449': 0.7442660356795271,\n",
       " '25433': 0.7531031131469756,\n",
       " '29747': 0.7531031131469756,\n",
       " '23868': 0.7630393336716889,\n",
       " '154': 0.7697800267739587,\n",
       " '18812': 0.7712170286468021,\n",
       " '9053': 0.776590585054546,\n",
       " '21846': 0.7908724877667423,\n",
       " '17586': 0.7909582612811973,\n",
       " '25916': 0.7993729392018709,\n",
       " '16756': 0.8032992658023334,\n",
       " '29711': 0.8231701856355971,\n",
       " '25244': 0.8365925133666727,\n",
       " '22315': 0.8425774225458196,\n",
       " '27874': 0.8496987716976456,\n",
       " '2342': 0.8502093546384324,\n",
       " '20995': 0.8756918230010412,\n",
       " '20134': 0.875948933964519,\n",
       " '20937': 0.8774489211077894,\n",
       " '19220': 0.8811555410283205,\n",
       " '12685': 0.8868054871723675,\n",
       " '685': 0.8887206412360412,\n",
       " '12056': 0.9045516039296406,\n",
       " '13701': 0.9045516039296406,\n",
       " '1516': 0.9162682240108536,\n",
       " '28916': 0.9191879148988568,\n",
       " '27556': 0.9197155295060762,\n",
       " '27561': 0.9230913156333767,\n",
       " '94': 0.9247308197029648,\n",
       " '23998': 0.9280200211283659,\n",
       " '29701': 0.928902758969006,\n",
       " '28077': 0.9302233584956443,\n",
       " '23557': 0.9319033305991954,\n",
       " '7851': 0.9338980642792091,\n",
       " '5584': 0.933907228310664,\n",
       " '12167': 0.9343317821188064,\n",
       " '16726': 0.9418046229664983,\n",
       " '1912': 0.9439450816255286,\n",
       " '8123': 0.9439450816255286,\n",
       " '1968': 0.9445507930114557,\n",
       " '27746': 0.9455087239399382,\n",
       " '24223': 0.9474979133551856,\n",
       " '6500': 0.9475098745978817,\n",
       " '15760': 0.9504163398841587,\n",
       " '29212': 0.9504163398841587,\n",
       " '2509': 0.9520428009505935,\n",
       " '6654': 0.9559129601566124,\n",
       " '18683': 0.956386587961297,\n",
       " '28399': 0.956386587961297,\n",
       " '7124': 0.9569857674642809,\n",
       " '25459': 0.9570282162530357,\n",
       " '5329': 0.9577655221335512,\n",
       " '2647': 0.9577655221335516,\n",
       " '2698': 0.957788043835954,\n",
       " '27527': 0.9582911864094182,\n",
       " '18828': 0.9618178309331317,\n",
       " '19542': 0.9620289403155674,\n",
       " '26730': 0.9626555941686196,\n",
       " '29640': 0.965406253561195,\n",
       " '19263': 0.9668064265966549,\n",
       " '27263': 0.9668064265966549,\n",
       " '27476': 0.9676019711901807,\n",
       " '13534': 0.9680283867254954,\n",
       " '13944': 0.969424493231236,\n",
       " '21057': 0.9699254552702278,\n",
       " '25264': 0.9699254552702278,\n",
       " '533': 0.9704081922712016,\n",
       " '8064': 0.9709704465275498,\n",
       " '14599': 0.9720452718064633,\n",
       " '15026': 0.9740589902169445,\n",
       " '10977': 0.976078052621292,\n",
       " '10691': 0.9762560772032832,\n",
       " '21575': 0.9769714315976932,\n",
       " '18756': 0.9782481157915052,\n",
       " '25537': 0.978260210204285,\n",
       " '6310': 0.9782638238420868,\n",
       " '12400': 0.9782638238420868,\n",
       " '8518': 0.9783311054922466,\n",
       " '2571': 0.978650418999795,\n",
       " '3518': 0.97909848060297,\n",
       " '4609': 0.9798322164135269,\n",
       " '10870': 0.9805852064232013,\n",
       " '11036': 0.9810824069525874,\n",
       " '24488': 0.9813370284932768,\n",
       " '15952': 0.981623898064215,\n",
       " '23401': 0.9819336224833864,\n",
       " '5182': 0.9827469432711171,\n",
       " '5239': 0.9827469432711171,\n",
       " '18457': 0.9827469432711171,\n",
       " '27673': 0.9827469432711171,\n",
       " '28810': 0.9827469432711171,\n",
       " '3078': 0.9827469432711173,\n",
       " '25413': 0.9830093867478195,\n",
       " '19097': 0.9830739009614657,\n",
       " '613': 0.9831176411637885,\n",
       " '16308': 0.9836235073146817,\n",
       " '1415': 0.9839299248772715,\n",
       " '2035': 0.9840131348884059,\n",
       " '17302': 0.9842313067234348,\n",
       " '29077': 0.9854250070092911,\n",
       " '246': 0.9878712888814037,\n",
       " '1191': 0.9879232313781037,\n",
       " '8390': 0.9892833651164854,\n",
       " '1077': 0.9908071358456626,\n",
       " '14759': 0.9909479935326532,\n",
       " '15682': 0.9919110134824561,\n",
       " '25003': 0.9934858746134337,\n",
       " '4657': 0.9947671598720899,\n",
       " '17181': 0.9947671598720899,\n",
       " '5119': 0.9947748767581506,\n",
       " '23575': 0.9947748767581506,\n",
       " '22335': 0.9948251987421612,\n",
       " '3856': 0.9949386646989685,\n",
       " '26985': 0.9949386646989685,\n",
       " '14808': 0.9955088505527768,\n",
       " '11052': 0.9956678707532023,\n",
       " '625': 0.9956713638278131,\n",
       " '21039': 0.9956713638278131,\n",
       " '16989': 0.9957926166448606,\n",
       " '15237': 0.9965023696957555,\n",
       " '28057': 0.9969852121924867,\n",
       " '25517': 0.997298455849332,\n",
       " '10015': 0.9978921276210871,\n",
       " '25424': 0.9980402360150951,\n",
       " '23934': 0.9983523465563168,\n",
       " '20761': 0.9987327549396297,\n",
       " '21137': 0.9987884520423874,\n",
       " '3619': 0.9989608942564684,\n",
       " '27967': 0.9989792696635676,\n",
       " '21802': 0.9991425278254624,\n",
       " '20083': 0.9992025134695366,\n",
       " '12073': 0.9992714678081336,\n",
       " '25872': 0.9992714678081336,\n",
       " '1408': 0.9996592328653175,\n",
       " '11751': 0.9996592328653175,\n",
       " '27679': 0.9996592328653175,\n",
       " '28156': 0.9998634932613168,\n",
       " '29072': 0.9998634932613168,\n",
       " '28808': 0.999905713802597,\n",
       " '1935': 0.9999057138025973,\n",
       " '21401': 0.9999209004357215,\n",
       " '20480': 1.0000004094301747,\n",
       " '8590': 1.0000040214674364,\n",
       " '21660': 1.0000106141288174,\n",
       " '2518': 1.0000170096463747,\n",
       " '5437': 1.0000170096463747,\n",
       " '7768': 1.0000170096463747,\n",
       " '22314': 1.0000170096463747,\n",
       " '7798': 1.000017760938841,\n",
       " '27514': 1.000017760938841,\n",
       " '4455': 1.000026026078893,\n",
       " '17944': 1.000026026078893,\n",
       " '26916': 1.0000491702980605,\n",
       " '564': 1.0000547177523857,\n",
       " '29171': 1.0000547177523857,\n",
       " '29777': 1.0000547177523857,\n",
       " '20487': 1.0000567984026667,\n",
       " '7979': 1.0000683148613059,\n",
       " '27987': 1.0000780508664862,\n",
       " '17040': 1.0000850826978116,\n",
       " '4698': 1.0000920971477538,\n",
       " '15801': 1.0000980675085003,\n",
       " '24086': 1.0001062692545848,\n",
       " '1404': 1.0001136207748702,\n",
       " '4084': 1.0001136207748702,\n",
       " '4752': 1.0001136207748702,\n",
       " '9929': 1.0001136207748702,\n",
       " '13446': 1.0001136207748702,\n",
       " '24381': 1.0001136207748702,\n",
       " '25352': 1.0001136207748702,\n",
       " '8203': 1.000113620774871,\n",
       " '17288': 1.0001181280207847,\n",
       " '10396': 1.0001711422191917,\n",
       " '11401': 1.0001828499263814,\n",
       " '13860': 1.0001828499263814,\n",
       " '10642': 1.0001830712102797,\n",
       " '526': 1.0002007601363914,\n",
       " '2998': 1.0002437783894702,\n",
       " '20235': 1.0002437783894702,\n",
       " '20373': 1.0002437783894702,\n",
       " '3681': 1.0002437783894704,\n",
       " '19524': 1.0003085622276988,\n",
       " '6408': 1.0004022691338017,\n",
       " '11083': 1.0004344439711472,\n",
       " '29119': 1.0007254899201696,\n",
       " '4321': 1.0007825994204977,\n",
       " '3065': 1.0011216692329896,\n",
       " '22114': 1.0011216692329896,\n",
       " '8296': 1.001161884341328,\n",
       " '28307': 1.0013811868672031,\n",
       " '688': 1.0014430518556712,\n",
       " '3874': 1.0014430518556712,\n",
       " '4081': 1.0014430518556712,\n",
       " '11851': 1.0014430518556712,\n",
       " '23718': 1.0014430518556712,\n",
       " '16647': 1.0015699800736684,\n",
       " '12890': 1.0016212657388333,\n",
       " '15251': 1.0016212657388333,\n",
       " '18568': 1.0016212657388333,\n",
       " '29535': 1.0016913526158069,\n",
       " '27020': 1.0019361835176515,\n",
       " '6443': 1.0023169472658946,\n",
       " '25549': 1.0027937689504756,\n",
       " '872': 1.0039053052070184,\n",
       " '18102': 1.0045249531732823,\n",
       " '829': 1.0045249531732825,\n",
       " '29593': 1.0045249531732825,\n",
       " '6402': 1.0047048318036356,\n",
       " '25656': 1.0053622930542347,\n",
       " '28313': 1.0053685476034118,\n",
       " '13019': 1.0059687913708033,\n",
       " '27589': 1.0069259100483023,\n",
       " '27978': 1.0069259100483023,\n",
       " '1729': 1.0078122626682082,\n",
       " '14030': 1.0078122626682082,\n",
       " '18086': 1.0078122626682082,\n",
       " '23403': 1.0100121857445086,\n",
       " '21764': 1.0115294794009417,\n",
       " '24865': 1.0122537590308636,\n",
       " '28432': 1.0124703768975845,\n",
       " '19983': 1.0129068999288307,\n",
       " '3872': 1.0133164944357125,\n",
       " '22716': 1.013316494435714,\n",
       " '29284': 1.013316494435714,\n",
       " '25195': 1.0157278693029723,\n",
       " '21987': 1.0172382572737273,\n",
       " '19962': 1.0180318682547183,\n",
       " '29648': 1.0244088777770386,\n",
       " '3958': 1.024541916776083,\n",
       " '3700': 1.024641930912307,\n",
       " '20438': 1.024641930912307,\n",
       " '28657': 1.0251193332496802,\n",
       " '11521': 1.0252742814847646,\n",
       " '25266': 1.0252742814847646,\n",
       " '3037': 1.0261711611011004,\n",
       " '28461': 1.0281321534994663,\n",
       " '14408': 1.0287614081508363,\n",
       " '25855': 1.0307532179801724,\n",
       " '865': 1.034714823449686,\n",
       " '21990': 1.039496575872147,\n",
       " '23683': 1.0447168366251969,\n",
       " '5392': 1.046018638454282,\n",
       " '15672': 1.046018638454282,\n",
       " '19245': 1.046018638454282,\n",
       " '22993': 1.0514752962635678,\n",
       " '3395': 1.054569013864695,\n",
       " '18507': 1.0547588441478188,\n",
       " '16957': 1.0547588441478193,\n",
       " '2156': 1.0600026564306257,\n",
       " '28001': 1.0623756919620966,\n",
       " '26767': 1.0637592209854843,\n",
       " '16466': 1.0694246258792042,\n",
       " '22917': 1.0941787572753976,\n",
       " '11201': 1.0953126384637202,\n",
       " '25660': 1.0956046794129155,\n",
       " '22891': 1.102768193569372,\n",
       " '27735': 1.102768193569372,\n",
       " '28739': 1.1070540119520358,\n",
       " '21194': 1.1071384839055585,\n",
       " '29402': 1.107637010211698,\n",
       " '24410': 1.113200660953727,\n",
       " '22995': 1.1161483129914649,\n",
       " '23604': 1.1209641412687332,\n",
       " '29623': 1.1250730261096669,\n",
       " '24130': 1.129195569848038,\n",
       " '18744': 1.1464506511272983,\n",
       " '28270': 1.1637232852454185,\n",
       " '28299': 1.1666143810536977,\n",
       " '210': 1.2245915331551953,\n",
       " '15451': 1.2345765664558757,\n",
       " '241': 1.2438634186122113,\n",
       " '28881': 1.2461857916815278,\n",
       " '25469': 1.274978982598756,\n",
       " '27752': 1.2800458290267402,\n",
       " '27638': 1.2866049122283902,\n",
       " '29742': 1.3063798760875869,\n",
       " '28247': 1.3072390255788535,\n",
       " '21618': 1.3288116110002428,\n",
       " '22028': 1.4514852833906358}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls =LaplacianScore(np.array(B16172_test.iloc[:,:]))\n",
    "B16172_SEL = np.array(B16172_test.iloc[:,:])[:,list(np.where( ls < 0.001)[0])]\n",
    "B16172_score = {}\n",
    "for i in range(len(B16172_test.columns)):\n",
    "    \n",
    "    if str(list(ls)[i]) != 'nan':\n",
    "        B16172_score[list(B16172_test.columns)[i]] = list(ls)[i]\n",
    "res = sorted(B16172_score.items(),key = lambda item:item[1],reverse=False)\n",
    "sor_res = {str(k):v for k,v in res}\n",
    "sor_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(30,15))\n",
    "plt.title('Laplacian feature importance scores')\n",
    "plt.bar(np.arange(np.array(B16172_test).shape[1]),ls);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "indices = np.argsort(ls)[:30]  # top 30 features\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)),ls[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [B16172_test.columns[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[144,\n",
       " 145,\n",
       " 161,\n",
       " 169,\n",
       " 180,\n",
       " 204,\n",
       " 362,\n",
       " 371,\n",
       " 390,\n",
       " 405,\n",
       " 407,\n",
       " 408,\n",
       " 414,\n",
       " 415,\n",
       " 416,\n",
       " 417,\n",
       " 426,\n",
       " 427,\n",
       " 428,\n",
       " 429,\n",
       " 432,\n",
       " 433]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_def = []\n",
    "sel_def = []\n",
    "for i in range(len(list(sor_res.keys()))):\n",
    "    if int(list(sor_res.keys())[i]) in def_mutations:\n",
    "        rank_def.append(i)\n",
    "        sel_def.append(list(sor_res.keys())[i])\n",
    "rank_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10029',\n",
       " '4181',\n",
       " '9053',\n",
       " '27874',\n",
       " '28916',\n",
       " '7124',\n",
       " '6402',\n",
       " '23403',\n",
       " '28461',\n",
       " '26767',\n",
       " '22917',\n",
       " '11201',\n",
       " '29402',\n",
       " '24410',\n",
       " '22995',\n",
       " '23604',\n",
       " '28881',\n",
       " '25469',\n",
       " '27752',\n",
       " '27638',\n",
       " '21618',\n",
       " '22028']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_def"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
